{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Date: 22-5-2017\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: caution: 十一黃金周\n",
    "\n",
    "df_merged_volume = pd.read_csv(\"../data/preprocessed_input_traffic_time_and_weather_interpolate_20min_phase1and2_train.csv\")\n",
    "\n",
    "# change \"Date\" to datetime object\n",
    "df_merged_volume['date'] = pd.to_datetime(df_merged_volume['date'])\n",
    "\n",
    "# construct \"time of day\"\n",
    "df_merged_volume['timeofday'] = df_merged_volume.date.apply( lambda d : d.hour+d.minute/60.)\n",
    "\n",
    "# Select the phase 1 day\n",
    "\n",
    "end_day = datetime.datetime(year=2016, month=10, day=18, hour=0, minute=0, second=0)\n",
    "\n",
    "df_merged_volume = df_merged_volume[(df_merged_volume['date'] < end_day)]\n",
    "\n",
    "# check any unreasonable rows\n",
    "df_merged_volume.tail(30)\n",
    "\n",
    "''' Cut some rows (proprecessing)'''\n",
    "df_merged_volume = df_merged_volume[4:]  # Cut of NaN rows at the beginning\n",
    "df_merged_volume = df_merged_volume.reset_index(drop=True)  # reindexing\n",
    "df_merged_volume\n",
    "\n",
    "''' Make the dataset stationary '''\n",
    "\n",
    "station_cols = 6  # select the first 6 columns for stationary\n",
    "\n",
    "df_merged_volume_copy = df_merged_volume.copy()\n",
    "\n",
    "for i in range(1, len(df_merged_volume_copy)):\n",
    "    df_merged_volume_copy.loc[i, df_merged_volume_copy.columns[0:station_cols]] = df_merged_volume.loc[i, df_merged_volume.columns[0:station_cols]] - df_merged_volume.loc[i-1, df_merged_volume.columns[0:station_cols]]\n",
    "\n",
    "# Check Stationary dataframe\n",
    "\n",
    "df_merged_volume_copy.tail()\n",
    "\n",
    "## Hidden the selecting time\n",
    "# select the time for training: 6:20-10:00 (5 + 6 timestamp) and 15:20-19:00 (5 + 6 timestamp)\n",
    "# sel_rows = df_merged_volume_copy[ ((df_merged_volume_copy.timeofday>= 6.3) & (df_merged_volume_copy.timeofday<10)) |\n",
    "#                             ((df_merged_volume_copy.timeofday>=15.3) & (df_merged_volume_copy.timeofday<19))]\n",
    "\n",
    "## This time, training all time (24hrs) except the first non-stationary row\n",
    "sel_rows = df_merged_volume_copy[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAFkCAYAAADoo9t2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3XucHFWd9/HPL7chiZAQkCREIQQIExGQGZaLt+CjwvoI\nI8oiZo1cRPTRFdi4rsgKEsBdXBTiysVVwKBGZgFdJGFZA4oEBCQywy2SC5CES0iGS5JJTEKu5/nj\nnJ6prpnpnp7pqu7q+b5fr37N1KXrV7eu+tWpc6rMOYeIiIhIVgyq9AyIiIiIlELJi4iIiGSKkhcR\nERHJFCUvIiIikilKXkRERCRTlLyIiIhIpih5ERERkUxR8iIiIiKZouRFREREMkXJi4iIiGRKosmL\nmX3AzOaa2Soz22VmTbHhs0P/6Oee2Dh1Zna9mb1hZhvN7Fdmtk9snD3N7Jdm1m5m68zsJjMbmeSy\niYiISGUkXfIyEngS+ArQ00uU/hcYC4wLn2mx4T8APg6cCnwQ2Bf4dWycW4EpwIfDuB8Eftz/2RcR\nEZFqY2m9mNHMdgGnOOfmRvrNBkY55z7Vw3f2AF4HPuOcuzP0OwRYDBzrnFtoZlOAvwCNzrknwjgn\nAv8DvMM5tybJ5RIREZF0VUOdl+PNrM3MlpjZDWY2JjKsERgC/D7Xwzm3FHgJOC70OhZYl0tcgt/h\nS3qOSXbWRUREJG1DKhz/f/G3gFYABwJXAveY2XHOFwmNA7Y55zbEvtcWhhH+vhYd6JzbaWZrI+N0\nYWZ7AScCK4G3+r8oIiIiA8ZuwERgvnPuzbSDVzR5cc7dHun8i5k9A7wAHA/8IeHwJwK/TDiGiIhI\nLfssvt5pqipd8pLHObfCzN4ADsInL2uAYWa2R6z0ZWwYRvgbb300GBgTGac7KwHmzJnDlClTej2P\nM2bMYNasWb0ev7/SjFersdKOV6ux0o6nZcterLTj1WqstOP1JdbixYuZPn06hHNp2qoqeTGzdwB7\nAatDrxZgB74VUbTC7n7Ao2GcR4HRZnZkpN7LhwEDHisQ7i2AKVOm0NDQ0Ot5HDVqVEnj91ea8Wo1\nVtrxajVW2vG0bNmLlXa8Wo2Vdrx+xqpItYtEk5fwrJWD8IkEwCQzOwJYGz6X4uu8rAnj/TuwDJgP\n4JzbYGY3A9eY2TpgI/BD4GHn3MIwzhIzmw/caGZfBoYB1wLNamkkIiJSe5IueTkKf/vHhc/Vof/P\n8M9+ORw4AxgNvIpPWr7tnNsemcYMYCfwK6AO+C3wD7E4fw9ch29ltCuMe0H5F0dEREQqLdHkxTm3\ngMLNsf+2F9PYCpwXPj2Nsx6YXvIMioiISOYMnjlzZqXnoSIuu+yy8cCXvvSlLzF+/PiSvnvYYYcl\nM1NVEK9WY6Udr1ZjpR1Py5a9WGnHq9VYaccrNdbq1av5yU9+AvCTmTNnri42frml9oTdamNmDUBL\nS0tLqpWwREREsq61tZXGxkbwT7dvTTt+NTxhV0RERKTXlLxIRTQ3N1d6FkREJKOUvEhFKHkREZG+\nUvIiIiIimaLkRURERDKlql4PILWrubk571bRvHnzaGpq6uieNm0a06ZNq8SsiYhIxih5kVTEk5Om\npibmzp1bwTkSEZGs0m0jERERyRQlLyIiIpIpSl6qXK02KVb9FhER6SslL1VOyYuIiEg+JS8iIiKS\nKUpeREREJFPUVLrK6HkoIiIihSl5qTJ6HoqIiEhhum0kIiIimaLkRURERDJFyUuVU/0WERGRfEpe\nqpySFxERkXxKXkRERCRTlLyIiIhIpih5ERERkUxR8iIiIiKZouRFREREMkXJi4iIiGSKkhcRERHJ\nFCUvIiIikilKXkRERCRTlLyIiIhIpih5ERERkUxR8iIiIiKZouRFREREMkXJi4iIiGSKkhcRERHJ\nFCUvIiIikilKXkRERCRTlLyIiIhIpih5ESmz5ubmSs+CiEhNU/IiUmZKXkREkpVo8mJmHzCzuWa2\nysx2mVlTN+NcbmavmtlmM7vPzA6KDa8zs+vN7A0z22hmvzKzfWLj7GlmvzSzdjNbZ2Y3mdnIJJdN\nREREKiPpkpeRwJPAVwAXH2hmFwJfBb4IHA1sAuab2bDIaD8APg6cCnwQ2Bf4dWxStwJTgA+HcT8I\n/LicCyIiIiLVYUiSE3fO/Rb4LYCZWTejXABc4Zy7O4xzBtAGnALcbmZ7AJ8HPuOcWxDGORtYbGZH\nO+cWmtkU4ESg0Tn3RBjnPOB/zOzrzrk1SS6jSHNzc96tonnz5tHU1FnIOG3aNKZNm1aJWeuXzZs3\ns2TJkoLj1NfXM2LEiEzGE5HsSjR5KcTMDgDGAb/P9XPObTCzx4DjgNuBo/DzGB1nqZm9FMZZCBwL\nrMslLsHv8CU9xwB3JbwoMsDFk5Ompibmzp1bwTnqn+eeg40bYfHiJUyf3lhw3DlzWpgypQGA3XeH\ngw/ufZw3XtrMQzd2JiurVy/mppunF/zOF86Zw/jxU5gwAY4+ox6UyIgMSBVLXvCJi8OXtES1hWEA\nY4FtzrkNBcYZB7wWHeic22lmayPjiEgvPP2nzZx1XC6hWMeRXFFw/KunrwNaO7pvf6qegw7vXULx\n0I1L+OR38pOjrxT7UiS5WfH2Fg44taFXsUSktlQyeakKM2bMYNSoUXn9slrML9JfL/zPElopXNpS\nyEvLW+Dw3iUUHzi3njtp6eguueTlY/V9nk8R6b34rXGA9vb2Cs2NV8nkZQ1g+NKVaOnLWOCJyDjD\nzGyPWOnL2DAsN0689dFgYExknB7NmjWLhgZdvUn5ZDnxzSUUEyeC2RZefXVlwfH33XcidXXDARg5\nEvY7ofcJxd77jeCTV3T+9jZvrufYr7QU+IbqvIhUQncX9K2trTQ29v1Cp78qlrw451aY2Rp8C6Gn\nAUIF3WOA68NoLcCOMM6dYZxDgP2AR8M4jwKjzezISL2XD+MTo8dSWBSRPFlOXuIJxXt4X2qxR4wY\noQsJEemVRJOX8KyVg/CJBMAkMzsCWOucexnfDPpiM3seWAlcAbxCqGQbKvDeDFxjZuuAjcAPgYed\ncwvDOEvMbD5wo5l9GRgGXAs0q6WRiIhI7Um65OUo4A/4irkOuDr0/xnweefcVWY2Av9MltHAQ8DH\nnHPbItOYAewEfgXU4Zte/0Mszt8D1+FbGe0K416QxAKJiIhIZSX9nJcFFHkQnnNuJjCzwPCtwHnh\n09M464HCNf1ERESkJujdRiIiIpIpSl5EREQkU5S8iIiISKYoeREREZFMUfIiIiIimaLkRURERDJF\nyYuIiIhkipIXERERyRQlLyIiIpIpSl5EREQkU5S8iIiISKYoeREREZFMUfIiIiIimaLkRURERDJF\nyYuIiIhkipIXERERyRQlLyIiIpIpSl5EREQkU5S8iIiISKYoeREREZFMUfIiIiIimaLkRURERDJF\nyYuIiIhkipIXERERyRQlLyIiIpIpSl5kQGhubq70LIiISJkoeZEBQcmLiEjtUPIiIiIimaLkRURE\nRDJlSKVnQCQJzc3NebeK5s2bR1NTU0f3tGnTmDZtWiVmTURE+knJi9SkeHLS1NTE3LlzKzhHIiJS\nLrptJAPCqlWrKj0LIiJSJkpeZEBQ8iIiUjuUvMiAMGHChErPgoiIlImSFxkQlLyIiNQOVdiVmlTJ\n1kbNzc1qySQikiAlL1KTKtnaSMmLiEiydNtIREREMkXJi4iIiGSKbhvJgJDkbRw9zVdEJF3mnKvs\nDJhdClwa673EOfeuyDiXA18ARgMPA192zj0fGV4HXAOcDtQB84GvOOdeKxC3AWhpaWmhoaGhXIsj\nQmNjIy0tLZWeDRGRxLS2ttLY2AjQ6JxrTTt+tdw2WgSMBcaFz/tzA8zsQuCrwBeBo4FNwHwzGxb5\n/g+AjwOnAh8E9gV+ncqcJyx6RS/ZoAfiiYgkq1qSlx3Oudedc6+Fz9rIsAuAK5xzdzvnFgFn4JOT\nUwDMbA/g88AM59wC59wTwNnA+8zs6JSXo+y+//3vV3oWREREqkq1JC8Hm9kqM3vBzOaY2TsBzOwA\nfEnM73MjOuc2AI8Bx4VeR+Hr7kTHWQq8FBkns3QVnz3Dhw+v9CyIiNS0aqiw+yfgLGApMB6YCTxo\nZu/GJy4OaIt9py0MA3+7aVtIanoaRyQx8Qq7K1euVIVdEZEEVTx5cc7Nj3QuMrOFwIvAp4EllZmr\nyomfCNva2nQirHLxbTJu3LjUHognIjIQVTx5iXPOtZvZMuAg4AHA8KUr0dKXscAT4f81wDAz2yNW\n+jI2DCtoxowZjBo1Kq9foQRBT08VEZGBJH5RDdDe3l6hufEq3lQ6zszehq+vcolz7nozexX4nnNu\nVhi+Bz6ROcM5d0fofh34jHPuzjDOIcBi4Fjn3MIe4vSpqXSaj5kHfxW/Zk3RHEwqqLvnvJx88skd\n3SotE5FaU+mm0hUveTGz7wHz8LeKJgCXAduB/wqj/AC42MyeB1YCVwCvAHeBr8BrZjcD15jZOmAj\n8EPg4Z4Slyx56623Kj0LUkQ8OWlsbNRtIxGRBFVDa6N3ALfi67f8F74U5Vjn3JsAzrmrgGuBH+Nb\nGQ0HPuac2xaZxgzgbuBX+FtNr+Kf+ZJ51VYyllVpPi9nwoQJqcUSERmIKl7y4pwrWp7unJuJb4XU\n0/CtwHnhU1aVfvT7mDFjEpv2QKK6SiIitaPiyUu1iycnadd52bJlS2qxpDz233//Ss+CiEhNU/JS\nZdRUOvtefPHFSs+CiEhNU/JSoqSfeKtnhpRHpW/3iYhIcpS8VBmVvJRHpW/3iYhIcpS8lCjpliTx\nk+7o0aN10q1yKuUREUmXkhepiPPOO49rr7220rNRFrrVJyKSLiUvReiqOhl33HFHqsmLWgCJiNQO\nJS9FVPo2jh5SVx5ptgDSU5FFRJKl5KVEST93JV7Ss2HDBpX0VLn4Nmtvb9c2q3KbN29myZLCL62v\nr69nxIgRKc2RiJSi6l7MmJa+vphx6NChbN++PbkZi6mrq2Pr1q2pxEryKbTnnXced9xxR0d3W1sb\nY8eO7eg+7bTTEr2NlGZrI71Ms/pFXirXo1KPDSIDyYB/MWO1i19V79ixI9Gr6ni8bdu2pXYVn2Ty\ncu211+YlJ3V1dYme4CtZV0m3japffX09LS0tHd3Ll8M3vgFXXQWTJnWOIyLVSclLlYmfVM0stRKD\npB/Al6Y0n/Oi20bZM2LEiC6lKitW+MRFhS0i1U/JSxHxE8+gQYMSTSbiJ0IgtRNhLSUvcc8880xi\n045vk1GjRqmptIhIgpS8FBFPJpxziSYTaSZLaT7Nt5K3wwBeeumlxKYdN3z48NRiiYgMRKqwW2Kl\nvMGDB7Nz587E5quSFVtHjRpFe3t7ItOOGz16NOvXr08lFvjbb0nt693Vrzn55JM7unXbqPq1tkJj\nI7S06LaRSG+owm6Vi5+Ydu3alWiJQbxi66BBgxKr2FrJZtlJNzmPM7PEph1fT42NjbptJCKSICUv\nRcRPTHV1damemNI86SZdnydN8RIs5xzjxo3r6E66abaIiCRHyUuJkq7PkHZJT1SStxArXeclTU89\n9VSlZ0F68NxzsHFj1/6LF+f/jdp9dzj44GTnS0RKo+SliLSbwabZVLqSLZuSFr/9ZmapPTguyTpR\n0nfPPQeTJxceZ/r07vsvW6YERqSaqMJuiRV2hwwZwo4dO5KbsZgkK5pWMlbaT6Gt1fUovZerlDtn\nDkyZ0rvvLF7sExpV5BXJpwq7GTN48OBEp59maciJJ57IAw88kNevrq6u4//jjz+e+fPnlyVWXNJP\noU1zPdZyCVYtmjJFiYhI1il5KVEt3RKIJyZmltp7lLZt25ZKnDRceeWVLFq0KK/f3Xff3fH/ypUr\nlbyIiJSRkpci4q1Wdu7cmWirlUceeYSFCxfm9Yt277///ip5qTJPP/10XreZsWvXrgrNjYhI7VPy\nUkSaz13pLl6aFU3TVEt1QuIJLqBm2SIiCVLyUqKkT7ppnghXr17N9u3b8/pFu1evXl2WOJB+vZBz\nzz2XTZs25fWbN29ex//333+/buWIiGSUkpciarky5tSpU3nttdc6utva2thnn33yhmfVjTfeWPSR\n/SIikk1KXqrMjTfe2KXSbFtbW97wcpW8pHmLKu1KrWk+L2fZsmWsW7cur1+0e9myZYnEldLYls0c\nyRKGd/Mgup4MXwxHAralHhiR1KyJSImUvFSZyZMn553knXN5rwiYXOwpWyVIs8LuRRdd1KUk5KST\nTuroLndJiOqhSNxuK5fQSiP08CC67kwBWoHFK1vgfWpfLVItlLxUmTRv5UyePDnvUfZtbW3sueee\necPLJe2Sl7vuuiuvxAryS7DuuuuusiUvCxYs6NL0O9q9YMGCssSR/nlrYj0NtPDLEh9S99npcPPE\n+mRnTkRKouSliFtuuaVL6US0NGLr1q1lPekuWLAgL3kB8rrLeSJM83bH+PHjWbp0aUf3tm3bGDp0\naN7wcpoyZUpesrJt2zaGDRuWN7xcpk6dmrePxGNlue5QLXHDR/AEDWyZAvSyEGUL8ATgkn2lmYiU\nSMlLEWm2yAFYvnx5lxZN0e7ly5eXLVYlH1JXS9IswRIRESUvVWfz5s39Gl6Kvfbai7Vr1+b1i9av\nGTNmDG+++WZZYqWdBN5///1d3kEVvZVz//33ly3W7NmzuzTLjpb6zJ49W/VrRETKSMlLEevXry9Y\nErJ+/fq0Z6ls4ifcUoeXIs0SJSj+GodyvuYhzfUoIiIwqNIzUO3iJROlDi9VtK5EX4aXIs0T/KRJ\nkzCzjg+Q1z1p0qSyxQL46Ec/yrBhwzo+QF73Rz/60bLFirbQ6stwEREpjUpeihgzZkzBK+cxY8aU\nNV6xOiflrJMSv61S6vBSPPPMM136RUteuhveH/fee2+XftHbRt0N76s0t5mIiCh5KapYXYxy19UQ\nEcmKzZs3s2TJkoLj1NfXM2KEHvAn5aXkpYg0SyfSNmTIkILzP2SIdg+pHbm67q2tvf/O4hKexjsQ\nLVmyhMbGxoLjtLS00NCgB/xJeensNIDVcmImEpcrIDj33NK/u/vu5Z2XrHvuOdi4EbZsqWfOnJaO\n/itWwCWXwBVXwAEH+H5bttTT2urX4cEHV2iGpeYoeRGRAeGUU/zf+nqI38VYvBimT4c53Tx9Vyfd\nfM8/vZnTj+j5VtGRwH9fEu3TOe7tT9Vz0OG6hST9p+SlipTzGS5ZtHnzZt0bl8TsvTd84QuFx5ky\nBXSHo7CNfw7viOrBeUBPTzVa/EwLHF6+Fdzc3Kw3xA9QSl7KoFwn3WIV32rdkiVLdG9cpMo9+VY9\n59DS4/AnaOThHobfflh53xF15plnKnkZoGoqeTGzfwC+DowDngLOc879Oem45Trp1tfX09LS+aP3\nRdmNzJnT0lGUXV+fzRfEbdq0qSM56265oHzLNtBLsGRgS7oF0Mmnj2BnXUPB22//NKeh29tvB5X5\n9lv8qd0ycNRM8mJmpwNXA18EFgIzgPlmNtk590Zfp5vmSXfEiBHdJkFTpjRkvii7u2VLarmqsQRL\nt8Qkysy6PHG6zzZv5qV7l5B7HNWKFYu5+JLpBb/ynSvmcMABUxg5EvY7oZsspIDo7beeE6XOJl1q\nKi1JqJnkBZ+s/Ng593MAM/t/wMeBzwNX9XWiaZ50pTyqsQSrv6Vzna07NrNyZeHkbOLEeoYPH6GK\npgPEsrlLmDytsw7KFOD/FvtSJLl56c4W9julb/tmT02lp0/v7PfpT3+a2267rU/Tj2tubqa5uTmv\nX1NTU8f/06ZN022kHuSOIVD8OJI7hkD1VlivieTFzIYCjcC/5fo555yZ/Q44ri/TjG7onNwzH3p6\n9kNfN3J3sZKKF431xz9u6tiBfRPHRq64oqWjiePEifUdz8Qo57Ilvx5HAN0djDv7RS8Wk16P0L/m\novmtOxYDha+qYQ7+FKbWHQPBw2/W85m8OiZbgJVFvjURGA7A7ZP6nsj35iLg9ttvL1vy8tWvfrXL\nK1nmzZvX8f/DDz+s5KUbXVuIFTuOdB5DoDqPIzWRvAB7A4OBtlj/NuCQUidWrCng1dN7fspVqRu5\neLPDlrLFKxYLem7iWGqsYvHKuVzFYuVUbj1Cf5qLFmvd0VXnQancrTtqRfx2x/Ll/rkk0feD9ud2\nxxsvbeahG5eEWOt44YVHu4xz+Snf6fj/wAOPY8SIPQGYMAGOPqP3t3LidVAWL25l+vTCCa4vhWzo\ndz2UESNGdLn9Vc5bYtH1CL1719ydl/jfeanrMR6rp+0WldtupcaKx0s6Vn+OIVCdx5FaSV76bMaM\nGYwaNSqv3wffeSytfKvAt3reCUrdyNufKXWn6nu8YjuwQcHhaS5bqbHSXLa012N+644SS17K3Lqj\nVvR0u+O00zr/78+TYR+6cQmf/E7n9K2bcS69Kz/DjZ7uV7y9hQNO7V3seBPw+G3T7vjErFeTr6j4\neuyN6PilrMe+xIoqJVZ/45Uaq2sLsdJKXj73ytNc2DQzb4z29vZex09CrSQvbwA7gbGx/mOBNYW+\nOGvWrC4HqEd+t5mGG/6WSy72D7SKetf0Rp6d0/XAsGIFXHwJ3DyxtJPFurH1NNDSbaxC+hKvWBNH\naKShwPBST4R9Wba+rsc0ly3t9Ri9sjarZ+XKwiemaJ2XcrfuqBW9PcH31QfOrefOsA9s3ryOy2JX\n1ZfedQmXfeKKju4DDzyOO6MlLx/re+yeKv5nUXQ9AsyJlVCUcz3GY5VcGlLiNovvI0nGipfObdlS\n+DjStc5LAzM4K2+c1tbWoq+GSJKVrcZ7hZnZn4DHnHMXhG4DXgJ+6Jz7XjfjNwAt3V1d3XRToUeI\nG/nXSPmWLSutTkPhWOWN98Yb8JvfFHrCqDFnjuvSxBH6Vlej+LL1rNT1mOaypb0epfaUtbVRlUlz\n2Wp5PVa7SPLS6Jwr4Y1h5VErJS8A1wC3mFkLnU2lRwC3lDqhnh4jXugR4tC3E1NfH1nel3jx4uXu\nmzmWr4lj4fVY3hN8mk9PLXU9gpqLysChZELSUDPJi3PudjPbG7gcf7voSeBE59zrpU6r+HMMyndi\nquQjy0eOHNmlX7SJI/TvQFRs2ZJarvg262zdlMyzJ3qzHvVmXRGR8qmZ5AXAOXcDcEM5p5nmiSnt\nk26t6s2zJyDdK8SsPhlZkqHSifLQehy4aip5qZRynZiq8aRbLtHErLukDMqXmFVjoqCEU0SkfJS8\nlEG5TkzVeNItlzRLsJQoiIjUtkGVngHpNNBPurWcvImISPkoeSliyJDChVPFhkvvDfTkTUREekfJ\nSxE7d+7s13AREREpLyUvRfhn3fV9uIiIiJSXkpciDj30UMys4wPkdR966KEVnkMREZGBRRU2irjo\nootobm7u6J43bx4nnXRSR3eWX78+aNAgdu3aVXB4udTV1bF169aCw0VERHpDyUsRF154IS+//HJe\nv3nz5nX8/+STT5Y1gUkzoTj00ENZtGhRR7dzLu82WDlLlUaOHFkweemuKXV/pLkex4wZw9q1awsO\nFxGR8lHyUsSUKVNoa2vr6N62bRvDhg3LG15Oo0ePLngiHD16dNlirVq1qssD76Ldq1atKlus6667\nrksJ1sknn9zRXe4SrKFDhxZMloYOHVq2WOvXr+/XcBERKY2SlyImT57MU0891dHd1tbGnnvumTe8\nnAqdcHszvBRHHXUUDzzwQEd3PDE76qijyhbrlltuyYsFMH/+/I7/t27dWtYEZsiQIQXXVTmbuH/k\nIx8puB6PP/74ssUSERElL0UtW7aMdevW5fWLdi9btiztWSqbNBOzBQsWsG3btrx+0e4FCxaULRbA\npEmTCt4SmzRpUtli3XfffV1KsKLLdt9995UtloiIKHkpKlo6AL6lUTlLP+LOPvts7rjjjo7utrY2\nxo4d29F92mmnJRY7SVOnTi1YOjF16tSyxhs/fjxLly7Nixe9VTR+/PiyxRo2bFjBfSK6nCIi0n9K\nXopobm7Oq6sB0NTU1PH/tGnTynq7Y8GCBbz22mt5/aLd5SyhSLNU6ayzzsprUTRv3jxOPPHEju4s\nt9qaPHlywVKect9aFBEZ6JS8FPHII4+wcOHCvH7R7v3337+sJ97169cXrERbzsqfaZYqXXnllXkn\neIC777674/+VK1dmNoGp5eb0IiLVSMlLEe9973t58cUXO7rnzZvH0UcfnTe8nNJs3XTeeefl3aIC\nGDduXMf/p512Gtdee21ZYj399NN53WZWsClzfz3++OMF69g8/vjjZYuVdoIrIjLQKXkpIu0Sg7Tr\n2KQlzUQJ0m+aLSIi6VHyUkTatwTSrGOTZqlS2iVYaarlFmkiItXI4vUrBgozawBaWlpaaGhoKOV7\nXeqkJCnJePFEqbvSiaRKKLQeRUSyq7W1lcbGRoBG51xr2vFV8lJE2q2N4mr1rdVJL1ea2y0+LTNj\n7ty5ZZm2iIh0peSlyg0ePDixaVfypLvbbrslOv00l+3EE0/s8vTgaLPw448/vktdJhER6TslL0Wk\nfYKPlxjs2LEjsRKDNEsn4rG2bNmSaAlWmstWq5WsRUSqlZKXImr5qjrNxCweq7GxMdEkULdyRERq\nl5KXItJ+MmyaJ91K1ucp5xuru5Nm0+y0m4GLiAx0am1UZa2N0my5Ej/pdvcepaROuuPGjWPNmjWJ\nTLs7abZuSrsllYhI2tTaqMpVurVRkq699tq85GTIkCGpJRQTJkxIdPoqDRERqV1KXoqIJydDhgxJ\nta7GoEGDUqurkWTLpngS2NraWjNJYC0nuCIi1UjJS4ne9ra3JTr9+InQOZfaiTDNZtnjxo1LNClL\n84m+ereRiEi6lLyUKP6yv1oSre+SdWlWfI7ffqurq0u1Po+IyECj5KVESScv8ZPuiBEjUrttdNhh\nh6USB+Ctt95KLRb4229p2blzZ2qxREQGIiUvRcRv4+zcuTPV+gy1UtITX4/t7e2prsf99tsvsWnH\n1eorHUREqoWaSpfYVLquri7Vp6cOHTqU7du3JzLtSr5QMO2m0s3NzanVOznggANYsWJFKrFERCpB\nTaWrXLxAy50YAAAgAElEQVTJ7bZt21Jtcjty5MjEph1PTpqamvQU2jJI8/abiMhApOSliHhlzEGD\nBiVaYlDp2ytJiS9XW1tbqsuVZMlLdyVYtbDNRESqlZKXEiXZnLiWpf1uozTV8rKJiFQjJS8lSrrV\nSvxEOGrUqNROhGmWDiT9hN1KSvq9TSIiA52SlyLitwS2bduW6i2BNJsU19KtjUreykm7GbiIyECj\n5KWISldqHT58eGqx0pR0olTp7SYiIslR8lLlDjzwwErPQiJquZSnVipZi4hUKyUvVaaWX2BYSUnW\nQ0n7vU0iIgOdkpcS1fLtjjQf5FZLKt0MXERkoKlo8mJmK4Hoc9sdcJFz7qrIOO8E/hM4HtgI/Bz4\npnNuV2Scw4HrgL8BXgOuc859L4l5ruWTUC0nL0m2blLJi4hIuipd8uKAi4EbgdwLYTbmBprZIOAe\n4FXgWGBf4BfAtvA9zGx3YD5wL/Al4DBgtpmtc87dlM5iiHSq5WbgIiLVoNLJC8BfnXOv9zDsRKAe\n+JBz7g3gGTO7BPiumc10zu0ApgNDgXNC92IzOxL4GpD55KVWS0KSVsmm0kpeRESSVQ3JyzfN7NvA\nS8CtwCzn3M4w7FjgmZC45MwHfgQcCjwVxnkwJC7Rcb5hZqOcc+2JL0GCkn5kfq0+1r6SdYeyus5E\nRLKi0snLfwCtwFrgvcB3gXHA18PwcUBb7DttkWFPhb/LC4yT6eQlSXoWSjKUvIiIJKvsyYuZXQlc\nWGAUB0xxzi1zzv0g0n+RmW0DfmxmFznntpd73rozY8YMRo0aldcvyyUOIiIi5RQvpQf/PKtKSqLk\n5fvA7CLjxEtKchbi52ki8BywBt+CKGps+Lsm8ndskXF6NGvWLBoaGoqNJhmXZjJay622RGTg6e6C\nvrW1lcbGxgrNEZT9LYPOuTdDqUqhz44evn4ksAvf3BngUeAwM9s7Ms4J+FtBz0bG+aCZDY6NszTr\n9V3SVssn3LSTFxERSU6yr0guwMyONbMLzOxwMzvAzD4LXAP8IpJ03ItPUn4RxjsRuAL/HJfcbaVb\n8U2nf2pm7zKz04HzgavTXaLsq+XkRUREakfFkhdgK/AZ4AFgEXARPuH4Um6E8CC6k4CdwCP4B9Td\nAlwaGWcDvqRlIvA48D1gpnPu5uQXIXm6ihcREclXsdZGzrkngON6Md7L+ASm0DiLgKllmrWqovoT\n1a+Wm5yLiFSjSjeVFsk8NTkXEUlXJW8biYiIiJRMJS9VRrcgREREClPyUmV0CyL7lFyKiCRLt41E\nykzJi4hIspS8iIiISKYoealyuooXERHJp+Slyil5ERERyafkRURERDJFyYuIiIhkipKXKpfmu41q\nNZaIiNQWJS9VrlYTCiUvIiLSV0peREREJFOUvIiIiEim6PUAVSbNdxvVaiwREalt5pyr9DxUhJk1\nAC0tLS00NDRUenZ6lOa7jcaNG8eaNWtSiaV3NomIZFdrayuNjY0Ajc651rTj67aRiIiIZIqSFxER\nEckU1XmpcknWA4nXQ2lra0utHorqt4iISF+pzkuV13lJk+qhiIhIb6jOi4iIiEgJlLyIiIhIpih5\nKVEtP9Ze9VBERCQLlLyUSMmLiIhIZSl5ERERkUxR8iIiIiKZoue8FKF38oiIiFQXJS9FxJMTPQtF\nRESksnTbSERERDJFyYuIiIhkipKXEql+i4iISGUpeSmRkhcREZHKUvIiIiIimaLkRURERDJFyYuI\niIhkipIXERERyRQlLyIiIpIpSl5EREQkU5S8iIiISKYoeREREZFMSSx5MbN/MbOHzWyTma3tYZx3\nmtn/hHHWmNlVZjYoNs7hZvagmW0xsxfN7J+7mc7xZtZiZm+Z2TIzOzOp5RIpJvoWchERKb8kS16G\nArcDP+puYEhS7sG/2fpY4EzgLODyyDi7A/OBFUAD8M/ATDP7QmScicDdwO+BI4D/AG4ys4+WeXlE\nekXJi4hIsoYkNWHn3GUABUpBTgTqgQ85594AnjGzS4DvmtlM59wOYDo+CTondC82syOBrwE3hel8\nGVjunPtG6F5qZu8HZgD3JbFsIiIiUjmVrPNyLPBMSFxy5gOjgEMj4zwYEpfoOIeY2ajIOL+LTXs+\ncFz5Z1lEREQqLbGSl14YB7TF+rVFhj0V/i4vME57gensYWZ1zrmtZZtjkW40Nzfn3SqaN28eTU1N\nHd3Tpk3TCz1FRMqopOTFzK4ELiwwigOmOOeW9WuuejErCU9fpNfiyUlTUxNz586t4ByJiNS2Ukte\nvg/MLjJOvKSkJ2uAv4n1GxsZlvs7tptxXC/G2dCbUpcZM2YwatSovH66UhYREfHipcsA7e3tFZob\nr6TkxTn3JvBmmWI/CvyLme0dqfdyAv5W0LORcb5jZoOdczsj4yx1zrVHxvlYbNonhP5FzZo1i4aG\nhr4ug4iISE3r7oK+tbWVxsbGCs1Rss95eaeZHQHsDww2syPCZ2QY5V58kvKL8CyXE4ErgOucc9vD\nOLcC24Cfmtm7zOx04Hzg6kio/wQmmdm/m9khZvYV4O+Aa5JaNpFCVGonIpKsJCvsXg6cEeluDX8/\nhG9BtMvMTsI/B+YRYBNwC3Bp7gvOuQ1mdgJwPfA48AYw0zl3c2SclWb2cWAWPrF5Bd+0Ot4CSSQV\nSl5ERJKV5HNezgbOLjLOy8BJRcZZBEwtMs6DQOXKr0RERCQ1ereRiIiIZIqSFxEREckUJS8iIiKS\nKUpeREREJFOUvIiIiEimKHkRERGRTFHyIiIiIpmi5EVEREQyRcmLiIiIZIqSFxEREckUJS8iIiKS\nKUpeREREJFOUvIiIiEimKHkRERGRTFHyIiIiIpmi5EVEREQyRcmLiIiIZIqSFxEREckUJS8iIiKS\nKUpeREREJFOUvIiIiEimKHkRERGRTFHyUuWam5srPQsiIiJVRclLlVPyIiIikk/JS5VbtWpVpWch\nEUrKRESkr5S8VDklLyIiIvmGVHoGJF9zc3Peib2trY2mpqaO7mnTpjFt2rRKzJqIiEhVUPJSZeLJ\nybhx45g7d24F50hERKS6KHmpMrVa8hJfrnnz5tXEcomISPrMOVfpeagIM2sAWlpaWmhoaKj07PRo\n3LhxrFmzptKzUXZNTU0qURIRyajW1lYaGxsBGp1zrWnHV4XdKjdhwoRKz4KIiEhVUfJS5ZS8iIiI\n5FPyUuVqtR5IrS6XiIgkT8lLlavVk3ytLpeIiCRPyYuIiIhkipIXERERyRQlLyIiIpIpSl5EREQk\nU5S8iIiISKYoeREREZFMUfJSouj7eWotXq3GSjtercZKO56WLXux0o5Xq7HSjpf2spVDYsmLmf2L\nmT1sZpvMbG0P4+yKfXaa2adj4xxuZg+a2RYze9HM/rmb6RxvZi1m9paZLTOzM5NaLu3A2YuVdrxa\njZV2PC1b9mKlHa9WY6UdT8lLvqHA7cCPiox3JjAWGAeMB36TG2BmuwPzgRVAA/DPwEwz+0JknInA\n3cDvgSOA/wBuMrOPlmk5REREpIoMSWrCzrnLAHpRCtLunHu9h2HT8UnQOc65HcBiMzsS+BpwUxjn\ny8By59w3QvdSM3s/MAO4rz/LICIiItWnGuq8XG9mr5vZY2Z2dmzYscCDIXHJmQ8cYmajIuP8Lva9\n+cBxycyuiIiIVFJiJS+9dAlwP7AZOAG4wcxGOueuC8PHActj32mLDGsPf9u6GWcPM6tzzm3tIfZu\nAIsXLy5phtvb22ltbS3pO/2RZrxajZV2vFqNlXY8LVv2YqUdr1ZjpR2vL7Ei587dyj5DveGc6/UH\nuBLYVeCzE5gc+86ZwNpeTn8m8GKkez7wo9g4U0KsQ0L3UuDC2DgfC/NSVyDW3wNOH3300UcfffTp\n8+fvS8kjyvUpteTl+8DsIuPES0pKsRC4xMyGOue2A2vwlXmjxuJX2JrQ3dM4GwqUuoBPjD4LrATe\n6sc8i4iIDDS7ARPx59LUlZS8OOfeBN5MaF4AjgTWhcQF4FHgO2Y22Dm3M/Q7AVjqnGuPjPOx2HRO\nCP17FJbl1vLMtoiIyIDzSKUCJ/mcl3ea2RHA/sBgMzsifEaG4SeZ2TlmdqiZHWhmXwYuAn4Ymcyt\nwDbgp2b2LjM7HTgfuDoyzn8Ck8zs383sEDP7CvB3wDVJLZuIiIhUjoX6H+WfsNls4IxuBn3IOfeg\nmZ2Ir0NzIGDA88ANzrmboiOb2buB64G/Ad4Afuic+35snA8Cs4B3Aa8AlzvnflHmRRIREZEqkFjy\nIiIiIpKEanjOi4iIiEiv1XTyYmZ7mVmbme1XbfHM7EQzeyKNWP2N14dYU8zsZTMbnnS8NGPFxt+3\nL/EKTPcPZnZNrF8isSrJzM7s6V1nJU6ny/oq8fsrzOz8yDw5M2uqxDz1d1mKTPvS3v7uzWx2eBfd\n+UnMSy9iF9wGYT29nFtXZrY6vBNvjwTmpyOWmX3RzF4ysx2lrJu+bFczmxre8bdH6L7UzBaF5Tw8\nrKf/LnfcHqYz3Mx+bWbt0XnqZrwVpayXcqnp5AX4FvAb59xLAGa2v5nt6m5EM1ti/uWP+3Qz7A9m\n1l39nW7jAaPN7FYzWxV+kH/pZuP+B3BEqKjcl3gdy2ZmY8J3nPmXU74Udrrcyy53AXfin0wcr1M0\n28y+3dtY4TtXhVibzGxt+MFFY7UAewB5b/vqZaz4st1lZq+EeK+a2c/NbHyY3hfxTffHAWvNbKGZ\nXWBmu4Xhl5rZT0tctgtDrPbogTEcwP6Eb1o/CniyD7HymNl/mtnzZrYZeB/QZGaH5IaHFnE/Ay4v\nZbpV7r+AyZWeiZj/wj8/6n9L+VKpJ4nI7yR+Evgk/oGdSelX3YBSEqB+OB9f/7GUbXAEsL9zbgN0\nvOj3r6UG7mG7fBI4Bvh34Fp8/cx9gZ+UOv0iseP70MPA+NwyReS24fnAWeWchwLOxB+Xju1hniqq\nZpMX81fin6fzHUg5XX7IZvY+oA74FX3cMWLxGvFP+b0A/0C9fwWuNN8SKhrvz/gWVv2JRYhxb/h7\nMH6nOyoMm4w/uU8B5gHnmNmH+hELfBN7R/5LN10s1q3AJ8zs//Rz2e4HvhKW7VP4A9wdZjYH36Ls\nTuCf8E9b/g7QhG8q39dl2y0sy7+Gv8RiHQ98HJ/AfKq3sXrwOH5/qweeCv3mm5lFxrkF+KyZje5H\nHADMbGih7jQ457Y6594oNg9pzluYpyWRRzR0Nz9DzGxQbNuUyvD7VN40nHPrnXObSp5YP9dRid/v\nMQEqZTpmNrjbiTu30Tm3vNA26OY7rznnXo737u33o7NFbLuEbfIq8Hb88e6eEC/RZ4I553Y4517r\nYR5z6ymtJOJAYLFzbnEP81RZlXgyXhoffHPpNbF++wO7uhn3p/iT1YnAkm6G/wE4oz/xgOuA38Xi\nfRb/ozmglHi9WTZ8yY4D9oj0e2fo96+RfrOBb/clFuHpycBU/BONo7GGhnFu6G2sXq7Hk0OsXcBJ\nkVhb8C3ZAHYPfy8FftrHZcst05nRWJHxXgDO7m2sXuyvfwB+EWKtA1YDl0Zi/RNwF7ARn6jdBvwR\nf1V4LbA1fC6PTLMd/9DIn4X/1+Fb7O0I+8Eu/HObfgN8A3g2rMeV+De5/zV85yF8i7+l+Fd5bA6x\n2vEJ+PlhvEuBJ/BXxLuAf8Mn8Lm4j+IfCOmAp4FXw/7zRIixnc6ndr4VtsEw4AfAptB/K/639Ad8\nQrkfMDdM56/AM8Df4hPM9cAvgdcjy7wJ/3Tt1aG7OWxjF5ZjF3Bj6L4vMj+b8Y9t+BTwYNg34k8a\nfSRswxfCdBywAfgqnftVdPxc93ZgGf64sCFsg5ci62pb+PtUWJZc7Dcj62xXGH9d+P6LwB3h767w\ntx24jM794Vb8Bc32EGNHGHdTWJdbYtPPzW878L3w/8awTc7AX7S4SP/28P/SsF22hm2e+/3mYj4P\ntIZxm8K+e0jo3hGZ5lb8ReE1YZx1kXXc3fZYF+JcjN9PN4T154BVYRrHdrNNbsXvX2/GtlNuv3Rh\n3dwDHITf9x7B70frgO+G9bYD/1uaHeZ9F34/+g1+f5hN130itxwzwvz9d2R9rQjTfSVsw1XAy2Ha\n20L318K8/wD/UNlXwjz/NWzX1fjfxNuBU4FFdB4HvhY5dvw5tt3vD/3fjt9nNuP3878P83V+5Lsz\n8L/vv+L34+uBkWHYCPx+8anY8e+UMP7I3h4za7bkBXg//vZFXF5mbmZvA07DH3TuA0aFkpEev9PH\neKPwtzai8ZrxO8bnS4xXMJb5OhIfoOtV3qHh7674d/oaKyYa68Phb/SqrF/r0czG4BO+dfgk824A\n56/WnsQvM865jb2IUzBW5P/TorEiFgIfKCFWMYNCrHX44upvAN82sw+HWP8CjMYv40eASfjteQb+\ngHY3/uT2NTM7JzLdd+LXzUfw++BI/MHjf/FJwP8B9sYn09/CP25gb/xTqi/BH9x/gj8ZnYE/GD2C\nTwxuwB+oFwJvA8bj191U/Eni+DAPDhiDv5X4l9Bvf/wB8pf4K7z34PefR/EH0pYwjz8HPh3meRr+\noPz/6CxZvAGf4LwfeDdwIf4g+BCwO/7Bl0uB18IytOFL8nIvdn0oth2i2/4D+BPQYvzJ6jb8SWMF\n/oSwA39C/DP+5PGeMI974d92/3/Dd78U1tupYbqb8L/BbwBXAYPD+nk4zC/47XYXcBI+8QBfQjcc\nn7SC3x+WhnXWji/NfTZM/2J8ojUo9DsdX6r4Tfz+8B789pqA377n4Pc9CzGG4Nf/NvyJyOFPSrkT\n+BfD/58O3YPwJ9rcOlwDPBe6J+CPA6+E5bw1jNOCT6a+hE8Cor4V+f+HwGNhGvuE5YTOEpP34pNV\n8Cf6d4V1NSusi6lhfRwO/D6M89dQivYj/D65C3+r6Kkwv+BP0L8Lcb4JPBCWoQ1/wWBh+C78dhuG\nPzl/FvgtPil/J/CZsG4uCvM+Mgz/WoixHv97mYlPdgC+ZWafiyynAV8P8cbjT/Z/wu+/68J438f/\n5hrwx99j8NvnYvzvbBB+398/zM9t+G1xdZiPKyLVFR7HJ5qP4I8Fnwr9fxbWz1T8xd9X8AlN1E7g\nvLAdzgA+hL/9hnNuM/42bfwlzGcBt7tSSiD7eqVY7R98Ef+NvRjvXKAl0n0NfbiCLhQP/+PaGnao\neLy2aHd/YoUdMXdgfCj83YA/aG/Dn+RWAZeUabnOpLPkpbtYi4Cb+7ts+BPkX0OMh/EnhDtj4/y6\nHLEiw3IlL11iheFXA78vw3765bDOcqUCB0SGPYYvvbgjLPu+kWG5q9znQ/ds/AHpSmBR6NcOvBb+\nPzKM/yLwbGwensOfgD4C7BmW+yfAw93MbzvwOXxJ0MJI/8fxB+TWMB/fxJ/wv07nFfIx+FKLXfin\nYm/Hn7xz23YN/qT57/iDZq6E4y0iV2r4K8tt+N/qUz3tzyHuk2Ha90fmKVcy5ML/0ZKXnXSWvPwy\ndL87zFMb/mT3fIj/DP5AvCNsp9w0PxSZh3eE/geFfcqFfWod/iQ2KHz/L2H8g+m8Cj869DuJzhKY\nx+lMIraGdTcUn9DswN86fS6suzvD/D8RpvNqmJdh+Fu8u4CG2G/I4U+km0O/2/DJyxo6r9Lb8KUO\nu/AJwbqwXpbQeaV+Fv5458I62olPIC/DXyTeQ2Q/BBaEcZvCesmVcNwShu9JZ+nbgtBvdYi1R+jO\nrf8RoXs8fh9bH9bREPzxamf4nERnadpOfHKde3fen/GlGn8I0zwh9D8GnyTMxSdiW/HH2lZ8adRO\nfGnnOeG7a4Dtsd/0d8OyfCNMcz1wehj+uRDvJ/hj3X/TWSLzPvzxewv+mLFXWE+fwieaN4T1tDmM\nPy72e7gPv38cFeLeG1lP2/CJyTNhPb0Wpnl/5PsH03WfOST0O7+732AY51TCcSh0/02INzZ0vz10\nv7+UY2ctl7wMp3fvLDobmBPpvhX4tIUnAfc3nvmH7P0GmOmc+3038VYDh5UYr6dl+0f8SaqJzquH\n9+MP0EcAX8Bn0e8tQ6w4102sQ4DDSojVU7yr8FeKH8X/KN/Rzfe24K96+hsrrqc6Dn2J1505+GV7\nAn+gu8PMhoVhq/FXmrsD25y/Bw+Ac24x/mQVv+f/KHBwpG5GrmToKfxJ5h1AfajYvdHMNuJPrHX4\n0puX8Aejc4FGMzvfzMaZ2elm9kf8yfbn+G0yxcwmhekvwL/nBHyJxX/jT9KT8CeOHc65x8LwnfgD\n82D8AfgN/HreO8zjBfgSn+NCvDrg55H5fS/+pA3+qvwSM/ujmc00s+j+dj+d+9+x+JPKYvxvILfd\nV9CzF/DrfRF+W4zCn5QPDMv0bnyJxmB8QpEzNzKvi/G/jQMjwx/BJ5Er8HWaduFPquBLDHKlP7nG\nA7ltOARfWpHb/4fiT/Tb8Ce2wfgSi4Pwv8VT8Ovv8DAv48K0DwhxtjvnWiPbNvealb0i87o6xNiE\nP3nlPBNbV/vR+cBRw98qmBeGrQ9/98ZvkyPwiU19ZD3lSruH0rl+wZc+4Zxbhy9l2opPGnLrw4BF\nZraBzt/qfuE7q/FJ0m7438Wr+JN7bv0eg//9dLzyJvyu1odlzi0/+PqQue34KH79rsMnCm/iS2Xq\n8ceFifjEhbDehkSWswFf4lIX/t+K369uDsN/HL53Jn47gd8/DF9SPwS/76yks0RrIT6h3Cesp1fx\n231ZiLvJzHbgL04uDPNq+H0zup7ejt/GTfgEN1dyljOFsM9E1tdSOrcvAGb2ETP7XWhosQF/l2Gv\nXOMG59yf8aWBZ4avfA5Y6Zz7IyWo5eTlDfyO2iMzm4I/qF1lZtvNbDt+xxyOL+rrVzwzexe+mO8/\nnXNX9hDvCPwOWUq8bpfN+Qply5y/xXE1fgfd5HxFuMXOuZ/hS0eO7W+sHqyMxXoVv8OXoks859xa\n59zzIfmbhr9F8Z7Y98bgrxj7Fasbz+MPSnF9ideF8xXwXsCXaMwLsT6ZG4z/jY7En/ALyR3goiz3\nPefcLnwC8wL+6i136yN3pXcB/oroCHzS+XF8sfvp+HXwS3xyMxV/4vkt/qTwrJl9An9A3A//29nm\nnFuGT2gOwe/f0SQxfvswd7X++xD/Knzx/Aw662GcQGdiPCUMxzl3M/4g/3N8MvFnM/uHMN1b8CeT\nnZHunfhi7Nx73aLrLP6ut63h+7l5ziVuuZKRv+BLxY7Hl0DklvE9kXk9An9CeDAy3S34E9dn8L+R\nIfhEMd4Kqbvj8yb8eofOW2FTw/8On7Acj9++s8NnSZiPVfgr7xdyEzOzY/EJ9N34K/Pt+EQqFzt+\n6zm37XLF+4Y/gdbhS7ly6+bv8LfDc40Jot6GT2430LmO7gzDelVh18xG0JnEnIMvTcjN27DIqD8P\n8zYeX69oK+EWBr17t19u//tRmP5l4fu74xtmvA2/rhfQeaxb5ZzLvaA4tx4Pxy/n/fiEbDK+FC3n\nC2F4rgrBpfjknchy/U9Y5t3oup5y+2cu5i78PnYMfr+ci7+F9AE6jy/RytM3hWHgE/TbKH7M6cLM\n9scfx57Elwg1ALnfY3S73ERn45iz8PW9SlLLycsT+HtuhZyD3+lyO1buMysM63M8MzsUv6POds7l\nmgfH4x2F3wnvKDFeb5Ytt21z94cxszp8ll9Ki4nexOrJGHpXz6WUeIPDNPczs5Mj/d8dvks3J4G+\nxgK/bSbHYnXEKyFWb+SuWuti/UcBu5nZhI4RfWI8hM6r8NfxB+jjgOecL48dRlcr8QnG0fiD2gH4\nk9ruzrlnQvK53Dl3j3PuIufc+8K0Nzrnvuuca3XO3Y+/It2IPwmdjS86r8PfT18QYj2A39eHAsPN\nbFxkPo7DHxzfxJ/MDagLB/038SeN+fj9eCe+qebyMHwdvkQHAOfcKufcT5xzuXeanRsGPYQ/0A8O\n8/SP+BPM34Z5cmGd5UyisK1hfeVuV+wAVjvnFuAT4dzJcGJkPeY+W/AlJOCfbL7LOXe/c+6bYbq7\n4esfLabr7zO3j+0If3N1YEbjt+XK3Pecc3eF+XkUv2+8CGwN620H8KZzbgc+oRmCP6GtdM59Nwwf\nSuctlhyHP0k/h98XBtNZ8tWIL4F8EX9CziUvq+gstcglgC/iE99W/HrfFdmm0SbOL0SW9RQAM9sz\nTL8On1zV4/cNBzwWkuXuHoOxMvwdh79o20pnicJyfJ2U3PodHH5Xo+lMznLuxm+XL+CT9Jfwt04H\n4xPTB0P/oXTu/9BZKvF6WM7N+N/ScvwJvi7EOjD0y/1m/+icezEyHYdPoB4P8/y2yHo6JjdSWE9j\nw7yOxe9Xo4HznHN3OOf+FPo78i8A7wn91uJ/HzfT1RJ8KVJjJN4hYfo5jfj98OvOuYXOuefpvAsQ\nNQfY38zOw/8mf97NOAWV9FbpjJkP/JuZjXKdb6DuYGZD8FedF4eiwuiwm/AVH6fEh/UmHn7nuh9/\nz/AHZjYWv5OfAXwrN00zOx7/w/5X/HNDehsvb9nM7GP4HfLP+IPAu/FFkwDbQ/w6/EkmWrGupOXK\nrUczeyc+Mdk/LFeuuHiimbWFWB/H/8Cau51qL+Lhr9r/Bn8/fx2+OPxy/MHnCaDZzP4Vf09+X3yl\n3t/hbyXM7eOyjcUf6A4Oy/QC/soxF+te/BXj0fgTR0svY+UxswPwpRr34k8Ie+DvwW/GH0hycuv3\neeCXZjYDf4C8PqyTfczs+/hSgH/GJ8WXm9lMIpWlzexo/MF1If6A+gj+tsSb+G10abjT9DC+BUEb\nPml4BL+tR5jZdPytu/X4q6oh+O1zh3NuvZktwSeDw8LtpIPxtwrAH6B/hi9FMnxruNtC/634E8lR\nZvbJEK8Of6/8AXySf32kSe4lYRqY2Sz872xZ+N6H8EXS4EtuXsQnHEeE2CvD/+C340w6K21/gsLW\n429ZPRbW3RRgbLg1vHdYX4a/bXQJ/vd4DL7i7ofDvDjgGDP7Jv7Wwmo6r4CXOOeeN7M3wvT+KWyT\n3LoT/ZEAAAYESURBVItod+GPLW+E/weH5b6HcAvAzB4K/z+GL8E6HFhnZgfhk4xT8e+HW2Zm8/G3\nCPYL8/PBMN2RwKCwX43Gn1D3wZ883x2+MxZ/6+hq/AXYG2G8XEKxL/73Owi/XQxfH2sWvgTsi8AO\nM/sO/kQ2MbeSnXObzOw2/PH5s+HWw1H43xv4ff2l8L/hT4IH0Hmh9JFwC2ZNWOc76Hy8w0P4uk+E\ndbQIX5E2V/r4CfKTjwkhxgh8ydStYZkW4X+/G4G5zrmdZrYa/xuLfv8VfJJwl5ldGqZTZ2b/gS/B\neRN/nLzY/POrcrfu3m1mR0Wmk0tol+D351wl95vxdW2W4n/vs8PyLsEnBJfht8+VYf624Ev8cvvh\nxfjf4Xvxic5uwDLn3EIzmxaJT2Sf+Yn555PtxG/PzZHRngeGmn+u2Tz87bUvEROOF3eGeZ8fvSXe\na6VUkMnaB3/1cW4Pwz4VNurbexi+CPh+D8NuIVKRKR4PX+S3s5uPi8bDvxH7hr7Eiy4bvpj4YXzW\nvAm/4/4iFjvXtLUVGF5gnc0EVhRaj/gfSHfLFo31Jv7EX1Ks2Hp8N/5Wwut0Ns27Dn8VDv4A+KcQ\nbzv+xHwhsFsP8c4i1lS+m2W7FH8Ajy/fT0OsjXQ2Iy0pVmz4eHwx8Gp8Cchb+JPuwZFx7sSfvJ/F\nX0XfiT/hrscnHLmm0teHfpvC/K3FVypsxx+IwF+pvhnGybVw2BD+fw5/YH4yLNfWMD+5pOLb+EqG\nr+FLD/4a/u7Et/4ZFmLMCuvulTDt2fgr8F34/e5LYZq5Spyjwvpuxe/jz4ZtnGtm+it8nZXv0Fmp\neSf+9tdj+FKWH+JP4JvxJ6vZwJ5hfr6FP6nmKrvuwJ/0Vob/rwnLnJunK8mvsPstYG2Y1gVhXTTi\nb5ltpmsz18Uh/lI6fxNbgf+NbNMXIt/NNWHdBTwTGefByDy7sD5yt/1ep7NC/PVhnnZE4r0Vhm/E\nHwfeCMM2hHmZG4mzDz7x3h7G2RE+r4XpXB+Z3l/orOya2z+W449bDn/r5NTIOtmC3w9yrXhyFWLP\nDds51wR6Gz4Jz932aorsr47CTaXXhv6b8b+FmbHt8e0w3lcj/Z7AX1jtxCd2ud/VW3TevrwVf/H5\nMj4xzpVI/BX/G9oYls8B/xJZn78N/Q4O3blbRDvx+0VbWJ52/LH/bfiTe65Jdm7/dmEf+AT+QjO3\nfQ8P03k2rNv1+GP/z8I23IIvDbof/1u8lFBvK7JtWyPL/4/4BPStsP2uCMv/tcjvOX7eye0zm8N3\nPovfD6JNpS8I8/dXfGL92dz2j03rQyHep7o7RhY9v/flS1n54K94FiUw3QfopoVDKfHwleJexz8h\nsuR4pS5bb+PhTyI39zPWUPwJ4thSY/VhPfYqVhh3Zjc/xpL3EXzCc3qpsfq4r/UYi/Csk/7GSPoT\nDqKtlZ6PrHzi25VunqOUZvwKrYP9wzIfXoZpfQB/cn+mv9Oq5U9YT2/RwwV9AvE+h09ah/Tl+7V8\n2wjn3D1mdpCZTXDOrSrHNEMdh0n4k15/4k0EvuLy72v2Ol4flq1X8fAHyrzn3PQh1n74B+H9qdRY\nfYjX21jg7+X+Q7RHqctmZnsBv3bO3VZqrFKVEEtqX3+e7JtV/Vpm86329sffPtuBL0mQmLCe9sFf\nZNzunOt3Q4Qi8YbjbyteiG/MsqPIV7qfTsiARCRjzOx+4Enn3NeKjpzsfCzCnyTiHP5W0WTgE865\nhgRiv5/Oov34yc4558r+0r6k5ym+Xc1sKv5WwJ6uH4+GD/VAup0n4GPOuYe7i18JodXKcuBI59zT\nfZzGmfjbLOAfV3GqK9MJL9T7e5ae1+e7nHOvlCNW0sJ6uhl/S+kTzjedTjLepfhbsg8Apzj/4LrS\np6PkRUT6IxzIe3q/TZvrw3t7SohdR/etGQBwnU1WU1ON8wRgnc/k6c4q59zW1GYm48y/o6m7hD1n\npfOPJ5CEKHkRERGRTKnl57yIiIhIDVLyIiIiIpmi5EVEREQyRcmLiIiIZIqSFxEREckUJS8iIiKS\nKUpeREREJFP+P7OLHBpPnvU1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1208bf908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sel_rows.plot.box()  # box plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('A', 2)\n",
      "1 ('A', 3)\n",
      "2 ('B', 1)\n",
      "3 ('B', 3)\n",
      "4 ('C', 1)\n",
      "5 ('C', 3)\n",
      "6 date\n",
      "7 hour\n",
      "8 pressure\n",
      "9 sea_pressure\n",
      "10 wind_direction\n",
      "11 wind_speed\n",
      "12 temperature\n",
      "13 rel_humidity\n",
      "14 precipitation\n",
      "15 dayofweek\n",
      "16 is_holiday\n",
      "17 timeofday\n"
     ]
    }
   ],
   "source": [
    "# Create one-hot for hour\n",
    "\n",
    "# for i in range(24):\n",
    "#     sel_rows['{}:00'.format(i)] = np.where(sel_rows.hour == i, 1, 0)\n",
    "\n",
    "# Check all the columns\n",
    "for idx, i in enumerate(sel_rows.columns):\n",
    "    print(idx, i)\n",
    "\n",
    "# select using columns\n",
    "\n",
    "using_cols = [\n",
    "#                 \"(1, 0, 'cargocar')\",\n",
    "#                 \"(1, 0, 'etc')\",\n",
    "#                 \"(1, 0, 'motorcycle')\",\n",
    "#                 \"(1, 0, 'privatecar')\",\n",
    "#                 \"(1, 0, 'tot')\",\n",
    "#                 \"(1, 0, 'unknowncar')\",\n",
    "#                 \"(1, 1, 'cargocar')\",\n",
    "#                 \"(1, 1, 'etc')\",\n",
    "#                 \"(1, 1, 'motorcycle')\",\n",
    "#                 \"(1, 1, 'privatecar')\",\n",
    "#                 \"(1, 1, 'tot')\",\n",
    "#                 \"(1, 1, 'unknowncar')\",\n",
    "#                 \"(2, 0, 'cargocar')\",\n",
    "#                 \"(2, 0, 'etc')\",\n",
    "#                 \"(2, 0, 'motorcycle')\",\n",
    "#                 \"(2, 0, 'privatecar')\",\n",
    "#                 \"(2, 0, 'tot')\",\n",
    "#                 \"(2, 0, 'unknowncar')\",\n",
    "#                 \"(3, 0, 'cargocar')\",\n",
    "#                 \"(3, 0, 'etc')\",\n",
    "#                 \"(3, 0, 'motorcycle')\",\n",
    "#                 \"(3, 0, 'privatecar')\",\n",
    "#                 \"(3, 0, 'tot')\",\n",
    "#                 \"(3, 0, 'unknowncar')\",\n",
    "#                 \"(3, 1, 'cargocar')\",\n",
    "#                 \"(3, 1, 'etc')\",\n",
    "#                 \"(3, 1, 'motorcycle')\",\n",
    "#                 \"(3, 1, 'privatecar')\",\n",
    "#                 \"(3, 1, 'tot')\",\n",
    "#                 \"(3, 1, 'unknowncar')\",\n",
    "#                 \"('A', 2)\",\n",
    "                \"('A', 3)\",\n",
    "#                 \"('B', 1)\",\n",
    "                \"('B', 3)\",\n",
    "#                 \"('C', 1)\",\n",
    "                \"('C', 3)\",\n",
    "#                 'date',  # <== Notice this\n",
    "                'hour',\n",
    "                'pressure',\n",
    "#                 'sea_pressure',\n",
    "#                 'wind_direction',\n",
    "#                 'wind_speed',\n",
    "                'temperature',\n",
    "#                 'rel_humidity',\n",
    "                'precipitation',\n",
    "                'dayofweek',\n",
    "                'is_holiday',\n",
    "                'timeofday',\n",
    "#                 '0:00',\n",
    "#                 '1:00',\n",
    "#                 '2:00',\n",
    "#                 '3:00',\n",
    "#                 '4:00',\n",
    "#                 '5:00',\n",
    "#                 '6:00',\n",
    "#                 '7:00',\n",
    "#                 '8:00',\n",
    "#                 '9:00',\n",
    "#                 '10:00',\n",
    "#                 '11:00',\n",
    "#                 '12:00',\n",
    "#                 '13:00',\n",
    "#                 '14:00',\n",
    "#                 '15:00',\n",
    "#                 '16:00',\n",
    "#                 '17:00',\n",
    "#                 '18:00',\n",
    "#                 '19:00',\n",
    "#                 '20:00',\n",
    "#                 '21:00',\n",
    "#                 '22:00',\n",
    "#                 '23:00',\n",
    "              ]\n",
    "\n",
    "sel_rows = sel_rows[using_cols]\n",
    "\n",
    "# split to train and valid set\n",
    "train_rows = sel_rows[: -24*3*7]\n",
    "valid_rows = sel_rows[-24*3*7:] # reserve 7 days for validation\n",
    "\n",
    "# get numpy array from panda dataframe\n",
    "train_arr = train_rows.values\n",
    "valid_arr = valid_rows.values\n",
    "\n",
    "# np.shape(train_arr)\n",
    "# Out:\n",
    "# (726, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summary Stats\n",
    "\n",
    "# train_arr.mean()\n",
    "# train_rows.loc[abs(train_rows[\"('A', 2)\"] + 814.225)<0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scale feature array to range -1 to 1\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler = scaler.fit(train_arr)\n",
    "train_scaled_arr = scaler.transform(train_arr)\n",
    "\n",
    "valid_scaled_arr = scaler.transform(valid_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' save the scaler to another file use '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' save the scaler to another file use '''\n",
    "# import pickle\n",
    "# scalerfile = 'scaler-A-2_phase1.sav'\n",
    "# pickle.dump(scaler, open(scalerfile, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample subsequence from the time series\n",
    "train_seqs = []\n",
    "len_seqs = len(train_scaled_arr) - 6 + 1  # 6 is window size\n",
    "for i in range(len_seqs):\n",
    "    train_seqs.append(train_scaled_arr[i: i+6])  # append 6 timestamps each time (5 timestamps for x, 1 timestamp for y)\n",
    "train_seqs = np.stack(train_seqs)\n",
    "\n",
    "valid_seqs = []\n",
    "len_v_seqs = len(valid_scaled_arr) - 6 + 1  # 6 is window size\n",
    "for i in range(len_v_seqs):\n",
    "    valid_seqs.append(valid_scaled_arr[i: i+6])\n",
    "valid_seqs = np.stack(valid_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0026405 , -0.0402932 , -0.02030946, -0.82608696, -0.48043818,\n",
       "         0.28063241, -1.        , -0.66666667, -1.        , -0.83098592],\n",
       "       [ 0.0026405 ,  0.01570016, -0.02030946, -0.82608696, -0.48461137,\n",
       "         0.31752306, -1.        , -0.66666667, -1.        , -0.8028169 ],\n",
       "       [ 0.01286327,  0.01570016, -0.02030946, -0.82608696, -0.48878456,\n",
       "         0.3544137 , -1.        , -0.66666667, -1.        , -0.77464789],\n",
       "       [ 0.01286327, -0.0381565 , -0.02030946, -0.73913043, -0.49295775,\n",
       "         0.39130435, -1.        , -0.66666667, -1.        , -0.74647887],\n",
       "       [ 0.00672961, -0.0381565 , -0.02030946, -0.73913043, -0.50130412,\n",
       "         0.3921827 , -1.        , -0.66666667, -1.        , -0.71830986],\n",
       "       [ 0.00672961, -0.0381565 , -0.02030946, -0.73913043, -0.5096505 ,\n",
       "         0.39306105, -1.        , -0.66666667, -1.        , -0.69014085]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking\n",
    "train_seqs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keras\n",
    "#https://keras.io/getting-started/sequential-model-guide/#examples\n",
    "input_dim = len(using_cols)  # The features\n",
    "output_dim = 3  # \n",
    "timesteps = 5 # use 5 timesteps to predict the 6th\n",
    "\n",
    "x_train, y_train = train_seqs[:, 0:-1], train_seqs[:, -1, 0:output_dim]  # 0:output_dim is for deciding the output features\n",
    "x_valid , y_valid  =  valid_seqs[:, 0:-1],  valid_seqs[:, -1, 0:output_dim]  # 0:output_dim is for deciding the output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6038, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "loss_fuc = 'mean_squared_error'\n",
    "\n",
    "# construct the callback\n",
    "filepath=\"best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(output_dim))\n",
    "model.compile(loss=loss_fuc, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 5, 128)            71168     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 203,139\n",
      "Trainable params: 203,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6038 samples, validate on 499 samples\n",
      "Epoch 1/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0019Epoch 00000: val_loss improved from inf to 0.00129, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 7s - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 2/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0017Epoch 00001: val_loss improved from 0.00129 to 0.00124, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 3/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0016Epoch 00002: val_loss improved from 0.00124 to 0.00120, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 6s - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 4/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0016Epoch 00003: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 5/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0016Epoch 00004: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 6/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0016Epoch 00005: val_loss improved from 0.00120 to 0.00116, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 6s - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 7/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0016Epoch 00006: val_loss improved from 0.00116 to 0.00111, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 6s - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 8/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0015Epoch 00007: val_loss improved from 0.00111 to 0.00111, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 6s - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 9/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0015Epoch 00008: val_loss improved from 0.00111 to 0.00109, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 6s - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 10/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0014Epoch 00009: val_loss improved from 0.00109 to 0.00105, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 6s - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 11/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0014Epoch 00010: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 12/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0014Epoch 00011: val_loss improved from 0.00105 to 0.00104, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 6s - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 13/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00012: val_loss improved from 0.00104 to 0.00103, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 7s - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 14/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00013: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 15/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00014: val_loss improved from 0.00103 to 0.00102, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 6s - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 16/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00015: val_loss improved from 0.00102 to 0.00101, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 6s - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 17/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00016: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 18/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00017: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 19/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00018: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 20/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00019: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 21/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00020: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 22/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00021: val_loss improved from 0.00101 to 0.00100, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 23/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00022: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 24/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00023: val_loss improved from 0.00100 to 0.00099, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0013 - val_loss: 9.9405e-04\n",
      "Epoch 25/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00024: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 26/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00025: val_loss improved from 0.00099 to 0.00099, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 6s - loss: 0.0013 - val_loss: 9.8986e-04\n",
      "Epoch 27/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00026: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 28/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00027: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 29/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00028: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 30/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00029: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 31/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00030: val_loss improved from 0.00099 to 0.00098, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0013 - val_loss: 9.8348e-04\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00031: val_loss improved from 0.00098 to 0.00097, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 6s - loss: 0.0012 - val_loss: 9.6872e-04\n",
      "Epoch 33/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00032: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0013 - val_loss: 9.9389e-04\n",
      "Epoch 34/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00033: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0012 - val_loss: 9.7724e-04\n",
      "Epoch 35/100\n",
      "5952/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00034: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0012 - val_loss: 9.8069e-04\n",
      "Epoch 36/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00035: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0012 - val_loss: 9.6982e-04\n",
      "Epoch 37/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00036: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0012 - val_loss: 9.7857e-04\n",
      "Epoch 38/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00037: val_loss improved from 0.00097 to 0.00095, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0012 - val_loss: 9.5372e-04\n",
      "Epoch 39/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00038: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 40/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00039: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0012 - val_loss: 9.5947e-04\n",
      "Epoch 41/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00040: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0012 - val_loss: 9.8136e-04\n",
      "Epoch 42/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00041: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0012 - val_loss: 9.6399e-04\n",
      "Epoch 43/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00042: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 44/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00043: val_loss improved from 0.00095 to 0.00095, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0012 - val_loss: 9.5092e-04\n",
      "Epoch 45/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00044: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0012 - val_loss: 9.8097e-04\n",
      "Epoch 46/100\n",
      "5952/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00045: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0012 - val_loss: 9.5289e-04\n",
      "Epoch 47/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00046: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0012 - val_loss: 9.8408e-04\n",
      "Epoch 48/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00047: val_loss improved from 0.00095 to 0.00094, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0012 - val_loss: 9.3553e-04\n",
      "Epoch 49/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00048: val_loss improved from 0.00094 to 0.00092, saving model to best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0012 - val_loss: 9.2090e-04\n",
      "Epoch 50/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00049: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0012 - val_loss: 9.2868e-04\n",
      "Epoch 51/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00050: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0012 - val_loss: 9.6122e-04\n",
      "Epoch 52/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00051: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 53/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00052: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0012 - val_loss: 9.7002e-04\n",
      "Epoch 54/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00053: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 55/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00054: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 56/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00055: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0011 - val_loss: 9.9422e-04\n",
      "Epoch 57/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00056: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 58/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00057: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0012 - val_loss: 9.3896e-04\n",
      "Epoch 59/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00058: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.8505e-04\n",
      "Epoch 60/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00059: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.4757e-04\n",
      "Epoch 61/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00060: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.4146e-04\n",
      "Epoch 62/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00061: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.8998e-04\n",
      "Epoch 63/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00062: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.5887e-04\n",
      "Epoch 64/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00063: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.6798e-04\n",
      "Epoch 65/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00064: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.4475e-04\n",
      "Epoch 66/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00065: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0011 - val_loss: 9.7786e-04\n",
      "Epoch 67/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00066: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 68/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00067: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.4728e-04\n",
      "Epoch 69/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00068: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.4110e-04\n",
      "Epoch 70/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00069: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.7254e-04\n",
      "Epoch 71/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00070: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0011 - val_loss: 9.2824e-04\n",
      "Epoch 72/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00071: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 73/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00072: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.8797e-04\n",
      "Epoch 74/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00073: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 75/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00074: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.5638e-04\n",
      "Epoch 76/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00075: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.8146e-04\n",
      "Epoch 77/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00076: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 78/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00077: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0011 - val_loss: 9.8235e-04\n",
      "Epoch 79/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00078: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.4839e-04\n",
      "Epoch 80/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00079: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0011 - val_loss: 9.6586e-04\n",
      "Epoch 81/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00080: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.6486e-04\n",
      "Epoch 82/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00081: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.7516e-04\n",
      "Epoch 83/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00082: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.5428e-04\n",
      "Epoch 84/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00083: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.7329e-04\n",
      "Epoch 85/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00084: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 86/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00085: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 87/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00086: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.9003e-04\n",
      "Epoch 88/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00087: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.3550e-04\n",
      "Epoch 89/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00088: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0011 - val_loss: 9.2839e-04\n",
      "Epoch 90/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00089: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.7825e-04\n",
      "Epoch 91/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00090: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.4816e-04\n",
      "Epoch 92/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00091: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0011 - val_loss: 9.5124e-04\n",
      "Epoch 93/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0010Epoch 00092: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 94/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0010Epoch 00093: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 95/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00094: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 96/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0010Epoch 00095: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0010 - val_loss: 9.5020e-04\n",
      "Epoch 97/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0010Epoch 00096: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0010 - val_loss: 9.5545e-04\n",
      "Epoch 98/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0010Epoch 00097: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0010 - val_loss: 9.3465e-04\n",
      "Epoch 99/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0010Epoch 00098: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0010 - val_loss: 9.4278e-04\n",
      "Epoch 100/100\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0010Epoch 00099: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0010 - val_loss: 9.8884e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj0AAAGHCAYAAABbKOOPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w+NAZC2d2VoeQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12331b7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Start Training\n",
    "model.summary()\n",
    "history_w_model = model.fit(x_train, y_train, callbacks=callbacks_list, epochs=num_epochs, batch_size=64, validation_data=(x_valid, y_valid))\n",
    "\n",
    "plt.plot(history_w_model.history['loss'], label='loss')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.plot(history_w_model.history['val_loss'], label='Val_loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Save Model '''\n",
    "\n",
    "# serialize model to JSON\n",
    "\n",
    "# model_json = model.to_json()\n",
    "# with open(\"model_T.M._A-2-p1.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Load the saved model '''\n",
    "\n",
    "# load json and create model\n",
    "\n",
    "# json_file = open('model_500x5_300e.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "\n",
    "# loaded_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# Notes: last best model: 0.00175\n",
    "# load weights into the model\n",
    "model.load_weights(\"best_epoch_T.M._A-3_B-3_C-3_phase1.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 189.76230842  102.92072854  199.88587807]\n",
      " [ 190.71537439  111.99255937  192.09726386]\n",
      " [ 190.98300172  117.40483576  184.06633648]\n",
      " [ 191.17691741  121.74286434  188.73161163]\n",
      " [ 190.78629881  125.20246383  194.43114512]\n",
      " [ 190.23984751  130.11915866  198.34170979]]\n",
      "[[ 131.68275254  106.89113349  167.75714713]\n",
      " [ 131.99229391  113.01360255  164.93915209]\n",
      " [ 129.92571547  118.47794804  165.53933439]\n",
      " [ 127.6297513   121.53683276  166.32552021]\n",
      " [ 125.96652178  123.99866974  170.063499  ]\n",
      " [ 124.94256212  129.72110715  167.12908389]]\n",
      "[[ 194.47226809   95.73927876  143.06877506]\n",
      " [ 191.7626275   103.90176448  139.9163177 ]\n",
      " [ 193.65591198  111.03996664  139.10819881]\n",
      " [ 195.6153882   116.773319    139.28221229]\n",
      " [ 196.42687304  119.95258326  139.78382985]\n",
      " [ 196.71088115  123.7312547   143.54606834]]\n",
      "[[ 110.16627392  115.59331893  187.54315646]\n",
      " [ 108.13490346  127.28197614  175.01021126]\n",
      " [ 108.4377583   130.41010399  172.80679417]\n",
      " [ 109.70560476  136.5244738   171.91755309]\n",
      " [ 108.8636309   141.74930799  169.00357262]\n",
      " [ 109.04250801  144.08973443  170.81559341]]\n",
      "[[ 190.91416467  111.93009822  138.29734276]\n",
      " [ 187.15361059  105.94566242  112.60359805]\n",
      " [ 177.86799675  103.48359427   97.51781241]\n",
      " [ 169.30290049  101.71043588   90.97683138]\n",
      " [ 175.717377     97.82806559   94.30359424]\n",
      " [ 177.08375456  105.61570724  105.08673972]]\n",
      "[[ 133.19298422  132.68602515  152.69687871]\n",
      " [ 134.51947811  130.36078206  153.47901534]\n",
      " [ 135.03751591  134.79349341  154.73966153]\n",
      " [ 135.74451766  140.5049705   157.44298041]\n",
      " [ 137.50835194  145.370781    157.23856378]\n",
      " [ 137.78872638  150.37054793  156.74055224]]\n",
      "[[ 158.97114921   97.50902894  173.67578847]\n",
      " [ 160.09983902   97.62028743  181.31910073]\n",
      " [ 161.55045219  101.01245622  188.18658336]\n",
      " [ 162.97449251  106.98758606  186.91312226]\n",
      " [ 164.43896558  110.13068478  189.16220249]\n",
      " [ 165.37491745  114.88229919  189.64559119]]\n",
      "[[ 116.30691112  124.39615005  173.31150171]\n",
      " [ 118.85001017  127.96844072  169.95548995]\n",
      " [ 120.5483665   132.45905424  158.88910548]\n",
      " [ 122.01551906  133.67454011  164.63083991]\n",
      " [ 123.72211154  138.16601826  162.96156031]\n",
      " [ 125.01675779  141.49462827  166.86677772]]\n",
      "[[ 143.06376482  113.78226615  172.2975199 ]\n",
      " [ 144.27096154  117.0062565   166.16233094]\n",
      " [ 145.17695581  119.75834291  162.06252547]\n",
      " [ 145.59581215  121.13652455  164.02208987]\n",
      " [ 146.42971028  123.92074326  168.31125647]\n",
      " [ 147.03289271  127.66778907  172.18770179]]\n",
      "[[ 103.54473308  116.56838325  141.16647462]\n",
      " [ 106.21006258  116.58347171  162.2179265 ]\n",
      " [ 104.74007858  120.43322644  174.81446114]\n",
      " [ 106.40009598  123.40061716  174.55526827]\n",
      " [ 109.96065025  126.91509137  169.85598155]\n",
      " [ 113.57503229  131.65854856  165.1275604 ]]\n",
      "[[ 119.01640513  104.78623262  145.0862946 ]\n",
      " [ 115.57367586  101.40897241  155.67259263]\n",
      " [ 113.39498094  101.25322804  163.61428955]\n",
      " [ 113.01957785  102.43164341  170.82150891]\n",
      " [ 114.37742887  104.89418369  172.32911326]\n",
      " [ 115.03067484  105.95985999  171.06903805]]\n",
      "[[ 122.47018731  107.7117659   152.18915967]\n",
      " [ 121.34889108  111.23920193  161.59713809]\n",
      " [ 118.08379894  110.9977563   165.94913639]\n",
      " [ 116.7238254   110.71607661  173.86579197]\n",
      " [ 118.06281748  113.04098265  178.66212444]\n",
      " [ 121.67249211  112.1265409   179.38090082]]\n",
      "[[ 200.78051167  119.16755465  245.28243233]\n",
      " [ 204.43246272  126.88055116  232.11960142]\n",
      " [ 205.68898966  129.91659011  236.26243469]\n",
      " [ 202.67335136  132.0462698   235.48529179]\n",
      " [ 201.61286715  133.1511542   245.337977  ]\n",
      " [ 200.29416462  137.14192353  249.44069557]]\n",
      "[[ 123.30741888  103.18916475  160.43810459]\n",
      " [ 124.03623482  102.66225916  162.43375691]\n",
      " [ 122.83556048  105.65899673  167.76944338]\n",
      " [ 119.03040311  108.59680618  168.26667369]\n",
      " [ 118.11206862  112.39486237  169.37185344]\n",
      " [ 117.09403654  116.5181891   169.35625871]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nallAns[x,y,z]\\n[x]: Segment (AM & PM, total 14)\\n[y]: timestamp (6 [20mins])\\n[z]: 3 features\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' === Prediction ===\n",
    "Procedure:\n",
    "1. Load CSV\n",
    "2. to_datetime\n",
    "3. create timeofday column\n",
    "4. select the time for training: 6:00-8:00 (6 timestamps) and 15:00-17:00 (6 timestamps)\n",
    "5. change it to stationary\n",
    "6. Use using_cols to select the features\n",
    "7. change to np array\n",
    "8. MinMaxScaler\n",
    "9. make the sequences tensor as input\n",
    "10. make a forloop for prediction\n",
    "\n",
    "'''\n",
    "# 1. Load CSV - Vol + Route + Weather (Only Weather is 24-hour data)\n",
    "df_pred = pd.read_csv('../data/preprocessed_input_interpolate_20min_phase1and2_train.csv')\n",
    "\n",
    "# 2. to_datetime\n",
    "df_pred['date'] = pd.to_datetime(df_pred['date'])\n",
    "\n",
    "# 3. create timeofday column\n",
    "df_pred['timeofday'] = df_pred.date.apply( lambda d : d.hour+d.minute/60.)\n",
    "\n",
    "# Select the checking days (No need to real final test)\n",
    "\n",
    "start_day = datetime.datetime(year=2016, month=10, day=18, hour=1, minute=0, second=0)\n",
    "end_day = datetime.datetime(year=2016, month=10, day=24, hour=23, minute=0, second=0)\n",
    "\n",
    "df_pred_sel = df_pred[(df_pred['date'] > start_day) & (df_pred['date'] < end_day)]\n",
    "\n",
    "# 4. select the time for training\n",
    "\n",
    "df_pred_sel_time = df_pred_sel[ ((df_pred_sel.timeofday>= 6) & (df_pred_sel.timeofday<8)) |\n",
    "                            ((df_pred_sel.timeofday>=15) & (df_pred_sel.timeofday<17))]\n",
    "\n",
    "df_feedin_weather_sel_time = df_pred_sel[ ((df_pred_sel.timeofday>= 8) & (df_pred_sel.timeofday<10)) |\n",
    "                            ((df_pred_sel.timeofday>=17) & (df_pred_sel.timeofday<19))]\n",
    "\n",
    "# Checking\n",
    "df_pred_sel_time.iloc[12]\n",
    "\n",
    "# 5. change it to stationary\n",
    "df_pred_sel_time = df_pred_sel_time.reset_index(drop=True)\n",
    "\n",
    "df_pred_sel_time_copy = df_pred_sel_time.copy()\n",
    "\n",
    "for i in range(len(df_pred_sel_time_copy)//6):  # make the loop for 14 time slots (2 different time slot x 7days)\n",
    "    for t in range(5):  #  Do the \"difference\" 5 times every loop\n",
    "        start_idx = i*6 + t + 1  # Add 1 is for starting it from index 1 in every 6-space time slot\n",
    "        df_pred_sel_time_copy.loc[start_idx, df_pred_sel_time_copy.columns[0:36]] = df_pred_sel_time.loc[start_idx, df_pred_sel_time.columns[0:36]] - df_pred_sel_time.loc[start_idx-1, df_pred_sel_time.columns[0:36]]\n",
    "\n",
    "# Create one-hot for it\n",
    "# for i in range(24):\n",
    "#     df_pred_sel_time_copy['{}:00'.format(i)] = np.where(df_pred_sel_time_copy.hour == i, 1, 0)\n",
    "#     df_feedin_weather_sel_time['{}:00'.format(i)] = np.where(df_feedin_weather_sel_time.hour == i, 1, 0)\n",
    "\n",
    "# 6. Use using_cols to select the features\n",
    "\n",
    "sel_rows_pred = df_pred_sel_time_copy[ using_cols ]\n",
    "\n",
    "sel_rows_feedin_weather = df_feedin_weather_sel_time[using_cols[output_dim:]]\n",
    "\n",
    "sel_rows_pred\n",
    "\n",
    "# 7. change to np array\n",
    "pred_arr = sel_rows_pred.values\n",
    "\n",
    "feedin_weather_arr = sel_rows_feedin_weather.values\n",
    "\n",
    "# 8. MinMaxScaler\n",
    "pred_arr_scaled = scaler.transform(pred_arr)\n",
    "\n",
    "# add some dummy cells in front of the weather_array for transform\n",
    "temp_arr = np.zeros((84,output_dim))\n",
    "feedin_weather_arr = np.concatenate([temp_arr, feedin_weather_arr], axis=1)\n",
    "\n",
    "feedin_weather_arr_scaled = scaler.transform(feedin_weather_arr)\n",
    "\n",
    "# Now pred_arr_scaled is (84 x features)\n",
    "\n",
    "# 9. make the sequences tensor as input\n",
    "# Put into the model to get the prediction\n",
    "\n",
    "ans_arr = []  # For holding the output answer\n",
    "    \n",
    "for i in range(len(pred_arr_scaled)//6):  # make the loop for 14 time slots (2 different time slot x 7days)\n",
    "    # creating pre_seq\n",
    "    pred_seq = []\n",
    "    for t in range(5):  #  Do the \"difference\" 5 times every loop\n",
    "        k = i*6 + t + 1  # Add 1 is for starting it from index 1 in every 6-space time slot, to ignore the first index which is non-stationary\n",
    "        pred_seq.append(pred_arr_scaled[k])  # creating a sequence for a time slot\n",
    "    \n",
    "    # creating feedin_weather_seq\n",
    "    feedin_weather_seq = []\n",
    "    for t in range(6):  #  Do 6 times every loop\n",
    "        k = i*6 + t  #\n",
    "        feedin_weather_seq.append(feedin_weather_arr_scaled[k])\n",
    "\n",
    "\n",
    "    pred_seq = np.stack(pred_seq)  # change back to the numpy array (2D)\n",
    "    pred_seq = pred_seq.reshape(1, pred_seq.shape[0], pred_seq.shape[1])  # change to numpy 3D as input\n",
    "\n",
    "    feedin_weather_seq = np.stack(feedin_weather_seq)  # change back to the numpy array (2D)\n",
    "    feedin_weather_seq = feedin_weather_seq.reshape(1, feedin_weather_seq.shape[0], feedin_weather_seq.shape[1])  # change to numpy 3D as input\n",
    "\n",
    "    for q in range(6):\n",
    "        # predict next timestamp\n",
    "        output_pred = model.predict(pred_seq)  # get one prediction output (size (1 x output feature(s)))\n",
    "        ans_arr.append(output_pred)\n",
    "\n",
    "        # update the input seq\n",
    "        for j in range(1,5):\n",
    "            pred_seq[0][j-1] = pred_seq[0][j]\n",
    "        pred_seq[0][4] = feedin_weather_seq[0][q]\n",
    "        pred_seq[0][4][0:output_dim] = output_pred[0]\n",
    "\n",
    "# 10. Backward to the non-stationary, correct scale output\n",
    "\n",
    "#  Helper functions\n",
    "\n",
    "def backward_scaler(nn_output):\n",
    "    tmp = np.zeros(input_dim)\n",
    "    tmp[0:output_dim] = nn_output\n",
    "    tmp = scaler.inverse_transform(tmp)\n",
    "    return tmp[0:output_dim]\n",
    "\n",
    "def decode(last_timestamp_values, nn_output):\n",
    "    tmp = np.zeros(input_dim)\n",
    "    tmp[0:output_dim] = nn_output\n",
    "    tmp = scaler.inverse_transform(tmp)\n",
    "    return last_timestamp_values + tmp[0:output_dim]\n",
    "\n",
    "# create the non-stationary 6:40 and 16:40 for decoding\n",
    "df_non_station_sel_time = df_pred_sel[ ((df_pred_sel.timeofday>= 7.5) & (df_pred_sel.timeofday<8)) |\n",
    "                            ((df_pred_sel.timeofday>=16.5) & (df_pred_sel.timeofday<17))]\n",
    "\n",
    "''' Output the non-stationary Answers (allAns)'''\n",
    "\n",
    "tmp = df_non_station_sel_time[using_cols[0:output_dim]].values\n",
    "allAns = []\n",
    "for i in range(len(tmp)):\n",
    "    seed = tmp[i]  # non-stationary for reconstructing a sequence\n",
    "    segmentAns = []\n",
    "    for timestep in range(6):\n",
    "        seed = decode(seed, ans_arr[i*6+timestep])\n",
    "        segmentAns.append(seed)\n",
    "    allAns.append(segmentAns)\n",
    "\n",
    "# Change back to np array for easy visualize\n",
    "allAns = np.array(allAns)\n",
    "\n",
    "# Checking\n",
    "for i in allAns:\n",
    "    print(i)\n",
    "\n",
    "# 11. Output the CSV file\n",
    "\n",
    "# create the datetime objects\n",
    "import datetime\n",
    "\n",
    "pred_start_date = 18\n",
    "\n",
    "\n",
    "start_8am = datetime.datetime(year=2016, month=10, day=pred_start_date, hour=8, minute=0, second=0)\n",
    "start_5pm = datetime.datetime(year=2016, month=10, day=pred_start_date, hour=17, minute=0, second=0)\n",
    "add_1_day = datetime.timedelta(days=1)\n",
    "add_20_min = datetime.timedelta(minutes=20)\n",
    "\n",
    "'''\n",
    "allAns[x,y,z]\n",
    "[x]: Segment (AM & PM, total 14)\n",
    "[y]: timestamp (6 [20mins])\n",
    "[z]: 3 features\n",
    "'''\n",
    "# allAns[0,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 189.76230842  102.92072854  199.88587807]\n",
      " [ 190.71537439  111.99255937  192.09726386]\n",
      " [ 190.98300172  117.40483576  184.06633648]\n",
      " [ 191.17691741  121.74286434  188.73161163]\n",
      " [ 190.78629881  125.20246383  194.43114512]\n",
      " [ 190.23984751  130.11915866  198.34170979]]\n",
      "[[ 131.68275254  106.89113349  167.75714713]\n",
      " [ 131.99229391  113.01360255  164.93915209]\n",
      " [ 129.92571547  118.47794804  165.53933439]\n",
      " [ 127.6297513   121.53683276  166.32552021]\n",
      " [ 125.96652178  123.99866974  170.063499  ]\n",
      " [ 124.94256212  129.72110715  167.12908389]]\n",
      "[[ 194.47226809   95.73927876  143.06877506]\n",
      " [ 191.7626275   103.90176448  139.9163177 ]\n",
      " [ 193.65591198  111.03996664  139.10819881]\n",
      " [ 195.6153882   116.773319    139.28221229]\n",
      " [ 196.42687304  119.95258326  139.78382985]\n",
      " [ 196.71088115  123.7312547   143.54606834]]\n",
      "[[ 110.16627392  115.59331893  187.54315646]\n",
      " [ 108.13490346  127.28197614  175.01021126]\n",
      " [ 108.4377583   130.41010399  172.80679417]\n",
      " [ 109.70560476  136.5244738   171.91755309]\n",
      " [ 108.8636309   141.74930799  169.00357262]\n",
      " [ 109.04250801  144.08973443  170.81559341]]\n",
      "[[ 190.91416467  111.93009822  138.29734276]\n",
      " [ 187.15361059  105.94566242  112.60359805]\n",
      " [ 177.86799675  103.48359427   97.51781241]\n",
      " [ 169.30290049  101.71043588   90.97683138]\n",
      " [ 175.717377     97.82806559   94.30359424]\n",
      " [ 177.08375456  105.61570724  105.08673972]]\n",
      "[[ 133.19298422  132.68602515  152.69687871]\n",
      " [ 134.51947811  130.36078206  153.47901534]\n",
      " [ 135.03751591  134.79349341  154.73966153]\n",
      " [ 135.74451766  140.5049705   157.44298041]\n",
      " [ 137.50835194  145.370781    157.23856378]\n",
      " [ 137.78872638  150.37054793  156.74055224]]\n",
      "[[ 158.97114921   97.50902894  173.67578847]\n",
      " [ 160.09983902   97.62028743  181.31910073]\n",
      " [ 161.55045219  101.01245622  188.18658336]\n",
      " [ 162.97449251  106.98758606  186.91312226]\n",
      " [ 164.43896558  110.13068478  189.16220249]\n",
      " [ 165.37491745  114.88229919  189.64559119]]\n",
      "[[ 116.30691112  124.39615005  173.31150171]\n",
      " [ 118.85001017  127.96844072  169.95548995]\n",
      " [ 120.5483665   132.45905424  158.88910548]\n",
      " [ 122.01551906  133.67454011  164.63083991]\n",
      " [ 123.72211154  138.16601826  162.96156031]\n",
      " [ 125.01675779  141.49462827  166.86677772]]\n",
      "[[ 143.06376482  113.78226615  172.2975199 ]\n",
      " [ 144.27096154  117.0062565   166.16233094]\n",
      " [ 145.17695581  119.75834291  162.06252547]\n",
      " [ 145.59581215  121.13652455  164.02208987]\n",
      " [ 146.42971028  123.92074326  168.31125647]\n",
      " [ 147.03289271  127.66778907  172.18770179]]\n",
      "[[ 103.54473308  116.56838325  141.16647462]\n",
      " [ 106.21006258  116.58347171  162.2179265 ]\n",
      " [ 104.74007858  120.43322644  174.81446114]\n",
      " [ 106.40009598  123.40061716  174.55526827]\n",
      " [ 109.96065025  126.91509137  169.85598155]\n",
      " [ 113.57503229  131.65854856  165.1275604 ]]\n",
      "[[ 119.01640513  104.78623262  145.0862946 ]\n",
      " [ 115.57367586  101.40897241  155.67259263]\n",
      " [ 113.39498094  101.25322804  163.61428955]\n",
      " [ 113.01957785  102.43164341  170.82150891]\n",
      " [ 114.37742887  104.89418369  172.32911326]\n",
      " [ 115.03067484  105.95985999  171.06903805]]\n",
      "[[ 122.47018731  107.7117659   152.18915967]\n",
      " [ 121.34889108  111.23920193  161.59713809]\n",
      " [ 118.08379894  110.9977563   165.94913639]\n",
      " [ 116.7238254   110.71607661  173.86579197]\n",
      " [ 118.06281748  113.04098265  178.66212444]\n",
      " [ 121.67249211  112.1265409   179.38090082]]\n",
      "[[ 200.78051167  119.16755465  245.28243233]\n",
      " [ 204.43246272  126.88055116  232.11960142]\n",
      " [ 205.68898966  129.91659011  236.26243469]\n",
      " [ 202.67335136  132.0462698   235.48529179]\n",
      " [ 201.61286715  133.1511542   245.337977  ]\n",
      " [ 200.29416462  137.14192353  249.44069557]]\n",
      "[[ 123.30741888  103.18916475  160.43810459]\n",
      " [ 124.03623482  102.66225916  162.43375691]\n",
      " [ 122.83556048  105.65899673  167.76944338]\n",
      " [ 119.03040311  108.59680618  168.26667369]\n",
      " [ 118.11206862  112.39486237  169.37185344]\n",
      " [ 117.09403654  116.5181891   169.35625871]]\n"
     ]
    }
   ],
   "source": [
    "for i in allAns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 11.a [FOR TRAFFIC TIME] Output the CSV file\n",
    "\n",
    "## --- (For checking Phase1 Test_answer only)\n",
    "''' For checking Answer'''\n",
    "df_check_answer = df_pred_sel[ ((df_pred_sel.timeofday>= 8) & (df_pred_sel.timeofday<10)) |\n",
    "                            ((df_pred_sel.timeofday>=17) & (df_pred_sel.timeofday<19))]\n",
    "\n",
    "df_check_answer = df_check_answer[using_cols]\n",
    "df_check_answer = df_check_answer[\"('C', 3)\"]\n",
    "check_ans_arr = df_check_answer.values\n",
    "\n",
    "check_ans_arr[0]\n",
    "\n",
    "## --- End of Check\n",
    "\n",
    "route = 'C'\n",
    "checkpoint = '3'\n",
    "vol_or_traj = 2  # select the output cell\n",
    "\n",
    "with open('{}-{}_checking_phase1.csv'.format(route, checkpoint), 'w') as f:\n",
    "    for day in range(7):\n",
    "        for am_pm in range(2):\n",
    "            if am_pm == 0:\n",
    "                ref_time = start_8am\n",
    "            else:\n",
    "                ref_time = start_5pm\n",
    "            for timestep in range(6):\n",
    "                start_timestamp = ref_time + day*add_1_day + timestep*add_20_min\n",
    "                end_timestamp = start_timestamp + add_20_min\n",
    "                start_timestr = start_timestamp.strftime(\"%Y-%m-%d %H:%M:00\")\n",
    "                end_timestr = end_timestamp.strftime(\"%Y-%m-%d %H:%M:00\")\n",
    "                f.write('{},{},\"[{},{})\",{},{}\\n'.format(route,\n",
    "                                                      checkpoint,\n",
    "                                                      start_timestr,\n",
    "                                                      end_timestr,\n",
    "                                                      allAns[day*2+am_pm, timestep, vol_or_traj ],\n",
    "                                                      check_ans_arr[day*2*6 + am_pm*6 + timestep]))  # This last value is for checking answer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 11.b [FOR VOLUME] Output the CSV file\n",
    "\n",
    "# checkpoint = '2'\n",
    "# direction = '0'\n",
    "# vol_or_traj = 1  # select the output cell\n",
    "\n",
    "# with open('{}-{}.csv'.format(checkpoint, direction), 'w') as f:\n",
    "#     for day in range(7):\n",
    "#         for am_pm in range(2):\n",
    "#             if am_pm == 0:\n",
    "#                 ref_time = start_8am\n",
    "#             else:\n",
    "#                 ref_time = start_5pm\n",
    "#             for timestep in range(6):\n",
    "#                 start_timestamp = ref_time + day*add_1_day + timestep*add_20_min\n",
    "#                 end_timestamp = start_timestamp + add_20_min\n",
    "#                 start_timestr = start_timestamp.strftime(\"%Y-%m-%d %H:%M:00\")\n",
    "#                 end_timestr = end_timestamp.strftime(\"%Y-%m-%d %H:%M:00\")\n",
    "#                 f.write('{},\"[{},{})\",{},{}\\n'.format(checkpoint,\n",
    "#                                                   start_timestr,\n",
    "#                                                   end_timestr,\n",
    "#                                                   direction,\n",
    "#                                                   allAns[day*2+am_pm, timestep, vol_or_traj ]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
