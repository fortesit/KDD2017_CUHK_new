{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Date: 22-5-2017\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: caution: 十一黃金周\n",
    "\n",
    "df_merged_volume = pd.read_csv(\"../data/preprocessed_input_traffic_time_and_weather_interpolate_20min_phase1and2_train.csv\")\n",
    "\n",
    "# change \"Date\" to datetime object\n",
    "df_merged_volume['date'] = pd.to_datetime(df_merged_volume['date'])\n",
    "\n",
    "# construct \"time of day\"\n",
    "df_merged_volume['timeofday'] = df_merged_volume.date.apply( lambda d : d.hour+d.minute/60.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select the phase 1 day\n",
    "\n",
    "end_day = datetime.datetime(year=2016, month=10, day=18, hour=0, minute=0, second=0)\n",
    "\n",
    "df_merged_volume = df_merged_volume[(df_merged_volume['date'] < end_day)]\n",
    "\n",
    "# check any unreasonable rows\n",
    "df_merged_volume.tail(30)\n",
    "\n",
    "''' Cut some rows (proprecessing)'''\n",
    "df_merged_volume = df_merged_volume[4:]  # Cut of NaN rows at the beginning\n",
    "df_merged_volume = df_merged_volume.reset_index(drop=True)  # reindexing\n",
    "df_merged_volume\n",
    "\n",
    "''' Make the dataset stationary '''\n",
    "\n",
    "station_cols = 6  # select the first 6 columns for stationary\n",
    "\n",
    "df_merged_volume_copy = df_merged_volume.copy()\n",
    "\n",
    "for i in range(1, len(df_merged_volume_copy)):\n",
    "    df_merged_volume_copy.loc[i, df_merged_volume_copy.columns[0:station_cols]] = df_merged_volume.loc[i, df_merged_volume.columns[0:station_cols]] - df_merged_volume.loc[i-1, df_merged_volume.columns[0:station_cols]]\n",
    "\n",
    "# Check Stationary dataframe\n",
    "\n",
    "df_merged_volume_copy.tail()\n",
    "\n",
    "## Hidden the selecting time\n",
    "# select the time for training: 6:20-10:00 (5 + 6 timestamp) and 15:20-19:00 (5 + 6 timestamp)\n",
    "# sel_rows = df_merged_volume_copy[ ((df_merged_volume_copy.timeofday>= 6.3) & (df_merged_volume_copy.timeofday<10)) |\n",
    "#                             ((df_merged_volume_copy.timeofday>=15.3) & (df_merged_volume_copy.timeofday<19))]\n",
    "\n",
    "## This time, training all time (24hrs) except the first non-stationary row\n",
    "sel_rows = df_merged_volume_copy[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAFkCAYAAADoo9t2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKUpeREREJFP+P7OLHBpPnvU1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1211d4898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sel_rows.plot.box()  # box plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('A', 2)\n",
      "1 ('A', 3)\n",
      "2 ('B', 1)\n",
      "3 ('B', 3)\n",
      "4 ('C', 1)\n",
      "5 ('C', 3)\n",
      "6 date\n",
      "7 hour\n",
      "8 pressure\n",
      "9 sea_pressure\n",
      "10 wind_direction\n",
      "11 wind_speed\n",
      "12 temperature\n",
      "13 rel_humidity\n",
      "14 precipitation\n",
      "15 dayofweek\n",
      "16 is_holiday\n",
      "17 timeofday\n"
     ]
    }
   ],
   "source": [
    "# Create one-hot for hour\n",
    "\n",
    "# for i in range(24):\n",
    "#     sel_rows['{}:00'.format(i)] = np.where(sel_rows.hour == i, 1, 0)\n",
    "\n",
    "# Check all the columns\n",
    "for idx, i in enumerate(sel_rows.columns):\n",
    "    print(idx, i)\n",
    "\n",
    "# select using columns\n",
    "\n",
    "using_cols = [\n",
    "#                 \"(1, 0, 'cargocar')\",\n",
    "#                 \"(1, 0, 'etc')\",\n",
    "#                 \"(1, 0, 'motorcycle')\",\n",
    "#                 \"(1, 0, 'privatecar')\",\n",
    "#                 \"(1, 0, 'tot')\",\n",
    "#                 \"(1, 0, 'unknowncar')\",\n",
    "#                 \"(1, 1, 'cargocar')\",\n",
    "#                 \"(1, 1, 'etc')\",\n",
    "#                 \"(1, 1, 'motorcycle')\",\n",
    "#                 \"(1, 1, 'privatecar')\",\n",
    "#                 \"(1, 1, 'tot')\",\n",
    "#                 \"(1, 1, 'unknowncar')\",\n",
    "#                 \"(2, 0, 'cargocar')\",\n",
    "#                 \"(2, 0, 'etc')\",\n",
    "#                 \"(2, 0, 'motorcycle')\",\n",
    "#                 \"(2, 0, 'privatecar')\",\n",
    "#                 \"(2, 0, 'tot')\",\n",
    "#                 \"(2, 0, 'unknowncar')\",\n",
    "#                 \"(3, 0, 'cargocar')\",\n",
    "#                 \"(3, 0, 'etc')\",\n",
    "#                 \"(3, 0, 'motorcycle')\",\n",
    "#                 \"(3, 0, 'privatecar')\",\n",
    "#                 \"(3, 0, 'tot')\",\n",
    "#                 \"(3, 0, 'unknowncar')\",\n",
    "#                 \"(3, 1, 'cargocar')\",\n",
    "#                 \"(3, 1, 'etc')\",\n",
    "#                 \"(3, 1, 'motorcycle')\",\n",
    "#                 \"(3, 1, 'privatecar')\",\n",
    "#                 \"(3, 1, 'tot')\",\n",
    "#                 \"(3, 1, 'unknowncar')\",\n",
    "#                 \"('A', 2)\",\n",
    "#                 \"('A', 3)\",\n",
    "                \"('B', 1)\",\n",
    "#                 \"('B', 3)\",\n",
    "                \"('C', 1)\",\n",
    "#                 \"('C', 3)\",\n",
    "#                 'date',  # <== Notice this\n",
    "                'hour',\n",
    "                'pressure',\n",
    "#                 'sea_pressure',\n",
    "#                 'wind_direction',\n",
    "#                 'wind_speed',\n",
    "                'temperature',\n",
    "#                 'rel_humidity',\n",
    "                'precipitation',\n",
    "                'dayofweek',\n",
    "                'is_holiday',\n",
    "                'timeofday',\n",
    "#                 '0:00',\n",
    "#                 '1:00',\n",
    "#                 '2:00',\n",
    "#                 '3:00',\n",
    "#                 '4:00',\n",
    "#                 '5:00',\n",
    "#                 '6:00',\n",
    "#                 '7:00',\n",
    "#                 '8:00',\n",
    "#                 '9:00',\n",
    "#                 '10:00',\n",
    "#                 '11:00',\n",
    "#                 '12:00',\n",
    "#                 '13:00',\n",
    "#                 '14:00',\n",
    "#                 '15:00',\n",
    "#                 '16:00',\n",
    "#                 '17:00',\n",
    "#                 '18:00',\n",
    "#                 '19:00',\n",
    "#                 '20:00',\n",
    "#                 '21:00',\n",
    "#                 '22:00',\n",
    "#                 '23:00',\n",
    "              ]\n",
    "\n",
    "sel_rows = sel_rows[using_cols]\n",
    "\n",
    "# split to train and valid set\n",
    "train_rows = sel_rows[: -24*3*7]\n",
    "valid_rows = sel_rows[-24*3*7:] # reserve 7 days for validation\n",
    "\n",
    "# get numpy array from panda dataframe\n",
    "train_arr = train_rows.values\n",
    "valid_arr = valid_rows.values\n",
    "\n",
    "# np.shape(train_arr)\n",
    "# Out:\n",
    "# (726, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summary Stats\n",
    "\n",
    "# train_arr.mean()\n",
    "# train_rows.loc[abs(train_rows[\"('A', 2)\"] + 814.225)<0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scale feature array to range -1 to 1\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler = scaler.fit(train_arr)\n",
    "train_scaled_arr = scaler.transform(train_arr)\n",
    "\n",
    "valid_scaled_arr = scaler.transform(valid_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' save the scaler to another file use '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' save the scaler to another file use '''\n",
    "# import pickle\n",
    "# scalerfile = 'scaler-A-2_phase1.sav'\n",
    "# pickle.dump(scaler, open(scalerfile, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample subsequence from the time series\n",
    "train_seqs = []\n",
    "len_seqs = len(train_scaled_arr) - 6 + 1  # 6 is window size\n",
    "for i in range(len_seqs):\n",
    "    train_seqs.append(train_scaled_arr[i: i+6])  # append 6 timestamps each time (5 timestamps for x, 1 timestamp for y)\n",
    "train_seqs = np.stack(train_seqs)\n",
    "\n",
    "valid_seqs = []\n",
    "len_v_seqs = len(valid_scaled_arr) - 6 + 1  # 6 is window size\n",
    "for i in range(len_v_seqs):\n",
    "    valid_seqs.append(valid_scaled_arr[i: i+6])\n",
    "valid_seqs = np.stack(valid_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37374879, -0.16327664, -0.82608696, -0.48043818,  0.28063241,\n",
       "        -1.        , -0.66666667, -1.        , -0.83098592],\n",
       "       [ 0.37374879, -0.16327664, -0.82608696, -0.48461137,  0.31752306,\n",
       "        -1.        , -0.66666667, -1.        , -0.8028169 ],\n",
       "       [ 0.37374879, -0.16327664, -0.82608696, -0.48878456,  0.3544137 ,\n",
       "        -1.        , -0.66666667, -1.        , -0.77464789],\n",
       "       [ 0.37374879, -0.16327664, -0.73913043, -0.49295775,  0.39130435,\n",
       "        -1.        , -0.66666667, -1.        , -0.74647887],\n",
       "       [ 0.37374879, -0.16327664, -0.73913043, -0.50130412,  0.3921827 ,\n",
       "        -1.        , -0.66666667, -1.        , -0.71830986],\n",
       "       [ 0.37374879, -0.16327664, -0.73913043, -0.5096505 ,  0.39306105,\n",
       "        -1.        , -0.66666667, -1.        , -0.69014085]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking\n",
    "train_seqs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keras\n",
    "#https://keras.io/getting-started/sequential-model-guide/#examples\n",
    "input_dim = len(using_cols)  # The features\n",
    "output_dim = 2  # \n",
    "timesteps = 5 # use 5 timesteps to predict the 6th\n",
    "\n",
    "x_train, y_train = train_seqs[:, 0:-1], train_seqs[:, -1, 0:output_dim]  # 0:output_dim is for deciding the output features\n",
    "x_valid , y_valid  =  valid_seqs[:, 0:-1],  valid_seqs[:, -1, 0:output_dim]  # 0:output_dim is for deciding the output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6038, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "loss_fuc = 'mean_squared_error'\n",
    "\n",
    "# construct the callback\n",
    "filepath=\"best_epoch_T.M._B-1_C-1_phase1.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(output_dim))\n",
    "model.compile(loss=loss_fuc, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 5, 128)            70656     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 202,498\n",
      "Trainable params: 202,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6038 samples, validate on 499 samples\n",
      "Epoch 1/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0090Epoch 00000: val_loss improved from inf to 0.00801, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 7s - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 2/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0052Epoch 00001: val_loss improved from 0.00801 to 0.00793, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0052 - val_loss: 0.0079\n",
      "Epoch 3/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0051Epoch 00002: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0051 - val_loss: 0.0082\n",
      "Epoch 4/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0050Epoch 00003: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0050 - val_loss: 0.0080\n",
      "Epoch 5/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0050Epoch 00004: val_loss improved from 0.00793 to 0.00779, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0050 - val_loss: 0.0078\n",
      "Epoch 6/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0050Epoch 00005: val_loss improved from 0.00779 to 0.00776, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0050 - val_loss: 0.0078\n",
      "Epoch 7/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0049Epoch 00006: val_loss improved from 0.00776 to 0.00769, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0049 - val_loss: 0.0077\n",
      "Epoch 8/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0049Epoch 00007: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0049 - val_loss: 0.0078\n",
      "Epoch 9/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0050Epoch 00008: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0050 - val_loss: 0.0077\n",
      "Epoch 10/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0049Epoch 00009: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0049 - val_loss: 0.0078\n",
      "Epoch 11/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0049Epoch 00010: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0049 - val_loss: 0.0078\n",
      "Epoch 12/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0048Epoch 00011: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0048 - val_loss: 0.0078\n",
      "Epoch 13/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0048Epoch 00012: val_loss improved from 0.00769 to 0.00753, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0048 - val_loss: 0.0075\n",
      "Epoch 14/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0048Epoch 00013: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0048 - val_loss: 0.0078\n",
      "Epoch 15/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0048Epoch 00014: val_loss improved from 0.00753 to 0.00740, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0048 - val_loss: 0.0074\n",
      "Epoch 16/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0048Epoch 00015: val_loss improved from 0.00740 to 0.00729, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 6s - loss: 0.0047 - val_loss: 0.0073\n",
      "Epoch 17/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0047Epoch 00016: val_loss improved from 0.00729 to 0.00724, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 6s - loss: 0.0047 - val_loss: 0.0072\n",
      "Epoch 18/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0047Epoch 00017: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0047 - val_loss: 0.0073\n",
      "Epoch 19/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0046Epoch 00018: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0046 - val_loss: 0.0073\n",
      "Epoch 20/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0046Epoch 00019: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0046 - val_loss: 0.0074\n",
      "Epoch 21/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0046Epoch 00020: val_loss improved from 0.00724 to 0.00711, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0046 - val_loss: 0.0071\n",
      "Epoch 22/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0046Epoch 00021: val_loss improved from 0.00711 to 0.00704, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 6s - loss: 0.0046 - val_loss: 0.0070\n",
      "Epoch 23/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0045Epoch 00022: val_loss improved from 0.00704 to 0.00686, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 6s - loss: 0.0045 - val_loss: 0.0069\n",
      "Epoch 24/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0045Epoch 00023: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0046 - val_loss: 0.0070\n",
      "Epoch 25/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0045Epoch 00024: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0045 - val_loss: 0.0069\n",
      "Epoch 26/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0045Epoch 00025: val_loss improved from 0.00686 to 0.00671, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 6s - loss: 0.0045 - val_loss: 0.0067\n",
      "Epoch 27/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0045Epoch 00026: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0045 - val_loss: 0.0067\n",
      "Epoch 28/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0044Epoch 00027: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0044 - val_loss: 0.0073\n",
      "Epoch 29/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0045Epoch 00028: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0045 - val_loss: 0.0070\n",
      "Epoch 30/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0044Epoch 00029: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0044 - val_loss: 0.0069\n",
      "Epoch 31/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0044Epoch 00030: val_loss improved from 0.00671 to 0.00643, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 32/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0044Epoch 00031: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0044 - val_loss: 0.0065\n",
      "Epoch 33/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0044Epoch 00032: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0044 - val_loss: 0.0070\n",
      "Epoch 34/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0043Epoch 00033: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0043 - val_loss: 0.0069\n",
      "Epoch 35/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0043Epoch 00034: val_loss improved from 0.00643 to 0.00641, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0043 - val_loss: 0.0064\n",
      "Epoch 36/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0043Epoch 00035: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0043 - val_loss: 0.0064\n",
      "Epoch 37/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0042Epoch 00036: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0043 - val_loss: 0.0068\n",
      "Epoch 38/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0043Epoch 00037: val_loss improved from 0.00641 to 0.00595, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 39/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0043Epoch 00038: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 40/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0042Epoch 00039: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0042 - val_loss: 0.0062\n",
      "Epoch 41/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0042Epoch 00040: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0042 - val_loss: 0.0062\n",
      "Epoch 42/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0042Epoch 00041: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0042 - val_loss: 0.0069\n",
      "Epoch 43/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0041Epoch 00042: val_loss improved from 0.00595 to 0.00592, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 44/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0042Epoch 00043: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0042 - val_loss: 0.0063\n",
      "Epoch 45/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0041Epoch 00044: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 46/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0041Epoch 00045: val_loss improved from 0.00592 to 0.00572, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0041 - val_loss: 0.0057\n",
      "Epoch 47/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0040Epoch 00046: val_loss improved from 0.00572 to 0.00560, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 48/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0041Epoch 00047: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0041 - val_loss: 0.0057\n",
      "Epoch 49/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0041Epoch 00048: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 50/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0040Epoch 00049: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0040 - val_loss: 0.0059\n",
      "Epoch 51/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0040Epoch 00050: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0040 - val_loss: 0.0057\n",
      "Epoch 52/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0040Epoch 00051: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 53/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0040Epoch 00052: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0040 - val_loss: 0.0059\n",
      "Epoch 54/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0039Epoch 00053: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0039 - val_loss: 0.0064\n",
      "Epoch 55/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0039Epoch 00054: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0039 - val_loss: 0.0059\n",
      "Epoch 56/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0039Epoch 00055: val_loss improved from 0.00560 to 0.00548, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 6s - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 57/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0039Epoch 00056: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0039 - val_loss: 0.0065\n",
      "Epoch 58/120\n",
      "5952/6038 [============================>.] - ETA: 0s - loss: 0.0039Epoch 00057: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 59/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0039Epoch 00058: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 60/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0041Epoch 00059: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0041 - val_loss: 0.0058\n",
      "Epoch 61/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00060: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 62/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0039Epoch 00061: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0039 - val_loss: 0.0066\n",
      "Epoch 63/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0039Epoch 00062: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0039 - val_loss: 0.0061\n",
      "Epoch 64/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00063: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0039 - val_loss: 0.0064\n",
      "Epoch 65/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00064: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0038 - val_loss: 0.0064\n",
      "Epoch 66/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00065: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 67/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0039Epoch 00066: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0039 - val_loss: 0.0059\n",
      "Epoch 68/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00067: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 69/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00068: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0038 - val_loss: 0.0057\n",
      "Epoch 70/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00069: val_loss improved from 0.00548 to 0.00533, saving model to best_epoch_T.M._B-1_C-1_phase1.hdf5\n",
      "6038/6038 [==============================] - 5s - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 71/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00070: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6038/6038 [==============================] - 5s - loss: 0.0038 - val_loss: 0.0055\n",
      "Epoch 72/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00071: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0038 - val_loss: 0.0063\n",
      "Epoch 73/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00072: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 74/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00073: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 75/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00074: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0038 - val_loss: 0.0060\n",
      "Epoch 76/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00075: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 77/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00076: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0037 - val_loss: 0.0065\n",
      "Epoch 78/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00077: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0037 - val_loss: 0.0066\n",
      "Epoch 79/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00078: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0036 - val_loss: 0.0066\n",
      "Epoch 80/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00079: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0037 - val_loss: 0.0066\n",
      "Epoch 81/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00080: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 82/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00081: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 83/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00082: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0037 - val_loss: 0.0065\n",
      "Epoch 84/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00083: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0036 - val_loss: 0.0059\n",
      "Epoch 85/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00084: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 86/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00085: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0036 - val_loss: 0.0067\n",
      "Epoch 87/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00086: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0036 - val_loss: 0.0066\n",
      "Epoch 88/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00087: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 89/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00088: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0036 - val_loss: 0.0066\n",
      "Epoch 90/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00089: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0036 - val_loss: 0.0064\n",
      "Epoch 91/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00090: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0036 - val_loss: 0.0062\n",
      "Epoch 92/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00091: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 93/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00092: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 94/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00093: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0035 - val_loss: 0.0068\n",
      "Epoch 95/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00094: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0035 - val_loss: 0.0068\n",
      "Epoch 96/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00095: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0035 - val_loss: 0.0066\n",
      "Epoch 97/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00096: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0035 - val_loss: 0.0068\n",
      "Epoch 98/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00097: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0035 - val_loss: 0.0068\n",
      "Epoch 99/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00098: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0035 - val_loss: 0.0070\n",
      "Epoch 100/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00099: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0035 - val_loss: 0.0068\n",
      "Epoch 101/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00100: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0035 - val_loss: 0.0068\n",
      "Epoch 102/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00101: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0035 - val_loss: 0.0070\n",
      "Epoch 103/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00102: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0034 - val_loss: 0.0072\n",
      "Epoch 104/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00103: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0035 - val_loss: 0.0072\n",
      "Epoch 105/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00104: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0035 - val_loss: 0.0074\n",
      "Epoch 106/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00105: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0034 - val_loss: 0.0073\n",
      "Epoch 107/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00106: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0034 - val_loss: 0.0072\n",
      "Epoch 108/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00107: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0034 - val_loss: 0.0071\n",
      "Epoch 109/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0033Epoch 00108: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0033 - val_loss: 0.0075\n",
      "Epoch 110/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0033Epoch 00109: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0033 - val_loss: 0.0075\n",
      "Epoch 111/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0033Epoch 00110: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0033 - val_loss: 0.0075\n",
      "Epoch 112/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0033Epoch 00111: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6038/6038 [==============================] - 5s - loss: 0.0033 - val_loss: 0.0071\n",
      "Epoch 113/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0033Epoch 00112: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0033 - val_loss: 0.0074\n",
      "Epoch 114/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00113: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0034 - val_loss: 0.0075\n",
      "Epoch 115/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0033Epoch 00114: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0033 - val_loss: 0.0076\n",
      "Epoch 116/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0032Epoch 00115: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0032 - val_loss: 0.0080\n",
      "Epoch 117/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0032Epoch 00116: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0032 - val_loss: 0.0084\n",
      "Epoch 118/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0032Epoch 00117: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0032 - val_loss: 0.0078\n",
      "Epoch 119/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0032Epoch 00118: val_loss did not improve\n",
      "6038/6038 [==============================] - 6s - loss: 0.0032 - val_loss: 0.0077\n",
      "Epoch 120/120\n",
      "6016/6038 [============================>.] - ETA: 0s - loss: 0.0032Epoch 00119: val_loss did not improve\n",
      "6038/6038 [==============================] - 5s - loss: 0.0032 - val_loss: 0.0081\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGHCAYAAACnPchFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuWcBjTHGGGPKPQtojDHGGFPu/T+Qv8QYufUrgQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1234ab320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Start Training\n",
    "model.summary()\n",
    "history_w_model = model.fit(x_train, y_train, callbacks=callbacks_list, epochs=num_epochs, batch_size=64, validation_data=(x_valid, y_valid))\n",
    "\n",
    "plt.plot(history_w_model.history['loss'], label='loss')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.plot(history_w_model.history['val_loss'], label='Val_loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Save Model '''\n",
    "\n",
    "# serialize model to JSON\n",
    "\n",
    "# model_json = model.to_json()\n",
    "# with open(\"model_T.M._A-2-p1.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Load the saved model '''\n",
    "\n",
    "# load json and create model\n",
    "\n",
    "# json_file = open('model_500x5_300e.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "\n",
    "# loaded_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# Notes: last best model: 0.00175\n",
    "# load weights into the model\n",
    "model.load_weights(\"best_epoch_T.M._B-1_C-1_phase1.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 133.08025795  241.56894734]\n",
      " [ 124.57608219  222.4716755 ]\n",
      " [ 124.79905392  217.37033802]\n",
      " [ 125.32407546  223.56885002]\n",
      " [ 128.75631861  227.60688374]\n",
      " [ 138.17791408  232.1132275 ]]\n",
      "[[ 135.69530736  201.38181195]\n",
      " [ 136.60795845  206.35171523]\n",
      " [ 138.52349308  211.70348567]\n",
      " [ 140.75374433  216.97096794]\n",
      " [ 144.61971539  222.95241415]\n",
      " [ 147.39703413  228.74862318]]\n",
      "[[ 101.99241855  147.74963987]\n",
      " [ 109.95147027  151.39145299]\n",
      " [ 116.12595143  155.075512  ]\n",
      " [ 124.48753668  153.85464565]\n",
      " [ 127.77827079  159.725523  ]\n",
      " [ 130.84802895  165.47138478]]\n",
      "[[ 125.39226443  204.32628228]\n",
      " [ 131.41275879  211.74590395]\n",
      " [ 135.44670685  213.12221788]\n",
      " [ 134.89694024  218.41533611]\n",
      " [ 136.36198392  222.75903322]\n",
      " [ 137.75959732  227.16239204]]\n",
      "[[ 120.21104924  214.18707182]\n",
      " [ 121.55894069  217.64082289]\n",
      " [ 125.5481453   222.68858414]\n",
      " [ 130.6454751   227.4769913 ]\n",
      " [ 135.0078149   230.90215429]\n",
      " [ 138.79879341  234.40719424]]\n",
      "[[ 141.88238456  195.92859209]\n",
      " [ 142.6635151   196.71218269]\n",
      " [ 143.21591838  201.65678085]\n",
      " [ 143.880905    206.14145027]\n",
      " [ 145.23544495  210.18009477]\n",
      " [ 146.80125593  214.51883774]]\n",
      "[[ 110.19180265  175.50237545]\n",
      " [ 115.24662616  180.37928689]\n",
      " [ 119.37834812  181.60782505]\n",
      " [ 122.04273691  185.27573222]\n",
      " [ 124.40236606  190.10809884]\n",
      " [ 127.83631072  193.40508205]]\n",
      "[[ 153.71575366  241.68144316]\n",
      " [ 152.39287059  238.11442021]\n",
      " [ 149.02518022  242.03776229]\n",
      " [ 147.62116026  246.39209721]\n",
      " [ 149.14339363  249.85167618]\n",
      " [ 150.79809283  254.38406309]]\n",
      "[[ 127.7588797   170.23040995]\n",
      " [ 131.69218651  167.64480641]\n",
      " [ 135.46599236  171.52583473]\n",
      " [ 137.88864046  175.90817241]\n",
      " [ 141.12779355  178.14827895]\n",
      " [ 144.11329538  182.35015544]]\n",
      "[[ 147.49617719  238.68840395]\n",
      " [ 147.46842803  231.97452069]\n",
      " [ 145.17038976  236.5783269 ]\n",
      " [ 142.92396402  240.85224195]\n",
      " [ 140.87135305  240.82460976]\n",
      " [ 141.88360558  244.83773706]]\n",
      "[[ 122.18118055  153.37895747]\n",
      " [ 125.79293318  149.77414228]\n",
      " [ 125.81956937  152.74465302]\n",
      " [ 127.2731436   158.42257357]\n",
      " [ 130.09542636  162.37343485]\n",
      " [ 133.08902612  166.26309898]]\n",
      "[[ 197.9300942   270.3859801 ]\n",
      " [ 177.14500646  245.19231323]\n",
      " [ 159.44709093  235.08278549]\n",
      " [ 143.9136872   231.32468051]\n",
      " [ 143.55430083  232.00340291]\n",
      " [ 147.56559358  240.67867746]]\n",
      "[[ 111.6511154   243.77802146]\n",
      " [ 111.99911672  240.13857821]\n",
      " [ 113.89004245  242.48409587]\n",
      " [ 115.093589    251.3915192 ]\n",
      " [ 120.33838313  260.11753971]\n",
      " [ 125.64430564  265.2062659 ]]\n",
      "[[ 121.0388278   184.27995246]\n",
      " [ 125.76160448  197.48527529]\n",
      " [ 129.52810013  201.40772664]\n",
      " [ 131.57758153  205.64055799]\n",
      " [ 132.17331033  212.93588514]\n",
      " [ 133.64626289  218.68430881]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nallAns[x,y,z]\\n[x]: Segment (AM & PM, total 14)\\n[y]: timestamp (6 [20mins])\\n[z]: 3 features\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' === Prediction ===\n",
    "Procedure:\n",
    "1. Load CSV\n",
    "2. to_datetime\n",
    "3. create timeofday column\n",
    "4. select the time for training: 6:00-8:00 (6 timestamps) and 15:00-17:00 (6 timestamps)\n",
    "5. change it to stationary\n",
    "6. Use using_cols to select the features\n",
    "7. change to np array\n",
    "8. MinMaxScaler\n",
    "9. make the sequences tensor as input\n",
    "10. make a forloop for prediction\n",
    "\n",
    "'''\n",
    "# 1. Load CSV - Vol + Route + Weather (Only Weather is 24-hour data)\n",
    "df_pred = pd.read_csv('../data/preprocessed_input_interpolate_20min_phase1and2_train.csv')\n",
    "\n",
    "# 2. to_datetime\n",
    "df_pred['date'] = pd.to_datetime(df_pred['date'])\n",
    "\n",
    "# 3. create timeofday column\n",
    "df_pred['timeofday'] = df_pred.date.apply( lambda d : d.hour+d.minute/60.)\n",
    "\n",
    "# Select the checking days (No need to real final test)\n",
    "\n",
    "start_day = datetime.datetime(year=2016, month=10, day=18, hour=1, minute=0, second=0)\n",
    "end_day = datetime.datetime(year=2016, month=10, day=24, hour=23, minute=0, second=0)\n",
    "\n",
    "df_pred_sel = df_pred[(df_pred['date'] > start_day) & (df_pred['date'] < end_day)]\n",
    "\n",
    "# 4. select the time for training\n",
    "\n",
    "df_pred_sel_time = df_pred_sel[ ((df_pred_sel.timeofday>= 6) & (df_pred_sel.timeofday<8)) |\n",
    "                            ((df_pred_sel.timeofday>=15) & (df_pred_sel.timeofday<17))]\n",
    "\n",
    "df_feedin_weather_sel_time = df_pred_sel[ ((df_pred_sel.timeofday>= 8) & (df_pred_sel.timeofday<10)) |\n",
    "                            ((df_pred_sel.timeofday>=17) & (df_pred_sel.timeofday<19))]\n",
    "\n",
    "# Checking\n",
    "df_pred_sel_time.iloc[12]\n",
    "\n",
    "# 5. change it to stationary\n",
    "df_pred_sel_time = df_pred_sel_time.reset_index(drop=True)\n",
    "\n",
    "df_pred_sel_time_copy = df_pred_sel_time.copy()\n",
    "\n",
    "for i in range(len(df_pred_sel_time_copy)//6):  # make the loop for 14 time slots (2 different time slot x 7days)\n",
    "    for t in range(5):  #  Do the \"difference\" 5 times every loop\n",
    "        start_idx = i*6 + t + 1  # Add 1 is for starting it from index 1 in every 6-space time slot\n",
    "        df_pred_sel_time_copy.loc[start_idx, df_pred_sel_time_copy.columns[0:36]] = df_pred_sel_time.loc[start_idx, df_pred_sel_time.columns[0:36]] - df_pred_sel_time.loc[start_idx-1, df_pred_sel_time.columns[0:36]]\n",
    "\n",
    "# Create one-hot for it\n",
    "# for i in range(24):\n",
    "#     df_pred_sel_time_copy['{}:00'.format(i)] = np.where(df_pred_sel_time_copy.hour == i, 1, 0)\n",
    "#     df_feedin_weather_sel_time['{}:00'.format(i)] = np.where(df_feedin_weather_sel_time.hour == i, 1, 0)\n",
    "\n",
    "# 6. Use using_cols to select the features\n",
    "\n",
    "sel_rows_pred = df_pred_sel_time_copy[ using_cols ]\n",
    "\n",
    "sel_rows_feedin_weather = df_feedin_weather_sel_time[using_cols[output_dim:]]\n",
    "\n",
    "sel_rows_pred\n",
    "\n",
    "# 7. change to np array\n",
    "pred_arr = sel_rows_pred.values\n",
    "\n",
    "feedin_weather_arr = sel_rows_feedin_weather.values\n",
    "\n",
    "# 8. MinMaxScaler\n",
    "pred_arr_scaled = scaler.transform(pred_arr)\n",
    "\n",
    "# add some dummy cells in front of the weather_array for transform\n",
    "temp_arr = np.zeros((84,output_dim))\n",
    "feedin_weather_arr = np.concatenate([temp_arr, feedin_weather_arr], axis=1)\n",
    "\n",
    "feedin_weather_arr_scaled = scaler.transform(feedin_weather_arr)\n",
    "\n",
    "# Now pred_arr_scaled is (84 x features)\n",
    "\n",
    "# 9. make the sequences tensor as input\n",
    "# Put into the model to get the prediction\n",
    "\n",
    "ans_arr = []  # For holding the output answer\n",
    "    \n",
    "for i in range(len(pred_arr_scaled)//6):  # make the loop for 14 time slots (2 different time slot x 7days)\n",
    "    # creating pre_seq\n",
    "    pred_seq = []\n",
    "    for t in range(5):  #  Do the \"difference\" 5 times every loop\n",
    "        k = i*6 + t + 1  # Add 1 is for starting it from index 1 in every 6-space time slot, to ignore the first index which is non-stationary\n",
    "        pred_seq.append(pred_arr_scaled[k])  # creating a sequence for a time slot\n",
    "    \n",
    "    # creating feedin_weather_seq\n",
    "    feedin_weather_seq = []\n",
    "    for t in range(6):  #  Do 6 times every loop\n",
    "        k = i*6 + t  #\n",
    "        feedin_weather_seq.append(feedin_weather_arr_scaled[k])\n",
    "\n",
    "\n",
    "    pred_seq = np.stack(pred_seq)  # change back to the numpy array (2D)\n",
    "    pred_seq = pred_seq.reshape(1, pred_seq.shape[0], pred_seq.shape[1])  # change to numpy 3D as input\n",
    "\n",
    "    feedin_weather_seq = np.stack(feedin_weather_seq)  # change back to the numpy array (2D)\n",
    "    feedin_weather_seq = feedin_weather_seq.reshape(1, feedin_weather_seq.shape[0], feedin_weather_seq.shape[1])  # change to numpy 3D as input\n",
    "\n",
    "    for q in range(6):\n",
    "        # predict next timestamp\n",
    "        output_pred = model.predict(pred_seq)  # get one prediction output (size (1 x output feature(s)))\n",
    "        ans_arr.append(output_pred)\n",
    "\n",
    "        # update the input seq\n",
    "        for j in range(1,5):\n",
    "            pred_seq[0][j-1] = pred_seq[0][j]\n",
    "        pred_seq[0][4] = feedin_weather_seq[0][q]\n",
    "        pred_seq[0][4][0:output_dim] = output_pred[0]\n",
    "\n",
    "# 10. Backward to the non-stationary, correct scale output\n",
    "\n",
    "#  Helper functions\n",
    "\n",
    "def backward_scaler(nn_output):\n",
    "    tmp = np.zeros(input_dim)\n",
    "    tmp[0:output_dim] = nn_output\n",
    "    tmp = scaler.inverse_transform(tmp)\n",
    "    return tmp[0:output_dim]\n",
    "\n",
    "def decode(last_timestamp_values, nn_output):\n",
    "    tmp = np.zeros(input_dim)\n",
    "    tmp[0:output_dim] = nn_output\n",
    "    tmp = scaler.inverse_transform(tmp)\n",
    "    return last_timestamp_values + tmp[0:output_dim]\n",
    "\n",
    "# create the non-stationary 6:40 and 16:40 for decoding\n",
    "df_non_station_sel_time = df_pred_sel[ ((df_pred_sel.timeofday>= 7.5) & (df_pred_sel.timeofday<8)) |\n",
    "                            ((df_pred_sel.timeofday>=16.5) & (df_pred_sel.timeofday<17))]\n",
    "\n",
    "''' Output the non-stationary Answers (allAns)'''\n",
    "\n",
    "tmp = df_non_station_sel_time[using_cols[0:output_dim]].values\n",
    "allAns = []\n",
    "for i in range(len(tmp)):\n",
    "    seed = tmp[i]  # non-stationary for reconstructing a sequence\n",
    "    segmentAns = []\n",
    "    for timestep in range(6):\n",
    "        seed = decode(seed, ans_arr[i*6+timestep])\n",
    "        segmentAns.append(seed)\n",
    "    allAns.append(segmentAns)\n",
    "\n",
    "# Change back to np array for easy visualize\n",
    "allAns = np.array(allAns)\n",
    "\n",
    "# Checking\n",
    "for i in allAns:\n",
    "    print(i)\n",
    "\n",
    "# 11. Output the CSV file\n",
    "\n",
    "# create the datetime objects\n",
    "import datetime\n",
    "\n",
    "pred_start_date = 18\n",
    "\n",
    "\n",
    "start_8am = datetime.datetime(year=2016, month=10, day=pred_start_date, hour=8, minute=0, second=0)\n",
    "start_5pm = datetime.datetime(year=2016, month=10, day=pred_start_date, hour=17, minute=0, second=0)\n",
    "add_1_day = datetime.timedelta(days=1)\n",
    "add_20_min = datetime.timedelta(minutes=20)\n",
    "\n",
    "'''\n",
    "allAns[x,y,z]\n",
    "[x]: Segment (AM & PM, total 14)\n",
    "[y]: timestamp (6 [20mins])\n",
    "[z]: 3 features\n",
    "'''\n",
    "# allAns[0,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 133.08025795  241.56894734]\n",
      " [ 124.57608219  222.4716755 ]\n",
      " [ 124.79905392  217.37033802]\n",
      " [ 125.32407546  223.56885002]\n",
      " [ 128.75631861  227.60688374]\n",
      " [ 138.17791408  232.1132275 ]]\n",
      "[[ 135.69530736  201.38181195]\n",
      " [ 136.60795845  206.35171523]\n",
      " [ 138.52349308  211.70348567]\n",
      " [ 140.75374433  216.97096794]\n",
      " [ 144.61971539  222.95241415]\n",
      " [ 147.39703413  228.74862318]]\n",
      "[[ 101.99241855  147.74963987]\n",
      " [ 109.95147027  151.39145299]\n",
      " [ 116.12595143  155.075512  ]\n",
      " [ 124.48753668  153.85464565]\n",
      " [ 127.77827079  159.725523  ]\n",
      " [ 130.84802895  165.47138478]]\n",
      "[[ 125.39226443  204.32628228]\n",
      " [ 131.41275879  211.74590395]\n",
      " [ 135.44670685  213.12221788]\n",
      " [ 134.89694024  218.41533611]\n",
      " [ 136.36198392  222.75903322]\n",
      " [ 137.75959732  227.16239204]]\n",
      "[[ 120.21104924  214.18707182]\n",
      " [ 121.55894069  217.64082289]\n",
      " [ 125.5481453   222.68858414]\n",
      " [ 130.6454751   227.4769913 ]\n",
      " [ 135.0078149   230.90215429]\n",
      " [ 138.79879341  234.40719424]]\n",
      "[[ 141.88238456  195.92859209]\n",
      " [ 142.6635151   196.71218269]\n",
      " [ 143.21591838  201.65678085]\n",
      " [ 143.880905    206.14145027]\n",
      " [ 145.23544495  210.18009477]\n",
      " [ 146.80125593  214.51883774]]\n",
      "[[ 110.19180265  175.50237545]\n",
      " [ 115.24662616  180.37928689]\n",
      " [ 119.37834812  181.60782505]\n",
      " [ 122.04273691  185.27573222]\n",
      " [ 124.40236606  190.10809884]\n",
      " [ 127.83631072  193.40508205]]\n",
      "[[ 153.71575366  241.68144316]\n",
      " [ 152.39287059  238.11442021]\n",
      " [ 149.02518022  242.03776229]\n",
      " [ 147.62116026  246.39209721]\n",
      " [ 149.14339363  249.85167618]\n",
      " [ 150.79809283  254.38406309]]\n",
      "[[ 127.7588797   170.23040995]\n",
      " [ 131.69218651  167.64480641]\n",
      " [ 135.46599236  171.52583473]\n",
      " [ 137.88864046  175.90817241]\n",
      " [ 141.12779355  178.14827895]\n",
      " [ 144.11329538  182.35015544]]\n",
      "[[ 147.49617719  238.68840395]\n",
      " [ 147.46842803  231.97452069]\n",
      " [ 145.17038976  236.5783269 ]\n",
      " [ 142.92396402  240.85224195]\n",
      " [ 140.87135305  240.82460976]\n",
      " [ 141.88360558  244.83773706]]\n",
      "[[ 122.18118055  153.37895747]\n",
      " [ 125.79293318  149.77414228]\n",
      " [ 125.81956937  152.74465302]\n",
      " [ 127.2731436   158.42257357]\n",
      " [ 130.09542636  162.37343485]\n",
      " [ 133.08902612  166.26309898]]\n",
      "[[ 197.9300942   270.3859801 ]\n",
      " [ 177.14500646  245.19231323]\n",
      " [ 159.44709093  235.08278549]\n",
      " [ 143.9136872   231.32468051]\n",
      " [ 143.55430083  232.00340291]\n",
      " [ 147.56559358  240.67867746]]\n",
      "[[ 111.6511154   243.77802146]\n",
      " [ 111.99911672  240.13857821]\n",
      " [ 113.89004245  242.48409587]\n",
      " [ 115.093589    251.3915192 ]\n",
      " [ 120.33838313  260.11753971]\n",
      " [ 125.64430564  265.2062659 ]]\n",
      "[[ 121.0388278   184.27995246]\n",
      " [ 125.76160448  197.48527529]\n",
      " [ 129.52810013  201.40772664]\n",
      " [ 131.57758153  205.64055799]\n",
      " [ 132.17331033  212.93588514]\n",
      " [ 133.64626289  218.68430881]]\n"
     ]
    }
   ],
   "source": [
    "for i in allAns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 11.a [FOR TRAFFIC TIME] Output the CSV file\n",
    "\n",
    "## --- (For checking Phase1 Test_answer only)\n",
    "''' For checking Answer'''\n",
    "df_check_answer = df_pred_sel[ ((df_pred_sel.timeofday>= 8) & (df_pred_sel.timeofday<10)) |\n",
    "                            ((df_pred_sel.timeofday>=17) & (df_pred_sel.timeofday<19))]\n",
    "\n",
    "df_check_answer = df_check_answer[using_cols]\n",
    "df_check_answer = df_check_answer[\"('C', 1)\"]\n",
    "check_ans_arr = df_check_answer.values\n",
    "\n",
    "check_ans_arr[0]\n",
    "\n",
    "## --- End of Check\n",
    "\n",
    "route = 'C'\n",
    "checkpoint = '1'\n",
    "vol_or_traj = 1  # select the output cell\n",
    "\n",
    "with open('{}-{}_checking_phase1.csv'.format(route, checkpoint), 'w') as f:\n",
    "    for day in range(7):\n",
    "        for am_pm in range(2):\n",
    "            if am_pm == 0:\n",
    "                ref_time = start_8am\n",
    "            else:\n",
    "                ref_time = start_5pm\n",
    "            for timestep in range(6):\n",
    "                start_timestamp = ref_time + day*add_1_day + timestep*add_20_min\n",
    "                end_timestamp = start_timestamp + add_20_min\n",
    "                start_timestr = start_timestamp.strftime(\"%Y-%m-%d %H:%M:00\")\n",
    "                end_timestr = end_timestamp.strftime(\"%Y-%m-%d %H:%M:00\")\n",
    "                f.write('{},{},\"[{},{})\",{},{}\\n'.format(route,\n",
    "                                                      checkpoint,\n",
    "                                                      start_timestr,\n",
    "                                                      end_timestr,\n",
    "                                                      allAns[day*2+am_pm, timestep, vol_or_traj ],\n",
    "                                                      check_ans_arr[day*2*6 + am_pm*6 + timestep]))  # This last value is for checking answer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 11.b [FOR VOLUME] Output the CSV file\n",
    "\n",
    "# checkpoint = '2'\n",
    "# direction = '0'\n",
    "# vol_or_traj = 1  # select the output cell\n",
    "\n",
    "# with open('{}-{}.csv'.format(checkpoint, direction), 'w') as f:\n",
    "#     for day in range(7):\n",
    "#         for am_pm in range(2):\n",
    "#             if am_pm == 0:\n",
    "#                 ref_time = start_8am\n",
    "#             else:\n",
    "#                 ref_time = start_5pm\n",
    "#             for timestep in range(6):\n",
    "#                 start_timestamp = ref_time + day*add_1_day + timestep*add_20_min\n",
    "#                 end_timestamp = start_timestamp + add_20_min\n",
    "#                 start_timestr = start_timestamp.strftime(\"%Y-%m-%d %H:%M:00\")\n",
    "#                 end_timestr = end_timestamp.strftime(\"%Y-%m-%d %H:%M:00\")\n",
    "#                 f.write('{},\"[{},{})\",{},{}\\n'.format(checkpoint,\n",
    "#                                                   start_timestr,\n",
    "#                                                   end_timestr,\n",
    "#                                                   direction,\n",
    "#                                                   allAns[day*2+am_pm, timestep, vol_or_traj ]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
