{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sys\n",
    "sys.path.insert(0, '../../upload/Roy/exploreData/scripts')\n",
    "\n",
    "import readDataUtil\n",
    "\n",
    "datapath = \"../../data/original_dataset/\"\n",
    "#======================================================\n",
    "#train data\n",
    "#df_trajectories, df_travel_segment = readDataUtil.read_trajectory(\"df_trajectories.pkl\", \"df_travel_segment.pkl\")\n",
    "# df_trajectories, df_travel_segment = readDataUtil.read_trajectory(datapath+\"/training/trajectories_table_5_training.csv\")\n",
    "# df_volume = readDataUtil.read_volume(datapath+\"/training/volume_table_6_training.csv\")\n",
    "# df_weather = readDataUtil.read_weather(datapath+\"/training/weather_table_7_training_update.csv\")\n",
    "\n",
    "#outname = 'phase1_training_vol_route_interpolated_weather_joined_table'\n",
    "#times = pd.date_range('09/20/2016' , '10/18/2016', freq=\"3H\")\n",
    "# outname = 'phase1_training_vol_route_weather_joined_table_interpolated_per20min'\n",
    "# vol_sampling_times = pd.date_range('09/20/2016' , '10/18/2016', freq=\"20min\")\n",
    "# route_sampling_times = pd.date_range('07/19/2016' , '10/18/2016', freq=\"20min\")\n",
    "#train data\n",
    "#df_trajectories, df_travel_segment = readDataUtil.read_trajectory(\"df_trajectories.pkl\", \"df_travel_segment.pkl\")\n",
    "\n",
    "# df_trajectories, df_travel_segment = readDataUtil.read_trajectory(datapath+\"/training/trajectories_table_5_training.csv\")\n",
    "# df_volume = readDataUtil.read_volume(datapath+\"/training/volume_table_6_training.csv\")\n",
    "# df_weather = readDataUtil.read_weather(datapath+\"/training/weather_table_7_training_update.csv\")\n",
    "#outname = 'phase1_training_vol_route_interpolated_weather_joined_table'\n",
    "#times = pd.date_range('09/20/2016' , '10/18/2016', freq=\"3H\")\n",
    "#outname = 'phase1_training_vol_route_weather_joined_table_interpolated_per20min'\n",
    "#vol_sampling_times = pd.date_range('09/20/2016' , '10/18/2016', freq=\"20min\")\n",
    "#route_sampling_times = pd.date_range('07/19/2016' , '10/18/2016', freq=\"20min\")\n",
    "\n",
    "##train data\n",
    "##df_trajectories, df_travel_segment = readDataUtil.read_trajectory(\"df_trajectories.pkl\", \"df_travel_segment.pkl\")\n",
    "#df_trajectories, df_travel_segment = readDataUtil.read_trajectory(datapath+\"/training/trajectories_table_5_training.csv\")\n",
    "#df_volume = readDataUtil.read_volume(datapath+\"/training/volume_table_6_training.csv\")\n",
    "#df_weather = readDataUtil.read_weather(datapath+\"/training/weather_table_7_training_update.csv\")\n",
    "##outname = 'phase1_training_vol_route_interpolated_weather_joined_table'\n",
    "##times = pd.date_range('09/20/2016' , '10/18/2016', freq=\"3H\")\n",
    "#outname = 'phase1_training_vol_route_weather_joined_table_interpolated_per20min'\n",
    "#vol_sampling_times = pd.date_range('09/20/2016' , '10/18/2016', freq=\"20min\")\n",
    "#route_sampling_times = pd.date_range('07/19/2016' , '10/18/2016', freq=\"20min\")\n",
    "\n",
    "#======================================================\n",
    "\n",
    "##test data\n",
    "#df_trajectories, df_travel_segment = readDataUtil.read_trajectory(datapath+\"/testing_phase1/trajectories_table_5_test1.csv\")\n",
    "#df_volume = readDataUtil.read_volume(datapath+\"/testing_phase1/volume_table_6_test1.csv\")\n",
    "#df_weather = readDataUtil.read_weather(datapath+\"/testing_phase1/weather_table_7_test1.csv\")\n",
    "#outname = 'phase1_testing_vol_route_weather_joined_table'\n",
    "#times = pd.date_range('10/18/2016' , '10/25/2016', freq=\"20min\")\n",
    "\n",
    "##test data\n",
    "#df_trajectories, df_travel_segment = readDataUtil.read_trajectory(datapath+\"/testing_phase1/trajectories_table_5_test1.csv\")\n",
    "#df_volume = readDataUtil.read_volume(datapath+\"/testing_phase1/volume_table_6_test1.csv\")\n",
    "#df_weather = readDataUtil.read_weather(datapath+\"/testing_phase1/weather_table_7_test1.csv\")\n",
    "#outname = 'phase1_testing_vol_route_weather_joined_table'\n",
    "#times = pd.date_range('10/18/2016' , '10/25/2016', freq=\"3H\")\n",
    "\n",
    "#test data\n",
    "df_trajectories, df_travel_segment = readDataUtil.read_trajectory(datapath+\"/testing_phase1/trajectories_table_5_test1.csv\")\n",
    "df_volume = readDataUtil.read_volume(datapath+\"/testing_phase1/volume_table_6_test1.csv\")\n",
    "df_weather = readDataUtil.read_weather(datapath+\"/testing_phase1/weather_table_7_test1.csv\")\n",
    "outname = 'phase1_testing_vol_route_weather_joined_table'\n",
    "vol_sampling_times = pd.date_range('10/18/2016' , '10/25/2016', freq=\"20min\")\n",
    "route_sampling_times = pd.date_range('10/18/2016' , '10/25/2016', freq=\"20min\")\n",
    "\n",
    "#======================================================\n",
    "\n",
    "def is_holiday(t):\n",
    "    rdate = t.date()\n",
    "    if rdate>=datetime.date(2016, 9,15) and rdate<=datetime.date(2016, 9,17): return 1 #mid autum holiday\n",
    "    if rdate==datetime.date(2016, 9,18): return 0\n",
    "    if rdate>=datetime.date(2016,10, 1) and rdate<=datetime.date(2016,10, 7): return 1 #national holiday\n",
    "    if rdate>=datetime.date(2016,10, 8) and rdate<=datetime.date(2016,10, 9): return 0\n",
    "    if t.dayofweek == 0 or t.dayofweek == 6: return 1 # sun or sat\n",
    "    return 0 #weekdays\n",
    "\n",
    "vols = [(1,0), (1,1), (2,0), (3,0), (3,1)]\n",
    "routes = [ (\"A\",2), (\"A\",3), (\"B\",1), (\"B\",3), (\"C\",1), (\"C\",3) ]\n",
    "weather_fields = ['pressure', 'sea_pressure', 'wind_direction',\n",
    "                  'wind_speed', 'temperature', 'rel_humidity', 'precipitation']\n",
    "vehicle_class = ['motorcycle', 'cargocar', 'privatecar', 'unknowncar']\n",
    "\n",
    "#======================================================\n",
    "\n",
    "# prepare volume data\n",
    "def get_vehicle_class(row):\n",
    "    vehicle_type  = row.vehicle_type\n",
    "    vehicle_model = row.vehicle_model\n",
    "    if vehicle_type==1 : return 'cargocar'\n",
    "    if vehicle_model==1 and vehicle_type==0 : return 'motorcycle'\n",
    "    if vehicle_model>1 and vehicle_type==0 : return 'privatecar'\n",
    "    return 'unknowncar'\n",
    "\n",
    "df_volume['vehicle_type'] = df_volume['vehicle_type'].replace(np.nan,-1)\n",
    "df_volume['vehicle_class'] = df_volume.apply( get_vehicle_class, axis=1)\n",
    "vehicle_class_volume = df_volume.groupby( ['tollgate_id','direction','vehicle_class',pd.TimeGrouper('20min')]).size()\n",
    "etc_volume = df_volume.groupby( ['tollgate_id','direction','has_etc',pd.TimeGrouper('20min')]).size()\n",
    "tot_volume = etc_volume.sum(level=[0,1,3])\n",
    "\n",
    "tmp = {}\n",
    "for (p,q) in vols:\n",
    "    for aclass in vehicle_class:\n",
    "        try:\n",
    "            tmp2 = vehicle_class_volume[(p,q,aclass)].reindex(vol_sampling_times)\n",
    "            tmp2.fillna(0, inplace=True)\n",
    "        except KeyError as e:\n",
    "            tmp2 = pd.Series(0, index=vol_sampling_times)\n",
    "\n",
    "    tmp[(p,q,aclass)] = tmp2\n",
    "\n",
    "    tmp2 = etc_volume[(p,q,1)].reindex(vol_sampling_times)\n",
    "    tmp2.fillna(0, inplace=True)\n",
    "    tmp[(p,q,'etc')] = tmp2\n",
    "\n",
    "    tmp2 = tot_volume[(p,q)].reindex(vol_sampling_times)\n",
    "    tmp2.fillna(0, inplace=True)\n",
    "    tmp[(p,q,'tot')] = tmp2\n",
    "\n",
    "df_cartype_volume = pd.DataFrame(tmp)\n",
    "\n",
    "# prepare route median data\n",
    "trajectories_median = df_trajectories.set_index('starting_time') \\\n",
    "                                     .groupby(['intersection_id', 'tollgate_id',pd.TimeGrouper('20min')]) \\\n",
    "                                     .travel_time \\\n",
    "                                     .median()\n",
    "tmp = {}\n",
    "for aroute in routes:\n",
    "    tmp2 = trajectories_median[aroute].reindex(route_sampling_times) #fill missing times with NA\n",
    "    tmp2 = tmp2.interpolate() #interpolate NA from nearby data\n",
    "    tmp[aroute]=tmp2\n",
    "df_trajectories_median = pd.DataFrame(tmp)\n",
    "\n",
    "# preapre weather data\n",
    "df_weather['wind_direction'].replace(999017,np.NaN, inplace=True)\n",
    "df_weather = df_weather.reindex(vol_sampling_times) \n",
    "df_weather = df_weather.apply(pd.Series.interpolate) #interpolate 3hr interval data to 20min interval\n",
    "\n",
    "# combine and add extra columns\n",
    "df_combined = pd.concat( [df_cartype_volume, df_trajectories_median.loc[vol_sampling_times] , df_weather] , axis=1)\n",
    "df_combined[\"date\"] = df_combined.index\n",
    "df_combined[\"dayofweek\"] = df_combined['date'].apply( lambda x: x.dayofweek )\n",
    "df_combined[\"hour\"] = df_combined['date'].apply( lambda x: x.hour )\n",
    "df_combined[\"is_holiday\"] = df_combined['date'].apply( is_holiday )\n",
    "\n",
    "df_combined.to_csv('%s.csv'%outname, index=False)\n",
    "# df_combined.to_pickle('%s.pkl'%outname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
