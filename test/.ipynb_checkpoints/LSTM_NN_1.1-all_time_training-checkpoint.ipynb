{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Date: 22-5-2017\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# note:\n",
    "# Because of the 十一黃金周. sth is strange with (2,0,'tot') and others vol from 1 Oct 00:00 to 7 Oct 23:59\n",
    "\n",
    "df_merged_volume = pd.read_csv(\"../data/preprocessed_input_interpolate_20min_phase1and2_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change \"Date\" to datetime object\n",
    "df_merged_volume['date'] = pd.to_datetime(df_merged_volume['date'])\n",
    "\n",
    "# construct \"time of day\"\n",
    "df_merged_volume['timeofday'] = df_merged_volume.date.apply( lambda d : d.hour+d.minute/60.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(1, 0, 'cargocar')</th>\n",
       "      <th>(1, 0, 'etc')</th>\n",
       "      <th>(1, 0, 'motorcycle')</th>\n",
       "      <th>(1, 0, 'privatecar')</th>\n",
       "      <th>(1, 0, 'tot')</th>\n",
       "      <th>(1, 0, 'unknowncar')</th>\n",
       "      <th>(1, 1, 'cargocar')</th>\n",
       "      <th>(1, 1, 'etc')</th>\n",
       "      <th>(1, 1, 'motorcycle')</th>\n",
       "      <th>(1, 1, 'privatecar')</th>\n",
       "      <th>...</th>\n",
       "      <th>pressure</th>\n",
       "      <th>sea_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rel_humidity</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>timeofday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.200000</td>\n",
       "      <td>1018.200000</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>3.5</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.233333</td>\n",
       "      <td>1018.233333</td>\n",
       "      <td>342.444444</td>\n",
       "      <td>3.4</td>\n",
       "      <td>21.411111</td>\n",
       "      <td>66.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.266667</td>\n",
       "      <td>1018.266667</td>\n",
       "      <td>343.888889</td>\n",
       "      <td>3.3</td>\n",
       "      <td>21.722222</td>\n",
       "      <td>65.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.300000</td>\n",
       "      <td>1018.300000</td>\n",
       "      <td>345.333333</td>\n",
       "      <td>3.2</td>\n",
       "      <td>22.033333</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.333333</td>\n",
       "      <td>1018.333333</td>\n",
       "      <td>346.777778</td>\n",
       "      <td>3.1</td>\n",
       "      <td>22.344444</td>\n",
       "      <td>63.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.366667</td>\n",
       "      <td>1018.366667</td>\n",
       "      <td>348.222222</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.655556</td>\n",
       "      <td>62.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.400000</td>\n",
       "      <td>1018.400000</td>\n",
       "      <td>349.666667</td>\n",
       "      <td>2.9</td>\n",
       "      <td>22.966667</td>\n",
       "      <td>61.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.433333</td>\n",
       "      <td>1018.433333</td>\n",
       "      <td>351.111111</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.277778</td>\n",
       "      <td>60.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.466667</td>\n",
       "      <td>1018.466667</td>\n",
       "      <td>352.555556</td>\n",
       "      <td>2.7</td>\n",
       "      <td>23.588889</td>\n",
       "      <td>59.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.500000</td>\n",
       "      <td>1018.500000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (1, 0, 'cargocar')  (1, 0, 'etc')  (1, 0, 'motorcycle')  \\\n",
       "0                   0            1.0                     0   \n",
       "1                   0            0.0                     0   \n",
       "2                   0            1.0                     0   \n",
       "3                   0            2.0                     0   \n",
       "4                   0            1.0                     0   \n",
       "5                   0            1.0                     0   \n",
       "6                   0            0.0                     0   \n",
       "7                   0            2.0                     0   \n",
       "8                   0            0.0                     0   \n",
       "9                   0            0.0                     0   \n",
       "\n",
       "   (1, 0, 'privatecar')  (1, 0, 'tot')  (1, 0, 'unknowncar')  \\\n",
       "0                     0           14.0                  14.0   \n",
       "1                     0           13.0                  13.0   \n",
       "2                     0            7.0                   7.0   \n",
       "3                     0            6.0                   6.0   \n",
       "4                     0            5.0                   5.0   \n",
       "5                     0            5.0                   5.0   \n",
       "6                     0            6.0                   6.0   \n",
       "7                     0            9.0                   9.0   \n",
       "8                     0            7.0                   7.0   \n",
       "9                     0           10.0                  10.0   \n",
       "\n",
       "   (1, 1, 'cargocar')  (1, 1, 'etc')  (1, 1, 'motorcycle')  \\\n",
       "0                38.0           25.0                  89.0   \n",
       "1                24.0           11.0                  41.0   \n",
       "2                10.0            7.0                  22.0   \n",
       "3                 3.0            0.0                   3.0   \n",
       "4                 5.0            0.0                   3.0   \n",
       "5                 3.0            1.0                   8.0   \n",
       "6                 6.0            1.0                   2.0   \n",
       "7                 8.0            1.0                   4.0   \n",
       "8                 4.0            1.0                   4.0   \n",
       "9                 2.0            0.0                   0.0   \n",
       "\n",
       "   (1, 1, 'privatecar')    ...         pressure  sea_pressure  wind_direction  \\\n",
       "0                  12.0    ...      1013.200000   1018.200000      341.000000   \n",
       "1                  15.0    ...      1013.233333   1018.233333      342.444444   \n",
       "2                   5.0    ...      1013.266667   1018.266667      343.888889   \n",
       "3                   0.0    ...      1013.300000   1018.300000      345.333333   \n",
       "4                   0.0    ...      1013.333333   1018.333333      346.777778   \n",
       "5                   0.0    ...      1013.366667   1018.366667      348.222222   \n",
       "6                   0.0    ...      1013.400000   1018.400000      349.666667   \n",
       "7                   0.0    ...      1013.433333   1018.433333      351.111111   \n",
       "8                   0.0    ...      1013.466667   1018.466667      352.555556   \n",
       "9                   0.0    ...      1013.500000   1018.500000      354.000000   \n",
       "\n",
       "   wind_speed  temperature  rel_humidity  precipitation  dayofweek  \\\n",
       "0         3.5    21.100000     68.000000            0.0          1   \n",
       "1         3.4    21.411111     66.888889            0.0          1   \n",
       "2         3.3    21.722222     65.777778            0.0          1   \n",
       "3         3.2    22.033333     64.666667            0.0          1   \n",
       "4         3.1    22.344444     63.555556            0.0          1   \n",
       "5         3.0    22.655556     62.444444            0.0          1   \n",
       "6         2.9    22.966667     61.333333            0.0          1   \n",
       "7         2.8    23.277778     60.222222            0.0          1   \n",
       "8         2.7    23.588889     59.111111            0.0          1   \n",
       "9         2.6    23.900000     58.000000            0.0          1   \n",
       "\n",
       "   is_holiday  timeofday  \n",
       "0           0   0.000000  \n",
       "1           0   0.333333  \n",
       "2           0   0.666667  \n",
       "3           0   1.000000  \n",
       "4           0   1.333333  \n",
       "5           0   1.666667  \n",
       "6           0   2.000000  \n",
       "7           0   2.333333  \n",
       "8           0   2.666667  \n",
       "9           0   3.000000  \n",
       "\n",
       "[10 rows x 48 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_volume.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['(1, 0, 'cargocar')', '(1, 0, 'etc')', '(1, 0, 'motorcycle')',\n",
       "       '(1, 0, 'privatecar')', '(1, 0, 'tot')', '(1, 0, 'unknowncar')',\n",
       "       '(1, 1, 'cargocar')', '(1, 1, 'etc')', '(1, 1, 'motorcycle')',\n",
       "       '(1, 1, 'privatecar')', '(1, 1, 'tot')', '(1, 1, 'unknowncar')',\n",
       "       '(2, 0, 'cargocar')', '(2, 0, 'etc')', '(2, 0, 'motorcycle')',\n",
       "       '(2, 0, 'privatecar')', '(2, 0, 'tot')', '(2, 0, 'unknowncar')',\n",
       "       '(3, 0, 'cargocar')', '(3, 0, 'etc')', '(3, 0, 'motorcycle')',\n",
       "       '(3, 0, 'privatecar')', '(3, 0, 'tot')', '(3, 0, 'unknowncar')',\n",
       "       '(3, 1, 'cargocar')', '(3, 1, 'etc')', '(3, 1, 'motorcycle')',\n",
       "       '(3, 1, 'privatecar')', '(3, 1, 'tot')', '(3, 1, 'unknowncar')',\n",
       "       '('A', 2)', '('A', 3)', '('B', 1)', '('B', 3)', '('C', 1)', '('C', 3)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_volume.columns[0:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the dataset stationary\n",
    "\n",
    "df_merged_volume_copy = df_merged_volume.copy()\n",
    "\n",
    "for i in range(1, len(df_merged_volume_copy)):\n",
    "    df_merged_volume_copy.loc[i, df_merged_volume_copy.columns[0:36]] = df_merged_volume.loc[i, df_merged_volume.columns[0:36]] - df_merged_volume.loc[i-1, df_merged_volume.columns[0:36]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(1, 0, 'cargocar')</th>\n",
       "      <th>(1, 0, 'etc')</th>\n",
       "      <th>(1, 0, 'motorcycle')</th>\n",
       "      <th>(1, 0, 'privatecar')</th>\n",
       "      <th>(1, 0, 'tot')</th>\n",
       "      <th>(1, 0, 'unknowncar')</th>\n",
       "      <th>(1, 1, 'cargocar')</th>\n",
       "      <th>(1, 1, 'etc')</th>\n",
       "      <th>(1, 1, 'motorcycle')</th>\n",
       "      <th>(1, 1, 'privatecar')</th>\n",
       "      <th>...</th>\n",
       "      <th>pressure</th>\n",
       "      <th>sea_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rel_humidity</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>timeofday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.200000</td>\n",
       "      <td>1018.200000</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.233333</td>\n",
       "      <td>1018.233333</td>\n",
       "      <td>342.444444</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>21.411111</td>\n",
       "      <td>66.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.266667</td>\n",
       "      <td>1018.266667</td>\n",
       "      <td>343.888889</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>21.722222</td>\n",
       "      <td>65.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.300000</td>\n",
       "      <td>1018.300000</td>\n",
       "      <td>345.333333</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.033333</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.333333</td>\n",
       "      <td>1018.333333</td>\n",
       "      <td>346.777778</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>22.344444</td>\n",
       "      <td>63.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.366667</td>\n",
       "      <td>1018.366667</td>\n",
       "      <td>348.222222</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>22.655556</td>\n",
       "      <td>62.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.400000</td>\n",
       "      <td>1018.400000</td>\n",
       "      <td>349.666667</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>22.966667</td>\n",
       "      <td>61.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.433333</td>\n",
       "      <td>1018.433333</td>\n",
       "      <td>351.111111</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>23.277778</td>\n",
       "      <td>60.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.466667</td>\n",
       "      <td>1018.466667</td>\n",
       "      <td>352.555556</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>23.588889</td>\n",
       "      <td>59.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.500000</td>\n",
       "      <td>1018.500000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.355556</td>\n",
       "      <td>1018.355556</td>\n",
       "      <td>315.444444</td>\n",
       "      <td>2.822222</td>\n",
       "      <td>24.233333</td>\n",
       "      <td>56.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.211111</td>\n",
       "      <td>1018.211111</td>\n",
       "      <td>276.888889</td>\n",
       "      <td>3.044444</td>\n",
       "      <td>24.566667</td>\n",
       "      <td>54.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.066667</td>\n",
       "      <td>1018.066667</td>\n",
       "      <td>238.333333</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>24.900000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.922222</td>\n",
       "      <td>1017.922222</td>\n",
       "      <td>199.777778</td>\n",
       "      <td>3.488889</td>\n",
       "      <td>25.233333</td>\n",
       "      <td>51.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.777778</td>\n",
       "      <td>1017.777778</td>\n",
       "      <td>161.222222</td>\n",
       "      <td>3.711111</td>\n",
       "      <td>25.566667</td>\n",
       "      <td>49.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.633333</td>\n",
       "      <td>1017.633333</td>\n",
       "      <td>122.666667</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.488889</td>\n",
       "      <td>1017.488889</td>\n",
       "      <td>84.111111</td>\n",
       "      <td>4.155556</td>\n",
       "      <td>26.233333</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.344444</td>\n",
       "      <td>1017.344444</td>\n",
       "      <td>45.555556</td>\n",
       "      <td>4.377778</td>\n",
       "      <td>26.566667</td>\n",
       "      <td>44.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.200000</td>\n",
       "      <td>1017.200000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>26.900000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.244444</td>\n",
       "      <td>1017.244444</td>\n",
       "      <td>7.444444</td>\n",
       "      <td>4.588889</td>\n",
       "      <td>26.733333</td>\n",
       "      <td>42.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.288889</td>\n",
       "      <td>1017.288889</td>\n",
       "      <td>7.888889</td>\n",
       "      <td>4.577778</td>\n",
       "      <td>26.566667</td>\n",
       "      <td>42.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.333333</td>\n",
       "      <td>1017.333333</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>26.400000</td>\n",
       "      <td>42.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.377778</td>\n",
       "      <td>1017.377778</td>\n",
       "      <td>8.777778</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>26.233333</td>\n",
       "      <td>42.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.422222</td>\n",
       "      <td>1017.422222</td>\n",
       "      <td>9.222222</td>\n",
       "      <td>4.544444</td>\n",
       "      <td>26.066667</td>\n",
       "      <td>42.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.466667</td>\n",
       "      <td>1017.466667</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>42.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.511111</td>\n",
       "      <td>1017.511111</td>\n",
       "      <td>10.111111</td>\n",
       "      <td>4.522222</td>\n",
       "      <td>25.733333</td>\n",
       "      <td>42.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.555556</td>\n",
       "      <td>1017.555556</td>\n",
       "      <td>10.555556</td>\n",
       "      <td>4.511111</td>\n",
       "      <td>25.566667</td>\n",
       "      <td>42.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.600000</td>\n",
       "      <td>1017.600000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.722222</td>\n",
       "      <td>1017.722222</td>\n",
       "      <td>12.555556</td>\n",
       "      <td>4.188889</td>\n",
       "      <td>25.033333</td>\n",
       "      <td>43.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.844444</td>\n",
       "      <td>1017.844444</td>\n",
       "      <td>14.111111</td>\n",
       "      <td>3.877778</td>\n",
       "      <td>24.666667</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.786550</td>\n",
       "      <td>1015.786550</td>\n",
       "      <td>354.077973</td>\n",
       "      <td>3.349123</td>\n",
       "      <td>20.149123</td>\n",
       "      <td>86.226121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.780117</td>\n",
       "      <td>1015.780117</td>\n",
       "      <td>354.144250</td>\n",
       "      <td>3.350877</td>\n",
       "      <td>20.150877</td>\n",
       "      <td>86.218324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.773684</td>\n",
       "      <td>1015.773684</td>\n",
       "      <td>354.210526</td>\n",
       "      <td>3.352632</td>\n",
       "      <td>20.152632</td>\n",
       "      <td>86.210526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.767251</td>\n",
       "      <td>1015.767251</td>\n",
       "      <td>354.276803</td>\n",
       "      <td>3.354386</td>\n",
       "      <td>20.154386</td>\n",
       "      <td>86.202729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.760819</td>\n",
       "      <td>1015.760819</td>\n",
       "      <td>354.343080</td>\n",
       "      <td>3.356140</td>\n",
       "      <td>20.156140</td>\n",
       "      <td>86.194932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.754386</td>\n",
       "      <td>1015.754386</td>\n",
       "      <td>354.409357</td>\n",
       "      <td>3.357895</td>\n",
       "      <td>20.157895</td>\n",
       "      <td>86.187135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.747953</td>\n",
       "      <td>1015.747953</td>\n",
       "      <td>354.475634</td>\n",
       "      <td>3.359649</td>\n",
       "      <td>20.159649</td>\n",
       "      <td>86.179337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.741520</td>\n",
       "      <td>1015.741520</td>\n",
       "      <td>354.541910</td>\n",
       "      <td>3.361404</td>\n",
       "      <td>20.161404</td>\n",
       "      <td>86.171540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.735088</td>\n",
       "      <td>1015.735088</td>\n",
       "      <td>354.608187</td>\n",
       "      <td>3.363158</td>\n",
       "      <td>20.163158</td>\n",
       "      <td>86.163743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.728655</td>\n",
       "      <td>1015.728655</td>\n",
       "      <td>354.674464</td>\n",
       "      <td>3.364912</td>\n",
       "      <td>20.164912</td>\n",
       "      <td>86.155945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.722222</td>\n",
       "      <td>1015.722222</td>\n",
       "      <td>354.740741</td>\n",
       "      <td>3.366667</td>\n",
       "      <td>20.166667</td>\n",
       "      <td>86.148148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.715789</td>\n",
       "      <td>1015.715789</td>\n",
       "      <td>354.807018</td>\n",
       "      <td>3.368421</td>\n",
       "      <td>20.168421</td>\n",
       "      <td>86.140351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.709357</td>\n",
       "      <td>1015.709357</td>\n",
       "      <td>354.873294</td>\n",
       "      <td>3.370175</td>\n",
       "      <td>20.170175</td>\n",
       "      <td>86.132554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.702924</td>\n",
       "      <td>1015.702924</td>\n",
       "      <td>354.939571</td>\n",
       "      <td>3.371930</td>\n",
       "      <td>20.171930</td>\n",
       "      <td>86.124756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.696491</td>\n",
       "      <td>1015.696491</td>\n",
       "      <td>355.005848</td>\n",
       "      <td>3.373684</td>\n",
       "      <td>20.173684</td>\n",
       "      <td>86.116959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.690058</td>\n",
       "      <td>1015.690058</td>\n",
       "      <td>355.072125</td>\n",
       "      <td>3.375439</td>\n",
       "      <td>20.175439</td>\n",
       "      <td>86.109162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.683626</td>\n",
       "      <td>1015.683626</td>\n",
       "      <td>355.138402</td>\n",
       "      <td>3.377193</td>\n",
       "      <td>20.177193</td>\n",
       "      <td>86.101365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.677193</td>\n",
       "      <td>1015.677193</td>\n",
       "      <td>355.204678</td>\n",
       "      <td>3.378947</td>\n",
       "      <td>20.178947</td>\n",
       "      <td>86.093567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.670760</td>\n",
       "      <td>1015.670760</td>\n",
       "      <td>355.270955</td>\n",
       "      <td>3.380702</td>\n",
       "      <td>20.180702</td>\n",
       "      <td>86.085770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.664327</td>\n",
       "      <td>1015.664327</td>\n",
       "      <td>355.337232</td>\n",
       "      <td>3.382456</td>\n",
       "      <td>20.182456</td>\n",
       "      <td>86.077973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.657895</td>\n",
       "      <td>1015.657895</td>\n",
       "      <td>355.403509</td>\n",
       "      <td>3.384211</td>\n",
       "      <td>20.184211</td>\n",
       "      <td>86.070175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.651462</td>\n",
       "      <td>1015.651462</td>\n",
       "      <td>355.469786</td>\n",
       "      <td>3.385965</td>\n",
       "      <td>20.185965</td>\n",
       "      <td>86.062378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.645029</td>\n",
       "      <td>1015.645029</td>\n",
       "      <td>355.536062</td>\n",
       "      <td>3.387719</td>\n",
       "      <td>20.187719</td>\n",
       "      <td>86.054581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.638596</td>\n",
       "      <td>1015.638596</td>\n",
       "      <td>355.602339</td>\n",
       "      <td>3.389474</td>\n",
       "      <td>20.189474</td>\n",
       "      <td>86.046784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.632164</td>\n",
       "      <td>1015.632164</td>\n",
       "      <td>355.668616</td>\n",
       "      <td>3.391228</td>\n",
       "      <td>20.191228</td>\n",
       "      <td>86.038986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.625731</td>\n",
       "      <td>1015.625731</td>\n",
       "      <td>355.734893</td>\n",
       "      <td>3.392982</td>\n",
       "      <td>20.192982</td>\n",
       "      <td>86.031189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.619298</td>\n",
       "      <td>1015.619298</td>\n",
       "      <td>355.801170</td>\n",
       "      <td>3.394737</td>\n",
       "      <td>20.194737</td>\n",
       "      <td>86.023392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.612865</td>\n",
       "      <td>1015.612865</td>\n",
       "      <td>355.867446</td>\n",
       "      <td>3.396491</td>\n",
       "      <td>20.196491</td>\n",
       "      <td>86.015595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.606433</td>\n",
       "      <td>1015.606433</td>\n",
       "      <td>355.933723</td>\n",
       "      <td>3.398246</td>\n",
       "      <td>20.198246</td>\n",
       "      <td>86.007797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.600000</td>\n",
       "      <td>1015.600000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2521 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      (1, 0, 'cargocar')  (1, 0, 'etc')  (1, 0, 'motorcycle')  \\\n",
       "0                      0            1.0                     0   \n",
       "1                      0           -1.0                     0   \n",
       "2                      0            1.0                     0   \n",
       "3                      0            1.0                     0   \n",
       "4                      0           -1.0                     0   \n",
       "5                      0            0.0                     0   \n",
       "6                      0           -1.0                     0   \n",
       "7                      0            2.0                     0   \n",
       "8                      0           -2.0                     0   \n",
       "9                      0            0.0                     0   \n",
       "10                     0            0.0                     0   \n",
       "11                     0            0.0                     0   \n",
       "12                     0            0.0                     0   \n",
       "13                     0            1.0                     0   \n",
       "14                     0            0.0                     0   \n",
       "15                     0            0.0                     0   \n",
       "16                     0           -1.0                     0   \n",
       "17                     0            2.0                     0   \n",
       "18                     0            2.0                     0   \n",
       "19                     0            0.0                     0   \n",
       "20                     0            4.0                     0   \n",
       "21                     0            6.0                     0   \n",
       "22                     0           -7.0                     0   \n",
       "23                     0            2.0                     0   \n",
       "24                     0           12.0                     0   \n",
       "25                     0            0.0                     0   \n",
       "26                     0           -6.0                     0   \n",
       "27                     0           -2.0                     0   \n",
       "28                     0            8.0                     0   \n",
       "29                     0           -7.0                     0   \n",
       "...                  ...            ...                   ...   \n",
       "2491                   0           -7.0                     0   \n",
       "2492                   0            1.0                     0   \n",
       "2493                   0           -6.0                     0   \n",
       "2494                   0           10.0                     0   \n",
       "2495                   0           -6.0                     0   \n",
       "2496                   0            0.0                     0   \n",
       "2497                   0            8.0                     0   \n",
       "2498                   0           -4.0                     0   \n",
       "2499                   0           -5.0                     0   \n",
       "2500                   0            7.0                     0   \n",
       "2501                   0           -3.0                     0   \n",
       "2502                   0           -7.0                     0   \n",
       "2503                   0            0.0                     0   \n",
       "2504                   0            2.0                     0   \n",
       "2505                   0           -1.0                     0   \n",
       "2506                   0            0.0                     0   \n",
       "2507                   0           -2.0                     0   \n",
       "2508                   0            5.0                     0   \n",
       "2509                   0           -1.0                     0   \n",
       "2510                   0           -1.0                     0   \n",
       "2511                   0            0.0                     0   \n",
       "2512                   0           -2.0                     0   \n",
       "2513                   0           -2.0                     0   \n",
       "2514                   0            1.0                     0   \n",
       "2515                   0            0.0                     0   \n",
       "2516                   0            1.0                     0   \n",
       "2517                   0           -2.0                     0   \n",
       "2518                   0            0.0                     0   \n",
       "2519                   0           -1.0                     0   \n",
       "2520                   0            0.0                     0   \n",
       "\n",
       "      (1, 0, 'privatecar')  (1, 0, 'tot')  (1, 0, 'unknowncar')  \\\n",
       "0                        0           14.0                  14.0   \n",
       "1                        0           -1.0                  -1.0   \n",
       "2                        0           -6.0                  -6.0   \n",
       "3                        0           -1.0                  -1.0   \n",
       "4                        0           -1.0                  -1.0   \n",
       "5                        0            0.0                   0.0   \n",
       "6                        0            1.0                   1.0   \n",
       "7                        0            3.0                   3.0   \n",
       "8                        0           -2.0                  -2.0   \n",
       "9                        0            3.0                   3.0   \n",
       "10                       0           -2.0                  -2.0   \n",
       "11                       0           -3.0                  -3.0   \n",
       "12                       0            6.0                   6.0   \n",
       "13                       0           -3.0                  -3.0   \n",
       "14                       0            7.0                   7.0   \n",
       "15                       0           -6.0                  -6.0   \n",
       "16                       0           -5.0                  -5.0   \n",
       "17                       0            6.0                   6.0   \n",
       "18                       0            3.0                   3.0   \n",
       "19                       0            7.0                   7.0   \n",
       "20                       0            9.0                   9.0   \n",
       "21                       0            9.0                   9.0   \n",
       "22                       0           -8.0                  -8.0   \n",
       "23                       0            1.0                   1.0   \n",
       "24                       0           22.0                  22.0   \n",
       "25                       0           -3.0                  -3.0   \n",
       "26                       0           -5.0                  -5.0   \n",
       "27                       0            6.0                   6.0   \n",
       "28                       0           17.0                  17.0   \n",
       "29                       0           -9.0                  -9.0   \n",
       "...                    ...            ...                   ...   \n",
       "2491                     0            2.0                   2.0   \n",
       "2492                     0           -5.0                  -5.0   \n",
       "2493                     0            6.0                   6.0   \n",
       "2494                     0           -3.0                  -3.0   \n",
       "2495                     0          -21.0                 -21.0   \n",
       "2496                     0           23.0                  23.0   \n",
       "2497                     0            1.0                   1.0   \n",
       "2498                     0           -6.0                  -6.0   \n",
       "2499                     0          -12.0                 -12.0   \n",
       "2500                     0            7.0                   7.0   \n",
       "2501                     0          -10.0                 -10.0   \n",
       "2502                     0          -14.0                 -14.0   \n",
       "2503                     0            3.0                   3.0   \n",
       "2504                     0           -5.0                  -5.0   \n",
       "2505                     0           14.0                  14.0   \n",
       "2506                     0          -11.0                 -11.0   \n",
       "2507                     0           -6.0                  -6.0   \n",
       "2508                     0            8.0                   8.0   \n",
       "2509                     0            1.0                   1.0   \n",
       "2510                     0           -2.0                  -2.0   \n",
       "2511                     0            2.0                   2.0   \n",
       "2512                     0           -5.0                  -5.0   \n",
       "2513                     0            0.0                   0.0   \n",
       "2514                     0           -4.0                  -4.0   \n",
       "2515                     0            1.0                   1.0   \n",
       "2516                     0           -4.0                  -4.0   \n",
       "2517                     0            4.0                   4.0   \n",
       "2518                     0           -4.0                  -4.0   \n",
       "2519                     0           -5.0                  -5.0   \n",
       "2520                     0           -2.0                  -2.0   \n",
       "\n",
       "      (1, 1, 'cargocar')  (1, 1, 'etc')  (1, 1, 'motorcycle')  \\\n",
       "0                   38.0           25.0                  89.0   \n",
       "1                  -14.0          -14.0                 -48.0   \n",
       "2                  -14.0           -4.0                 -19.0   \n",
       "3                   -7.0           -7.0                 -19.0   \n",
       "4                    2.0            0.0                   0.0   \n",
       "5                   -2.0            1.0                   5.0   \n",
       "6                    3.0            0.0                  -6.0   \n",
       "7                    2.0            0.0                   2.0   \n",
       "8                   -4.0            0.0                   0.0   \n",
       "9                   -2.0           -1.0                  -4.0   \n",
       "10                  10.0            0.0                   1.0   \n",
       "11                   2.0            0.0                   3.0   \n",
       "12                  -1.0            0.0                   3.0   \n",
       "13                  -3.0            3.0                   0.0   \n",
       "14                   0.0            0.0                   3.0   \n",
       "15                   4.0           -3.0                   3.0   \n",
       "16                  13.0            1.0                  -3.0   \n",
       "17                  -3.0            3.0                   1.0   \n",
       "18                  -1.0            0.0                  13.0   \n",
       "19                   1.0           -1.0                  11.0   \n",
       "20                   4.0            6.0                   5.0   \n",
       "21                  -8.0           14.0                  25.0   \n",
       "22                   6.0            9.0                  31.0   \n",
       "23                  -6.0            8.0                  21.0   \n",
       "24                   4.0           -3.0                 -17.0   \n",
       "25                  -5.0           -5.0                  27.0   \n",
       "26                   3.0           -9.0                 -19.0   \n",
       "27                   6.0            6.0                   7.0   \n",
       "28                  -6.0           -1.0                  -2.0   \n",
       "29                  11.0            9.0                  17.0   \n",
       "...                  ...            ...                   ...   \n",
       "2491                -1.0            1.0                  17.0   \n",
       "2492                -1.0            2.0                  -9.0   \n",
       "2493                -8.0           10.0                   1.0   \n",
       "2494                13.0           -8.0                 -12.0   \n",
       "2495                 0.0           -1.0                  21.0   \n",
       "2496               -11.0           10.0                  10.0   \n",
       "2497                 5.0            7.0                  -1.0   \n",
       "2498                -2.0           -8.0                  -1.0   \n",
       "2499                -3.0            7.0                   8.0   \n",
       "2500                -3.0           11.0                   4.0   \n",
       "2501                 1.0            5.0                  22.0   \n",
       "2502                 3.0          -28.0                 -63.0   \n",
       "2503                -6.0            5.0                  19.0   \n",
       "2504                -6.0          -12.0                  -6.0   \n",
       "2505                 9.0            0.0                 -11.0   \n",
       "2506                -4.0           -5.0                 -21.0   \n",
       "2507                 1.0            2.0                   5.0   \n",
       "2508                -2.0           -6.0                 -17.0   \n",
       "2509                 0.0           10.0                  17.0   \n",
       "2510                -1.0           -7.0                 -11.0   \n",
       "2511                -2.0           -4.0                 -11.0   \n",
       "2512                -1.0            3.0                   4.0   \n",
       "2513                -2.0           -4.0                   1.0   \n",
       "2514                 3.0            3.0                  -1.0   \n",
       "2515                -2.0            0.0                   0.0   \n",
       "2516                 0.0            0.0                  -6.0   \n",
       "2517                -2.0           -3.0                  -1.0   \n",
       "2518                 3.0           -3.0                  -3.0   \n",
       "2519                -4.0            2.0                   3.0   \n",
       "2520                -1.0           -2.0                 -12.0   \n",
       "\n",
       "      (1, 1, 'privatecar')    ...         pressure  sea_pressure  \\\n",
       "0                     12.0    ...      1013.200000   1018.200000   \n",
       "1                      3.0    ...      1013.233333   1018.233333   \n",
       "2                    -10.0    ...      1013.266667   1018.266667   \n",
       "3                     -5.0    ...      1013.300000   1018.300000   \n",
       "4                      0.0    ...      1013.333333   1018.333333   \n",
       "5                      0.0    ...      1013.366667   1018.366667   \n",
       "6                      0.0    ...      1013.400000   1018.400000   \n",
       "7                      0.0    ...      1013.433333   1018.433333   \n",
       "8                      0.0    ...      1013.466667   1018.466667   \n",
       "9                      0.0    ...      1013.500000   1018.500000   \n",
       "10                     0.0    ...      1013.355556   1018.355556   \n",
       "11                     0.0    ...      1013.211111   1018.211111   \n",
       "12                     0.0    ...      1013.066667   1018.066667   \n",
       "13                     0.0    ...      1012.922222   1017.922222   \n",
       "14                     0.0    ...      1012.777778   1017.777778   \n",
       "15                     0.0    ...      1012.633333   1017.633333   \n",
       "16                     0.0    ...      1012.488889   1017.488889   \n",
       "17                     0.0    ...      1012.344444   1017.344444   \n",
       "18                     0.0    ...      1012.200000   1017.200000   \n",
       "19                     0.0    ...      1012.244444   1017.244444   \n",
       "20                     1.0    ...      1012.288889   1017.288889   \n",
       "21                     2.0    ...      1012.333333   1017.333333   \n",
       "22                     1.0    ...      1012.377778   1017.377778   \n",
       "23                    -2.0    ...      1012.422222   1017.422222   \n",
       "24                     6.0    ...      1012.466667   1017.466667   \n",
       "25                    -3.0    ...      1012.511111   1017.511111   \n",
       "26                    -4.0    ...      1012.555556   1017.555556   \n",
       "27                     6.0    ...      1012.600000   1017.600000   \n",
       "28                     0.0    ...      1012.722222   1017.722222   \n",
       "29                     3.0    ...      1012.844444   1017.844444   \n",
       "...                    ...    ...              ...           ...   \n",
       "2491                   0.0    ...      1010.786550   1015.786550   \n",
       "2492                   1.0    ...      1010.780117   1015.780117   \n",
       "2493                   3.0    ...      1010.773684   1015.773684   \n",
       "2494                  -3.0    ...      1010.767251   1015.767251   \n",
       "2495                   2.0    ...      1010.760819   1015.760819   \n",
       "2496                  -3.0    ...      1010.754386   1015.754386   \n",
       "2497                   5.0    ...      1010.747953   1015.747953   \n",
       "2498                  -2.0    ...      1010.741520   1015.741520   \n",
       "2499                   0.0    ...      1010.735088   1015.735088   \n",
       "2500                   3.0    ...      1010.728655   1015.728655   \n",
       "2501                  -1.0    ...      1010.722222   1015.722222   \n",
       "2502                  -5.0    ...      1010.715789   1015.715789   \n",
       "2503                   2.0    ...      1010.709357   1015.709357   \n",
       "2504                  -3.0    ...      1010.702924   1015.702924   \n",
       "2505                   1.0    ...      1010.696491   1015.696491   \n",
       "2506                   0.0    ...      1010.690058   1015.690058   \n",
       "2507                  -1.0    ...      1010.683626   1015.683626   \n",
       "2508                   3.0    ...      1010.677193   1015.677193   \n",
       "2509                  -1.0    ...      1010.670760   1015.670760   \n",
       "2510                  -2.0    ...      1010.664327   1015.664327   \n",
       "2511                   0.0    ...      1010.657895   1015.657895   \n",
       "2512                   0.0    ...      1010.651462   1015.651462   \n",
       "2513                   0.0    ...      1010.645029   1015.645029   \n",
       "2514                   0.0    ...      1010.638596   1015.638596   \n",
       "2515                   0.0    ...      1010.632164   1015.632164   \n",
       "2516                   0.0    ...      1010.625731   1015.625731   \n",
       "2517                   0.0    ...      1010.619298   1015.619298   \n",
       "2518                   0.0    ...      1010.612865   1015.612865   \n",
       "2519                   0.0    ...      1010.606433   1015.606433   \n",
       "2520                   0.0    ...      1010.600000   1015.600000   \n",
       "\n",
       "      wind_direction  wind_speed  temperature  rel_humidity  precipitation  \\\n",
       "0         341.000000    3.500000    21.100000     68.000000            0.0   \n",
       "1         342.444444    3.400000    21.411111     66.888889            0.0   \n",
       "2         343.888889    3.300000    21.722222     65.777778            0.0   \n",
       "3         345.333333    3.200000    22.033333     64.666667            0.0   \n",
       "4         346.777778    3.100000    22.344444     63.555556            0.0   \n",
       "5         348.222222    3.000000    22.655556     62.444444            0.0   \n",
       "6         349.666667    2.900000    22.966667     61.333333            0.0   \n",
       "7         351.111111    2.800000    23.277778     60.222222            0.0   \n",
       "8         352.555556    2.700000    23.588889     59.111111            0.0   \n",
       "9         354.000000    2.600000    23.900000     58.000000            0.0   \n",
       "10        315.444444    2.822222    24.233333     56.333333            0.0   \n",
       "11        276.888889    3.044444    24.566667     54.666667            0.0   \n",
       "12        238.333333    3.266667    24.900000     53.000000            0.0   \n",
       "13        199.777778    3.488889    25.233333     51.333333            0.0   \n",
       "14        161.222222    3.711111    25.566667     49.666667            0.0   \n",
       "15        122.666667    3.933333    25.900000     48.000000            0.0   \n",
       "16         84.111111    4.155556    26.233333     46.333333            0.0   \n",
       "17         45.555556    4.377778    26.566667     44.666667            0.0   \n",
       "18          7.000000    4.600000    26.900000     43.000000            0.0   \n",
       "19          7.444444    4.588889    26.733333     42.888889            0.0   \n",
       "20          7.888889    4.577778    26.566667     42.777778            0.0   \n",
       "21          8.333333    4.566667    26.400000     42.666667            0.0   \n",
       "22          8.777778    4.555556    26.233333     42.555556            0.0   \n",
       "23          9.222222    4.544444    26.066667     42.444444            0.0   \n",
       "24          9.666667    4.533333    25.900000     42.333333            0.0   \n",
       "25         10.111111    4.522222    25.733333     42.222222            0.0   \n",
       "26         10.555556    4.511111    25.566667     42.111111            0.0   \n",
       "27         11.000000    4.500000    25.400000     42.000000            0.0   \n",
       "28         12.555556    4.188889    25.033333     43.222222            0.0   \n",
       "29         14.111111    3.877778    24.666667     44.444444            0.0   \n",
       "...              ...         ...          ...           ...            ...   \n",
       "2491      354.077973    3.349123    20.149123     86.226121            0.0   \n",
       "2492      354.144250    3.350877    20.150877     86.218324            0.0   \n",
       "2493      354.210526    3.352632    20.152632     86.210526            0.0   \n",
       "2494      354.276803    3.354386    20.154386     86.202729            0.0   \n",
       "2495      354.343080    3.356140    20.156140     86.194932            0.0   \n",
       "2496      354.409357    3.357895    20.157895     86.187135            0.0   \n",
       "2497      354.475634    3.359649    20.159649     86.179337            0.0   \n",
       "2498      354.541910    3.361404    20.161404     86.171540            0.0   \n",
       "2499      354.608187    3.363158    20.163158     86.163743            0.0   \n",
       "2500      354.674464    3.364912    20.164912     86.155945            0.0   \n",
       "2501      354.740741    3.366667    20.166667     86.148148            0.0   \n",
       "2502      354.807018    3.368421    20.168421     86.140351            0.0   \n",
       "2503      354.873294    3.370175    20.170175     86.132554            0.0   \n",
       "2504      354.939571    3.371930    20.171930     86.124756            0.0   \n",
       "2505      355.005848    3.373684    20.173684     86.116959            0.0   \n",
       "2506      355.072125    3.375439    20.175439     86.109162            0.0   \n",
       "2507      355.138402    3.377193    20.177193     86.101365            0.0   \n",
       "2508      355.204678    3.378947    20.178947     86.093567            0.0   \n",
       "2509      355.270955    3.380702    20.180702     86.085770            0.0   \n",
       "2510      355.337232    3.382456    20.182456     86.077973            0.0   \n",
       "2511      355.403509    3.384211    20.184211     86.070175            0.0   \n",
       "2512      355.469786    3.385965    20.185965     86.062378            0.0   \n",
       "2513      355.536062    3.387719    20.187719     86.054581            0.0   \n",
       "2514      355.602339    3.389474    20.189474     86.046784            0.0   \n",
       "2515      355.668616    3.391228    20.191228     86.038986            0.0   \n",
       "2516      355.734893    3.392982    20.192982     86.031189            0.0   \n",
       "2517      355.801170    3.394737    20.194737     86.023392            0.0   \n",
       "2518      355.867446    3.396491    20.196491     86.015595            0.0   \n",
       "2519      355.933723    3.398246    20.198246     86.007797            0.0   \n",
       "2520      356.000000    3.400000    20.200000     86.000000            0.0   \n",
       "\n",
       "      dayofweek  is_holiday  timeofday  \n",
       "0             1           0   0.000000  \n",
       "1             1           0   0.333333  \n",
       "2             1           0   0.666667  \n",
       "3             1           0   1.000000  \n",
       "4             1           0   1.333333  \n",
       "5             1           0   1.666667  \n",
       "6             1           0   2.000000  \n",
       "7             1           0   2.333333  \n",
       "8             1           0   2.666667  \n",
       "9             1           0   3.000000  \n",
       "10            1           0   3.333333  \n",
       "11            1           0   3.666667  \n",
       "12            1           0   4.000000  \n",
       "13            1           0   4.333333  \n",
       "14            1           0   4.666667  \n",
       "15            1           0   5.000000  \n",
       "16            1           0   5.333333  \n",
       "17            1           0   5.666667  \n",
       "18            1           0   6.000000  \n",
       "19            1           0   6.333333  \n",
       "20            1           0   6.666667  \n",
       "21            1           0   7.000000  \n",
       "22            1           0   7.333333  \n",
       "23            1           0   7.666667  \n",
       "24            1           0   8.000000  \n",
       "25            1           0   8.333333  \n",
       "26            1           0   8.666667  \n",
       "27            1           0   9.000000  \n",
       "28            1           0   9.333333  \n",
       "29            1           0   9.666667  \n",
       "...         ...         ...        ...  \n",
       "2491          0           1  14.333333  \n",
       "2492          0           1  14.666667  \n",
       "2493          0           1  15.000000  \n",
       "2494          0           1  15.333333  \n",
       "2495          0           1  15.666667  \n",
       "2496          0           1  16.000000  \n",
       "2497          0           1  16.333333  \n",
       "2498          0           1  16.666667  \n",
       "2499          0           1  17.000000  \n",
       "2500          0           1  17.333333  \n",
       "2501          0           1  17.666667  \n",
       "2502          0           1  18.000000  \n",
       "2503          0           1  18.333333  \n",
       "2504          0           1  18.666667  \n",
       "2505          0           1  19.000000  \n",
       "2506          0           1  19.333333  \n",
       "2507          0           1  19.666667  \n",
       "2508          0           1  20.000000  \n",
       "2509          0           1  20.333333  \n",
       "2510          0           1  20.666667  \n",
       "2511          0           1  21.000000  \n",
       "2512          0           1  21.333333  \n",
       "2513          0           1  21.666667  \n",
       "2514          0           1  22.000000  \n",
       "2515          0           1  22.333333  \n",
       "2516          0           1  22.666667  \n",
       "2517          0           1  23.000000  \n",
       "2518          0           1  23.333333  \n",
       "2519          0           1  23.666667  \n",
       "2520          1           0   0.000000  \n",
       "\n",
       "[2521 rows x 48 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_volume_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (1, 0, 'cargocar')\n",
      "1 (1, 0, 'etc')\n",
      "2 (1, 0, 'motorcycle')\n",
      "3 (1, 0, 'privatecar')\n",
      "4 (1, 0, 'tot')\n",
      "5 (1, 0, 'unknowncar')\n",
      "6 (1, 1, 'cargocar')\n",
      "7 (1, 1, 'etc')\n",
      "8 (1, 1, 'motorcycle')\n",
      "9 (1, 1, 'privatecar')\n",
      "10 (1, 1, 'tot')\n",
      "11 (1, 1, 'unknowncar')\n",
      "12 (2, 0, 'cargocar')\n",
      "13 (2, 0, 'etc')\n",
      "14 (2, 0, 'motorcycle')\n",
      "15 (2, 0, 'privatecar')\n",
      "16 (2, 0, 'tot')\n",
      "17 (2, 0, 'unknowncar')\n",
      "18 (3, 0, 'cargocar')\n",
      "19 (3, 0, 'etc')\n",
      "20 (3, 0, 'motorcycle')\n",
      "21 (3, 0, 'privatecar')\n",
      "22 (3, 0, 'tot')\n",
      "23 (3, 0, 'unknowncar')\n",
      "24 (3, 1, 'cargocar')\n",
      "25 (3, 1, 'etc')\n",
      "26 (3, 1, 'motorcycle')\n",
      "27 (3, 1, 'privatecar')\n",
      "28 (3, 1, 'tot')\n",
      "29 (3, 1, 'unknowncar')\n",
      "30 ('A', 2)\n",
      "31 ('A', 3)\n",
      "32 ('B', 1)\n",
      "33 ('B', 3)\n",
      "34 ('C', 1)\n",
      "35 ('C', 3)\n",
      "36 date\n",
      "37 hour\n",
      "38 pressure\n",
      "39 sea_pressure\n",
      "40 wind_direction\n",
      "41 wind_speed\n",
      "42 temperature\n",
      "43 rel_humidity\n",
      "44 precipitation\n",
      "45 dayofweek\n",
      "46 is_holiday\n",
      "47 timeofday\n"
     ]
    }
   ],
   "source": [
    "for idx, i in enumerate(df_merged_volume.columns):\n",
    "    print(idx, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' OLD Function for converting it as stationary data'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' OLD Function for converting it as stationary data'''\n",
    "\n",
    "# # create a differenced series for Volumn and traffic time [modified from http://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/]\n",
    "# def difference(dataset, interval=1):\n",
    "#     diff_array = np.ndarray(np.shape(dataset))\n",
    "#     for i in range(interval, len(dataset)):\n",
    "#         diff_array[i][0:2] = dataset[i][0:2] - dataset[i - interval][0:2]  # only select index 0 & 1\n",
    "#     return diff_array[1:]  # eliminate the first row (all zeros)\n",
    "\n",
    "# # invert differenced value\n",
    "# def inverse_difference(history, y_hat, interval=1):\n",
    "#     return y_hat + history[-interval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select the time for training: 6:20-10:00 (5 + 6 timestamp) and 15:20-19:00 (5 + 6 timestamp)\n",
    "sel_rows = df_merged_volume_copy\n",
    "# sel_rows = df_merged_volume_copy[ ((df_merged_volume_copy.timeofday>= 6.3) & (df_merged_volume_copy.timeofday<10)) |\n",
    "#                             ((df_merged_volume_copy.timeofday>=15.3) & (df_merged_volume_copy.timeofday<19))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select using columns\n",
    "\n",
    "using_cols = [\n",
    "#                 \"(1, 0, 'cargocar')\",\n",
    "#                 \"(1, 0, 'etc')\",\n",
    "#                 \"(1, 0, 'motorcycle')\",\n",
    "#                 \"(1, 0, 'privatecar')\",\n",
    "#                 \"(1, 0, 'tot')\",\n",
    "#                 \"(1, 0, 'unknowncar')\",\n",
    "#                 \"(1, 1, 'cargocar')\",\n",
    "#                 \"(1, 1, 'etc')\",\n",
    "#                 \"(1, 1, 'motorcycle')\",\n",
    "#                 \"(1, 1, 'privatecar')\",\n",
    "#                 \"(1, 1, 'tot')\",\n",
    "#                 \"(1, 1, 'unknowncar')\",\n",
    "#                 \"(2, 0, 'cargocar')\",\n",
    "                \"(2, 0, 'etc')\",\n",
    "#                 \"(2, 0, 'motorcycle')\",\n",
    "#                 \"(2, 0, 'privatecar')\",\n",
    "                \"(2, 0, 'tot')\",\n",
    "#                 \"(2, 0, 'unknowncar')\",\n",
    "#                 \"(3, 0, 'cargocar')\",\n",
    "#                 \"(3, 0, 'etc')\",\n",
    "#                 \"(3, 0, 'motorcycle')\",\n",
    "#                 \"(3, 0, 'privatecar')\",\n",
    "#                 \"(3, 0, 'tot')\",\n",
    "#                 \"(3, 0, 'unknowncar')\",\n",
    "#                 \"(3, 1, 'cargocar')\",\n",
    "#                 \"(3, 1, 'etc')\",\n",
    "#                 \"(3, 1, 'motorcycle')\",\n",
    "#                 \"(3, 1, 'privatecar')\",\n",
    "#                 \"(3, 1, 'tot')\",\n",
    "#                 \"(3, 1, 'unknowncar')\",\n",
    "                \"('A', 2)\",\n",
    "#                 \"('A', 3)\",\n",
    "#                 \"('B', 1)\",\n",
    "#                 \"('B', 3)\",\n",
    "#                 \"('C', 1)\",\n",
    "#                 \"('C', 3)\",\n",
    "                'date',\n",
    "                'hour',\n",
    "                'pressure',\n",
    "                'sea_pressure',\n",
    "                'wind_direction',\n",
    "                'wind_speed',\n",
    "                'temperature',\n",
    "                'rel_humidity',\n",
    "                'precipitation',\n",
    "                'dayofweek',\n",
    "                'is_holiday',\n",
    "                'timeofday'\n",
    "              ]\n",
    "\n",
    "sel_rows = sel_rows[using_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(2, 0, 'etc')</th>\n",
       "      <th>(2, 0, 'tot')</th>\n",
       "      <th>('A', 2)</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>pressure</th>\n",
       "      <th>sea_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rel_humidity</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>timeofday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-8.512500</td>\n",
       "      <td>2016-09-20 00:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1013.233333</td>\n",
       "      <td>1018.233333</td>\n",
       "      <td>342.444444</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>21.411111</td>\n",
       "      <td>66.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.512500</td>\n",
       "      <td>2016-09-20 00:40:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1013.266667</td>\n",
       "      <td>1018.266667</td>\n",
       "      <td>343.888889</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>21.722222</td>\n",
       "      <td>65.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.710000</td>\n",
       "      <td>2016-09-20 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1013.300000</td>\n",
       "      <td>1018.300000</td>\n",
       "      <td>345.333333</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.033333</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.710000</td>\n",
       "      <td>2016-09-20 01:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1013.333333</td>\n",
       "      <td>1018.333333</td>\n",
       "      <td>346.777778</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>22.344444</td>\n",
       "      <td>63.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.940000</td>\n",
       "      <td>2016-09-20 01:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1013.366667</td>\n",
       "      <td>1018.366667</td>\n",
       "      <td>348.222222</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>22.655556</td>\n",
       "      <td>62.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.395000</td>\n",
       "      <td>2016-09-20 02:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1013.400000</td>\n",
       "      <td>1018.400000</td>\n",
       "      <td>349.666667</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>22.966667</td>\n",
       "      <td>61.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.395000</td>\n",
       "      <td>2016-09-20 02:20:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1013.433333</td>\n",
       "      <td>1018.433333</td>\n",
       "      <td>351.111111</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>23.277778</td>\n",
       "      <td>60.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.767500</td>\n",
       "      <td>2016-09-20 02:40:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1013.466667</td>\n",
       "      <td>1018.466667</td>\n",
       "      <td>352.555556</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>23.588889</td>\n",
       "      <td>59.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.767500</td>\n",
       "      <td>2016-09-20 03:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1013.500000</td>\n",
       "      <td>1018.500000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.905000</td>\n",
       "      <td>2016-09-20 03:20:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1013.355556</td>\n",
       "      <td>1018.355556</td>\n",
       "      <td>315.444444</td>\n",
       "      <td>2.822222</td>\n",
       "      <td>24.233333</td>\n",
       "      <td>56.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.450000</td>\n",
       "      <td>2016-09-20 03:40:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1013.211111</td>\n",
       "      <td>1018.211111</td>\n",
       "      <td>276.888889</td>\n",
       "      <td>3.044444</td>\n",
       "      <td>24.566667</td>\n",
       "      <td>54.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-31.930000</td>\n",
       "      <td>2016-09-20 04:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1013.066667</td>\n",
       "      <td>1018.066667</td>\n",
       "      <td>238.333333</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>24.900000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.410000</td>\n",
       "      <td>2016-09-20 04:20:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1012.922222</td>\n",
       "      <td>1017.922222</td>\n",
       "      <td>199.777778</td>\n",
       "      <td>3.488889</td>\n",
       "      <td>25.233333</td>\n",
       "      <td>51.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.620000</td>\n",
       "      <td>2016-09-20 04:40:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1012.777778</td>\n",
       "      <td>1017.777778</td>\n",
       "      <td>161.222222</td>\n",
       "      <td>3.711111</td>\n",
       "      <td>25.566667</td>\n",
       "      <td>49.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>2016-09-20 05:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1012.633333</td>\n",
       "      <td>1017.633333</td>\n",
       "      <td>122.666667</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>2016-09-20 05:20:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1012.488889</td>\n",
       "      <td>1017.488889</td>\n",
       "      <td>84.111111</td>\n",
       "      <td>4.155556</td>\n",
       "      <td>26.233333</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.055000</td>\n",
       "      <td>2016-09-20 05:40:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1012.344444</td>\n",
       "      <td>1017.344444</td>\n",
       "      <td>45.555556</td>\n",
       "      <td>4.377778</td>\n",
       "      <td>26.566667</td>\n",
       "      <td>44.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.582500</td>\n",
       "      <td>2016-09-20 06:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1012.200000</td>\n",
       "      <td>1017.200000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>26.900000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>22.582500</td>\n",
       "      <td>2016-09-20 06:20:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1012.244444</td>\n",
       "      <td>1017.244444</td>\n",
       "      <td>7.444444</td>\n",
       "      <td>4.588889</td>\n",
       "      <td>26.733333</td>\n",
       "      <td>42.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-40.840000</td>\n",
       "      <td>2016-09-20 06:40:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1012.288889</td>\n",
       "      <td>1017.288889</td>\n",
       "      <td>7.888889</td>\n",
       "      <td>4.577778</td>\n",
       "      <td>26.566667</td>\n",
       "      <td>42.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.645000</td>\n",
       "      <td>2016-09-20 07:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>1012.333333</td>\n",
       "      <td>1017.333333</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>26.400000</td>\n",
       "      <td>42.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-4.975000</td>\n",
       "      <td>2016-09-20 07:20:00</td>\n",
       "      <td>7</td>\n",
       "      <td>1012.377778</td>\n",
       "      <td>1017.377778</td>\n",
       "      <td>8.777778</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>26.233333</td>\n",
       "      <td>42.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.285000</td>\n",
       "      <td>2016-09-20 07:40:00</td>\n",
       "      <td>7</td>\n",
       "      <td>1012.422222</td>\n",
       "      <td>1017.422222</td>\n",
       "      <td>9.222222</td>\n",
       "      <td>4.544444</td>\n",
       "      <td>26.066667</td>\n",
       "      <td>42.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-5.361667</td>\n",
       "      <td>2016-09-20 08:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>1012.466667</td>\n",
       "      <td>1017.466667</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>42.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.203030</td>\n",
       "      <td>2016-09-20 08:20:00</td>\n",
       "      <td>8</td>\n",
       "      <td>1012.511111</td>\n",
       "      <td>1017.511111</td>\n",
       "      <td>10.111111</td>\n",
       "      <td>4.522222</td>\n",
       "      <td>25.733333</td>\n",
       "      <td>42.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.908373</td>\n",
       "      <td>2016-09-20 08:40:00</td>\n",
       "      <td>8</td>\n",
       "      <td>1012.555556</td>\n",
       "      <td>1017.555556</td>\n",
       "      <td>10.555556</td>\n",
       "      <td>4.511111</td>\n",
       "      <td>25.566667</td>\n",
       "      <td>42.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>6.003089</td>\n",
       "      <td>2016-09-20 09:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>1012.600000</td>\n",
       "      <td>1017.600000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-12.227826</td>\n",
       "      <td>2016-09-20 09:20:00</td>\n",
       "      <td>9</td>\n",
       "      <td>1012.722222</td>\n",
       "      <td>1017.722222</td>\n",
       "      <td>12.555556</td>\n",
       "      <td>4.188889</td>\n",
       "      <td>25.033333</td>\n",
       "      <td>43.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>14.685385</td>\n",
       "      <td>2016-09-20 09:40:00</td>\n",
       "      <td>9</td>\n",
       "      <td>1012.844444</td>\n",
       "      <td>1017.844444</td>\n",
       "      <td>14.111111</td>\n",
       "      <td>3.877778</td>\n",
       "      <td>24.666667</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-17.635385</td>\n",
       "      <td>2016-09-20 10:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>1012.966667</td>\n",
       "      <td>1017.966667</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>24.300000</td>\n",
       "      <td>45.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-10.765227</td>\n",
       "      <td>2016-10-24 14:20:00</td>\n",
       "      <td>14</td>\n",
       "      <td>1010.786550</td>\n",
       "      <td>1015.786550</td>\n",
       "      <td>354.077973</td>\n",
       "      <td>3.349123</td>\n",
       "      <td>20.149123</td>\n",
       "      <td>86.226121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.551974</td>\n",
       "      <td>2016-10-24 14:40:00</td>\n",
       "      <td>14</td>\n",
       "      <td>1010.780117</td>\n",
       "      <td>1015.780117</td>\n",
       "      <td>354.144250</td>\n",
       "      <td>3.350877</td>\n",
       "      <td>20.150877</td>\n",
       "      <td>86.218324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.342749</td>\n",
       "      <td>2016-10-24 15:00:00</td>\n",
       "      <td>15</td>\n",
       "      <td>1010.773684</td>\n",
       "      <td>1015.773684</td>\n",
       "      <td>354.210526</td>\n",
       "      <td>3.352632</td>\n",
       "      <td>20.152632</td>\n",
       "      <td>86.210526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-43.298586</td>\n",
       "      <td>2016-10-24 15:20:00</td>\n",
       "      <td>15</td>\n",
       "      <td>1010.767251</td>\n",
       "      <td>1015.767251</td>\n",
       "      <td>354.276803</td>\n",
       "      <td>3.354386</td>\n",
       "      <td>20.154386</td>\n",
       "      <td>86.202729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-7.185303</td>\n",
       "      <td>2016-10-24 15:40:00</td>\n",
       "      <td>15</td>\n",
       "      <td>1010.760819</td>\n",
       "      <td>1015.760819</td>\n",
       "      <td>354.343080</td>\n",
       "      <td>3.356140</td>\n",
       "      <td>20.156140</td>\n",
       "      <td>86.194932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>42.616333</td>\n",
       "      <td>2016-10-24 16:00:00</td>\n",
       "      <td>16</td>\n",
       "      <td>1010.754386</td>\n",
       "      <td>1015.754386</td>\n",
       "      <td>354.409357</td>\n",
       "      <td>3.357895</td>\n",
       "      <td>20.157895</td>\n",
       "      <td>86.187135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-19.589667</td>\n",
       "      <td>2016-10-24 16:20:00</td>\n",
       "      <td>16</td>\n",
       "      <td>1010.747953</td>\n",
       "      <td>1015.747953</td>\n",
       "      <td>354.475634</td>\n",
       "      <td>3.359649</td>\n",
       "      <td>20.159649</td>\n",
       "      <td>86.179337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-8.917222</td>\n",
       "      <td>2016-10-24 16:40:00</td>\n",
       "      <td>16</td>\n",
       "      <td>1010.741520</td>\n",
       "      <td>1015.741520</td>\n",
       "      <td>354.541910</td>\n",
       "      <td>3.361404</td>\n",
       "      <td>20.161404</td>\n",
       "      <td>86.171540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>26.232222</td>\n",
       "      <td>2016-10-24 17:00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>1010.735088</td>\n",
       "      <td>1015.735088</td>\n",
       "      <td>354.608187</td>\n",
       "      <td>3.363158</td>\n",
       "      <td>20.163158</td>\n",
       "      <td>86.163743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-16.053333</td>\n",
       "      <td>2016-10-24 17:20:00</td>\n",
       "      <td>17</td>\n",
       "      <td>1010.728655</td>\n",
       "      <td>1015.728655</td>\n",
       "      <td>354.674464</td>\n",
       "      <td>3.364912</td>\n",
       "      <td>20.164912</td>\n",
       "      <td>86.155945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.139167</td>\n",
       "      <td>2016-10-24 17:40:00</td>\n",
       "      <td>17</td>\n",
       "      <td>1010.722222</td>\n",
       "      <td>1015.722222</td>\n",
       "      <td>354.740741</td>\n",
       "      <td>3.366667</td>\n",
       "      <td>20.166667</td>\n",
       "      <td>86.148148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>11.297500</td>\n",
       "      <td>2016-10-24 18:00:00</td>\n",
       "      <td>18</td>\n",
       "      <td>1010.715789</td>\n",
       "      <td>1015.715789</td>\n",
       "      <td>354.807018</td>\n",
       "      <td>3.368421</td>\n",
       "      <td>20.168421</td>\n",
       "      <td>86.140351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-3.789000</td>\n",
       "      <td>2016-10-24 18:20:00</td>\n",
       "      <td>18</td>\n",
       "      <td>1010.709357</td>\n",
       "      <td>1015.709357</td>\n",
       "      <td>354.873294</td>\n",
       "      <td>3.370175</td>\n",
       "      <td>20.170175</td>\n",
       "      <td>86.132554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1.500250</td>\n",
       "      <td>2016-10-24 18:40:00</td>\n",
       "      <td>18</td>\n",
       "      <td>1010.702924</td>\n",
       "      <td>1015.702924</td>\n",
       "      <td>354.939571</td>\n",
       "      <td>3.371930</td>\n",
       "      <td>20.171930</td>\n",
       "      <td>86.124756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.755179</td>\n",
       "      <td>2016-10-24 19:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>1010.696491</td>\n",
       "      <td>1015.696491</td>\n",
       "      <td>355.005848</td>\n",
       "      <td>3.373684</td>\n",
       "      <td>20.173684</td>\n",
       "      <td>86.116959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-2.492857</td>\n",
       "      <td>2016-10-24 19:20:00</td>\n",
       "      <td>19</td>\n",
       "      <td>1010.690058</td>\n",
       "      <td>1015.690058</td>\n",
       "      <td>355.072125</td>\n",
       "      <td>3.375439</td>\n",
       "      <td>20.175439</td>\n",
       "      <td>86.109162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-3.844821</td>\n",
       "      <td>2016-10-24 19:40:00</td>\n",
       "      <td>19</td>\n",
       "      <td>1010.683626</td>\n",
       "      <td>1015.683626</td>\n",
       "      <td>355.138402</td>\n",
       "      <td>3.377193</td>\n",
       "      <td>20.177193</td>\n",
       "      <td>86.101365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.506250</td>\n",
       "      <td>2016-10-24 20:00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>1010.677193</td>\n",
       "      <td>1015.677193</td>\n",
       "      <td>355.204678</td>\n",
       "      <td>3.378947</td>\n",
       "      <td>20.178947</td>\n",
       "      <td>86.093567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-23.948000</td>\n",
       "      <td>2016-10-24 20:20:00</td>\n",
       "      <td>20</td>\n",
       "      <td>1010.670760</td>\n",
       "      <td>1015.670760</td>\n",
       "      <td>355.270955</td>\n",
       "      <td>3.380702</td>\n",
       "      <td>20.180702</td>\n",
       "      <td>86.085770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.863000</td>\n",
       "      <td>2016-10-24 20:40:00</td>\n",
       "      <td>20</td>\n",
       "      <td>1010.664327</td>\n",
       "      <td>1015.664327</td>\n",
       "      <td>355.337232</td>\n",
       "      <td>3.382456</td>\n",
       "      <td>20.182456</td>\n",
       "      <td>86.077973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-7.795000</td>\n",
       "      <td>2016-10-24 21:00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>1010.657895</td>\n",
       "      <td>1015.657895</td>\n",
       "      <td>355.403509</td>\n",
       "      <td>3.384211</td>\n",
       "      <td>20.184211</td>\n",
       "      <td>86.070175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-7.778333</td>\n",
       "      <td>2016-10-24 21:20:00</td>\n",
       "      <td>21</td>\n",
       "      <td>1010.651462</td>\n",
       "      <td>1015.651462</td>\n",
       "      <td>355.469786</td>\n",
       "      <td>3.385965</td>\n",
       "      <td>20.185965</td>\n",
       "      <td>86.062378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.149167</td>\n",
       "      <td>2016-10-24 21:40:00</td>\n",
       "      <td>21</td>\n",
       "      <td>1010.645029</td>\n",
       "      <td>1015.645029</td>\n",
       "      <td>355.536062</td>\n",
       "      <td>3.387719</td>\n",
       "      <td>20.187719</td>\n",
       "      <td>86.054581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.906071</td>\n",
       "      <td>2016-10-24 22:00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>1010.638596</td>\n",
       "      <td>1015.638596</td>\n",
       "      <td>355.602339</td>\n",
       "      <td>3.389474</td>\n",
       "      <td>20.189474</td>\n",
       "      <td>86.046784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.243929</td>\n",
       "      <td>2016-10-24 22:20:00</td>\n",
       "      <td>22</td>\n",
       "      <td>1010.632164</td>\n",
       "      <td>1015.632164</td>\n",
       "      <td>355.668616</td>\n",
       "      <td>3.391228</td>\n",
       "      <td>20.191228</td>\n",
       "      <td>86.038986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-16.537500</td>\n",
       "      <td>2016-10-24 22:40:00</td>\n",
       "      <td>22</td>\n",
       "      <td>1010.625731</td>\n",
       "      <td>1015.625731</td>\n",
       "      <td>355.734893</td>\n",
       "      <td>3.392982</td>\n",
       "      <td>20.192982</td>\n",
       "      <td>86.031189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-5.245000</td>\n",
       "      <td>2016-10-24 23:00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>1010.619298</td>\n",
       "      <td>1015.619298</td>\n",
       "      <td>355.801170</td>\n",
       "      <td>3.394737</td>\n",
       "      <td>20.194737</td>\n",
       "      <td>86.023392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-2.390000</td>\n",
       "      <td>2016-10-24 23:20:00</td>\n",
       "      <td>23</td>\n",
       "      <td>1010.612865</td>\n",
       "      <td>1015.612865</td>\n",
       "      <td>355.867446</td>\n",
       "      <td>3.396491</td>\n",
       "      <td>20.196491</td>\n",
       "      <td>86.015595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>2016-10-24 23:40:00</td>\n",
       "      <td>23</td>\n",
       "      <td>1010.606433</td>\n",
       "      <td>1015.606433</td>\n",
       "      <td>355.933723</td>\n",
       "      <td>3.398246</td>\n",
       "      <td>20.198246</td>\n",
       "      <td>86.007797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016-10-25 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1010.600000</td>\n",
       "      <td>1015.600000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2520 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      (2, 0, 'etc')  (2, 0, 'tot')   ('A', 2)                date  hour  \\\n",
       "1               2.0            2.0  -8.512500 2016-09-20 00:20:00     0   \n",
       "2               0.0            0.0  -8.512500 2016-09-20 00:40:00     0   \n",
       "3              -2.0           -2.0  -1.710000 2016-09-20 01:00:00     1   \n",
       "4               1.0            1.0  -1.710000 2016-09-20 01:20:00     1   \n",
       "5              -1.0           -1.0   7.940000 2016-09-20 01:40:00     1   \n",
       "6               0.0            0.0   8.395000 2016-09-20 02:00:00     2   \n",
       "7               0.0            0.0   8.395000 2016-09-20 02:20:00     2   \n",
       "8               0.0            0.0 -15.767500 2016-09-20 02:40:00     2   \n",
       "9               0.0            0.0 -15.767500 2016-09-20 03:00:00     3   \n",
       "10              0.0            0.0   1.905000 2016-09-20 03:20:00     3   \n",
       "11              0.0            0.0  29.450000 2016-09-20 03:40:00     3   \n",
       "12              0.0            0.0 -31.930000 2016-09-20 04:00:00     4   \n",
       "13              0.0            0.0  17.410000 2016-09-20 04:20:00     4   \n",
       "14              0.0            0.0 -13.620000 2016-09-20 04:40:00     4   \n",
       "15              0.0            5.0  -0.175000 2016-09-20 05:00:00     5   \n",
       "16              3.0           13.0  -0.175000 2016-09-20 05:20:00     5   \n",
       "17              1.0            3.0   1.055000 2016-09-20 05:40:00     5   \n",
       "18             -1.0           12.0  22.582500 2016-09-20 06:00:00     6   \n",
       "19              4.0           -2.0  22.582500 2016-09-20 06:20:00     6   \n",
       "20              6.0           23.0 -40.840000 2016-09-20 06:40:00     6   \n",
       "21             15.0           25.0   9.645000 2016-09-20 07:00:00     7   \n",
       "22              6.0            7.0  -4.975000 2016-09-20 07:20:00     7   \n",
       "23              2.0            7.0   7.285000 2016-09-20 07:40:00     7   \n",
       "24             -3.0           19.0  -5.361667 2016-09-20 08:00:00     8   \n",
       "25              6.0           -1.0  11.203030 2016-09-20 08:20:00     8   \n",
       "26             -6.0            1.0   6.908373 2016-09-20 08:40:00     8   \n",
       "27             -7.0           -7.0   6.003089 2016-09-20 09:00:00     9   \n",
       "28             -1.0           -6.0 -12.227826 2016-09-20 09:20:00     9   \n",
       "29             -1.0          -12.0  14.685385 2016-09-20 09:40:00     9   \n",
       "30             -4.0           -2.0 -17.635385 2016-09-20 10:00:00    10   \n",
       "...             ...            ...        ...                 ...   ...   \n",
       "2491           -2.0           -6.0 -10.765227 2016-10-24 14:20:00    14   \n",
       "2492            5.0            4.0  20.551974 2016-10-24 14:40:00    14   \n",
       "2493           -5.0            2.0  25.342749 2016-10-24 15:00:00    15   \n",
       "2494            9.0            6.0 -43.298586 2016-10-24 15:20:00    15   \n",
       "2495           -4.0           -2.0  -7.185303 2016-10-24 15:40:00    15   \n",
       "2496           -1.0           -2.0  42.616333 2016-10-24 16:00:00    16   \n",
       "2497           -3.0            6.0 -19.589667 2016-10-24 16:20:00    16   \n",
       "2498            5.0            5.0  -8.917222 2016-10-24 16:40:00    16   \n",
       "2499           -3.0           -6.0  26.232222 2016-10-24 17:00:00    17   \n",
       "2500           -1.0          -14.0 -16.053333 2016-10-24 17:20:00    17   \n",
       "2501           11.0            1.0 -15.139167 2016-10-24 17:40:00    17   \n",
       "2502          -10.0           -8.0  11.297500 2016-10-24 18:00:00    18   \n",
       "2503           -4.0           -8.0  -3.789000 2016-10-24 18:20:00    18   \n",
       "2504            2.0           -8.0   1.500250 2016-10-24 18:40:00    18   \n",
       "2505            3.0           14.0   0.755179 2016-10-24 19:00:00    19   \n",
       "2506           -4.0          -15.0  -2.492857 2016-10-24 19:20:00    19   \n",
       "2507           -7.0           -7.0  -3.844821 2016-10-24 19:40:00    19   \n",
       "2508            7.0            8.0  15.506250 2016-10-24 20:00:00    20   \n",
       "2509           -3.0          -10.0 -23.948000 2016-10-24 20:20:00    20   \n",
       "2510            3.0           13.0  24.863000 2016-10-24 20:40:00    20   \n",
       "2511           -4.0           -9.0  -7.795000 2016-10-24 21:00:00    21   \n",
       "2512            1.0           -3.0  -7.778333 2016-10-24 21:20:00    21   \n",
       "2513           -5.0          -10.0  -0.149167 2016-10-24 21:40:00    21   \n",
       "2514           -1.0            2.0   4.906071 2016-10-24 22:00:00    22   \n",
       "2515            3.0            0.0  10.243929 2016-10-24 22:20:00    22   \n",
       "2516           -3.0           -1.0 -16.537500 2016-10-24 22:40:00    22   \n",
       "2517            1.0          -12.0  -5.245000 2016-10-24 23:00:00    23   \n",
       "2518           -4.0           -4.0  -2.390000 2016-10-24 23:20:00    23   \n",
       "2519            2.0            6.0   5.370000 2016-10-24 23:40:00    23   \n",
       "2520           -2.0           -9.0   0.000000 2016-10-25 00:00:00     0   \n",
       "\n",
       "         pressure  sea_pressure  wind_direction  wind_speed  temperature  \\\n",
       "1     1013.233333   1018.233333      342.444444    3.400000    21.411111   \n",
       "2     1013.266667   1018.266667      343.888889    3.300000    21.722222   \n",
       "3     1013.300000   1018.300000      345.333333    3.200000    22.033333   \n",
       "4     1013.333333   1018.333333      346.777778    3.100000    22.344444   \n",
       "5     1013.366667   1018.366667      348.222222    3.000000    22.655556   \n",
       "6     1013.400000   1018.400000      349.666667    2.900000    22.966667   \n",
       "7     1013.433333   1018.433333      351.111111    2.800000    23.277778   \n",
       "8     1013.466667   1018.466667      352.555556    2.700000    23.588889   \n",
       "9     1013.500000   1018.500000      354.000000    2.600000    23.900000   \n",
       "10    1013.355556   1018.355556      315.444444    2.822222    24.233333   \n",
       "11    1013.211111   1018.211111      276.888889    3.044444    24.566667   \n",
       "12    1013.066667   1018.066667      238.333333    3.266667    24.900000   \n",
       "13    1012.922222   1017.922222      199.777778    3.488889    25.233333   \n",
       "14    1012.777778   1017.777778      161.222222    3.711111    25.566667   \n",
       "15    1012.633333   1017.633333      122.666667    3.933333    25.900000   \n",
       "16    1012.488889   1017.488889       84.111111    4.155556    26.233333   \n",
       "17    1012.344444   1017.344444       45.555556    4.377778    26.566667   \n",
       "18    1012.200000   1017.200000        7.000000    4.600000    26.900000   \n",
       "19    1012.244444   1017.244444        7.444444    4.588889    26.733333   \n",
       "20    1012.288889   1017.288889        7.888889    4.577778    26.566667   \n",
       "21    1012.333333   1017.333333        8.333333    4.566667    26.400000   \n",
       "22    1012.377778   1017.377778        8.777778    4.555556    26.233333   \n",
       "23    1012.422222   1017.422222        9.222222    4.544444    26.066667   \n",
       "24    1012.466667   1017.466667        9.666667    4.533333    25.900000   \n",
       "25    1012.511111   1017.511111       10.111111    4.522222    25.733333   \n",
       "26    1012.555556   1017.555556       10.555556    4.511111    25.566667   \n",
       "27    1012.600000   1017.600000       11.000000    4.500000    25.400000   \n",
       "28    1012.722222   1017.722222       12.555556    4.188889    25.033333   \n",
       "29    1012.844444   1017.844444       14.111111    3.877778    24.666667   \n",
       "30    1012.966667   1017.966667       15.666667    3.566667    24.300000   \n",
       "...           ...           ...             ...         ...          ...   \n",
       "2491  1010.786550   1015.786550      354.077973    3.349123    20.149123   \n",
       "2492  1010.780117   1015.780117      354.144250    3.350877    20.150877   \n",
       "2493  1010.773684   1015.773684      354.210526    3.352632    20.152632   \n",
       "2494  1010.767251   1015.767251      354.276803    3.354386    20.154386   \n",
       "2495  1010.760819   1015.760819      354.343080    3.356140    20.156140   \n",
       "2496  1010.754386   1015.754386      354.409357    3.357895    20.157895   \n",
       "2497  1010.747953   1015.747953      354.475634    3.359649    20.159649   \n",
       "2498  1010.741520   1015.741520      354.541910    3.361404    20.161404   \n",
       "2499  1010.735088   1015.735088      354.608187    3.363158    20.163158   \n",
       "2500  1010.728655   1015.728655      354.674464    3.364912    20.164912   \n",
       "2501  1010.722222   1015.722222      354.740741    3.366667    20.166667   \n",
       "2502  1010.715789   1015.715789      354.807018    3.368421    20.168421   \n",
       "2503  1010.709357   1015.709357      354.873294    3.370175    20.170175   \n",
       "2504  1010.702924   1015.702924      354.939571    3.371930    20.171930   \n",
       "2505  1010.696491   1015.696491      355.005848    3.373684    20.173684   \n",
       "2506  1010.690058   1015.690058      355.072125    3.375439    20.175439   \n",
       "2507  1010.683626   1015.683626      355.138402    3.377193    20.177193   \n",
       "2508  1010.677193   1015.677193      355.204678    3.378947    20.178947   \n",
       "2509  1010.670760   1015.670760      355.270955    3.380702    20.180702   \n",
       "2510  1010.664327   1015.664327      355.337232    3.382456    20.182456   \n",
       "2511  1010.657895   1015.657895      355.403509    3.384211    20.184211   \n",
       "2512  1010.651462   1015.651462      355.469786    3.385965    20.185965   \n",
       "2513  1010.645029   1015.645029      355.536062    3.387719    20.187719   \n",
       "2514  1010.638596   1015.638596      355.602339    3.389474    20.189474   \n",
       "2515  1010.632164   1015.632164      355.668616    3.391228    20.191228   \n",
       "2516  1010.625731   1015.625731      355.734893    3.392982    20.192982   \n",
       "2517  1010.619298   1015.619298      355.801170    3.394737    20.194737   \n",
       "2518  1010.612865   1015.612865      355.867446    3.396491    20.196491   \n",
       "2519  1010.606433   1015.606433      355.933723    3.398246    20.198246   \n",
       "2520  1010.600000   1015.600000      356.000000    3.400000    20.200000   \n",
       "\n",
       "      rel_humidity  precipitation  dayofweek  is_holiday  timeofday  \n",
       "1        66.888889            0.0          1           0   0.333333  \n",
       "2        65.777778            0.0          1           0   0.666667  \n",
       "3        64.666667            0.0          1           0   1.000000  \n",
       "4        63.555556            0.0          1           0   1.333333  \n",
       "5        62.444444            0.0          1           0   1.666667  \n",
       "6        61.333333            0.0          1           0   2.000000  \n",
       "7        60.222222            0.0          1           0   2.333333  \n",
       "8        59.111111            0.0          1           0   2.666667  \n",
       "9        58.000000            0.0          1           0   3.000000  \n",
       "10       56.333333            0.0          1           0   3.333333  \n",
       "11       54.666667            0.0          1           0   3.666667  \n",
       "12       53.000000            0.0          1           0   4.000000  \n",
       "13       51.333333            0.0          1           0   4.333333  \n",
       "14       49.666667            0.0          1           0   4.666667  \n",
       "15       48.000000            0.0          1           0   5.000000  \n",
       "16       46.333333            0.0          1           0   5.333333  \n",
       "17       44.666667            0.0          1           0   5.666667  \n",
       "18       43.000000            0.0          1           0   6.000000  \n",
       "19       42.888889            0.0          1           0   6.333333  \n",
       "20       42.777778            0.0          1           0   6.666667  \n",
       "21       42.666667            0.0          1           0   7.000000  \n",
       "22       42.555556            0.0          1           0   7.333333  \n",
       "23       42.444444            0.0          1           0   7.666667  \n",
       "24       42.333333            0.0          1           0   8.000000  \n",
       "25       42.222222            0.0          1           0   8.333333  \n",
       "26       42.111111            0.0          1           0   8.666667  \n",
       "27       42.000000            0.0          1           0   9.000000  \n",
       "28       43.222222            0.0          1           0   9.333333  \n",
       "29       44.444444            0.0          1           0   9.666667  \n",
       "30       45.666667            0.0          1           0  10.000000  \n",
       "...            ...            ...        ...         ...        ...  \n",
       "2491     86.226121            0.0          0           1  14.333333  \n",
       "2492     86.218324            0.0          0           1  14.666667  \n",
       "2493     86.210526            0.0          0           1  15.000000  \n",
       "2494     86.202729            0.0          0           1  15.333333  \n",
       "2495     86.194932            0.0          0           1  15.666667  \n",
       "2496     86.187135            0.0          0           1  16.000000  \n",
       "2497     86.179337            0.0          0           1  16.333333  \n",
       "2498     86.171540            0.0          0           1  16.666667  \n",
       "2499     86.163743            0.0          0           1  17.000000  \n",
       "2500     86.155945            0.0          0           1  17.333333  \n",
       "2501     86.148148            0.0          0           1  17.666667  \n",
       "2502     86.140351            0.0          0           1  18.000000  \n",
       "2503     86.132554            0.0          0           1  18.333333  \n",
       "2504     86.124756            0.0          0           1  18.666667  \n",
       "2505     86.116959            0.0          0           1  19.000000  \n",
       "2506     86.109162            0.0          0           1  19.333333  \n",
       "2507     86.101365            0.0          0           1  19.666667  \n",
       "2508     86.093567            0.0          0           1  20.000000  \n",
       "2509     86.085770            0.0          0           1  20.333333  \n",
       "2510     86.077973            0.0          0           1  20.666667  \n",
       "2511     86.070175            0.0          0           1  21.000000  \n",
       "2512     86.062378            0.0          0           1  21.333333  \n",
       "2513     86.054581            0.0          0           1  21.666667  \n",
       "2514     86.046784            0.0          0           1  22.000000  \n",
       "2515     86.038986            0.0          0           1  22.333333  \n",
       "2516     86.031189            0.0          0           1  22.666667  \n",
       "2517     86.023392            0.0          0           1  23.000000  \n",
       "2518     86.015595            0.0          0           1  23.333333  \n",
       "2519     86.007797            0.0          0           1  23.666667  \n",
       "2520     86.000000            0.0          1           0   0.000000  \n",
       "\n",
       "[2520 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_rows = sel_rows[1:]\n",
    "sel_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split to train and test set\n",
    "train_rows = sel_rows[: -22*]\n",
    "test_rows = sel_rows[-22*2:] # reserve 2 days for test\n",
    "\n",
    "# del date column for eliminate datetime\n",
    "del train_rows['date']\n",
    "del test_rows['date']\n",
    "\n",
    "# get numpy array from panda dataframe\n",
    "train_arr = train_rows.values\n",
    "test_arr = test_rows.values\n",
    "\n",
    "# np.shape(train_arr)\n",
    "# Out:\n",
    "# (726, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scale feature array to range -1 to 1\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler = scaler.fit(train_arr)\n",
    "train_scaled_arr = scaler.transform(train_arr)\n",
    "\n",
    "test_scaled_arr = scaler.transform(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07407407,  0.02290076, -0.00362976,  0.83333333,  0.09170719,\n",
       "         0.09125637,  0.98183371, -0.09828989, -0.41798835,  0.58013324,\n",
       "        -1.        , -1.        ,  0.        ,  0.78378378],\n",
       "       [ 0.37037037,  0.2519084 ,  0.0028705 ,  0.83333333,  0.09076042,\n",
       "         0.09032258,  0.98220827, -0.0977918 , -0.41778631,  0.57985421,\n",
       "        -1.        , -1.        ,  0.        ,  0.83783784],\n",
       "       [-0.40740741,  0.11450382,  0.19085073,  1.        ,  0.08981366,\n",
       "         0.08938879,  0.98258283, -0.09729371, -0.41758427,  0.57957518,\n",
       "        -1.        , -1.        ,  0.        ,  0.89189189],\n",
       "       [-0.18518519,  0.11450382,  0.08357685,  1.        ,  0.08886689,\n",
       "         0.08845501,  0.98295739, -0.09679562, -0.41738223,  0.57929615,\n",
       "        -1.        , -1.        ,  0.        ,  0.94594595],\n",
       "       [ 0.03703704,  0.11450382,  0.12118653,  1.        ,  0.08792013,\n",
       "         0.08752122,  0.98333196, -0.09629753, -0.41718019,  0.57901713,\n",
       "        -1.        , -1.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scaled_arr[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample subsequence from the time series\n",
    "train_seqs = []\n",
    "nSegments = len(train_scaled_arr)//11 # each segment holds 4hr data (12 datapoints, 20min each)\n",
    "for segment in range(nSegments):\n",
    "    for t in range(6):\n",
    "        startIdx = segment*11 + t\n",
    "        train_seqs.append(train_scaled_arr[startIdx: startIdx+6])  # append 6 timestamps each time (5 timestamps for x, 1 timestamp for y)\n",
    "train_seqs = np.stack(train_seqs)\n",
    "\n",
    "test_seqs = []\n",
    "nSegments = len(test_scaled_arr)//11 # each segment holds 4hr data (12 datapoints, 20min each)\n",
    "for segment in range(nSegments):\n",
    "    for t in range(6):\n",
    "        startIdx = segment*11 + t\n",
    "        test_seqs.append(test_scaled_arr[startIdx: startIdx+6])\n",
    "test_seqs = np.stack(test_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_seqs[:,:,0:6].shape  # checking for Index 0 to index 5 (6 values) for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keras\n",
    "#https://keras.io/getting-started/sequential-model-guide/#examples\n",
    "input_dim = len(using_cols) - 1  # The minus 1 is for deleted \"date\" feature\n",
    "output_dim = 3  # 2 vloumns and 1 traffic time output only\n",
    "timesteps = 5 # use 5 timesteps to predict the 6th\n",
    "\n",
    "x_train, y_train = train_seqs[:, 0:-1], train_seqs[:, -1,0:3]  # 0:3 is for output dimensions\n",
    "x_test , y_test  =  test_seqs[:, 0:-1],  test_seqs[:, -1,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396, 3)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "loss_fuc = 'mean_squared_error'\n",
    "\n",
    "# construct the callback\n",
    "filepath=\"best_epoch_all_time.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(output_dim))\n",
    "model.compile(loss=loss_fuc, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 5, 128)            73216     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 205,187\n",
      "Trainable params: 205,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1350 samples, validate on 24 samples\n",
      "Epoch 1/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0233Epoch 00000: val_loss improved from inf to 0.01776, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 2s - loss: 0.0233 - val_loss: 0.0178\n",
      "Epoch 2/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0225Epoch 00001: val_loss improved from 0.01776 to 0.01752, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0224 - val_loss: 0.0175\n",
      "Epoch 3/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0223Epoch 00002: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0223 - val_loss: 0.0177\n",
      "Epoch 4/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0220Epoch 00003: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0220 - val_loss: 0.0183\n",
      "Epoch 5/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0220Epoch 00004: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0220 - val_loss: 0.0177\n",
      "Epoch 6/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0221Epoch 00005: val_loss improved from 0.01752 to 0.01723, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0220 - val_loss: 0.0172\n",
      "Epoch 7/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0218Epoch 00006: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0218 - val_loss: 0.0174\n",
      "Epoch 8/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0217Epoch 00007: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0217 - val_loss: 0.0178\n",
      "Epoch 9/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0217Epoch 00008: val_loss improved from 0.01723 to 0.01702, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0216 - val_loss: 0.0170\n",
      "Epoch 10/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0215Epoch 00009: val_loss improved from 0.01702 to 0.01675, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0214 - val_loss: 0.0167\n",
      "Epoch 11/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0212Epoch 00010: val_loss improved from 0.01675 to 0.01629, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0212 - val_loss: 0.0163\n",
      "Epoch 12/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0211Epoch 00011: val_loss improved from 0.01629 to 0.01586, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0210 - val_loss: 0.0159\n",
      "Epoch 13/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0206Epoch 00012: val_loss improved from 0.01586 to 0.01533, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0205 - val_loss: 0.0153\n",
      "Epoch 14/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0205Epoch 00013: val_loss improved from 0.01533 to 0.01516, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0204 - val_loss: 0.0152\n",
      "Epoch 15/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0201Epoch 00014: val_loss improved from 0.01516 to 0.01485, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0201 - val_loss: 0.0148\n",
      "Epoch 16/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0202Epoch 00015: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0202 - val_loss: 0.0158\n",
      "Epoch 17/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0200Epoch 00016: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0201 - val_loss: 0.0149\n",
      "Epoch 18/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0199Epoch 00017: val_loss improved from 0.01485 to 0.01475, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0198 - val_loss: 0.0147\n",
      "Epoch 19/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0194Epoch 00018: val_loss improved from 0.01475 to 0.01445, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0195 - val_loss: 0.0144\n",
      "Epoch 20/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0191Epoch 00019: val_loss improved from 0.01445 to 0.01389, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0191 - val_loss: 0.0139\n",
      "Epoch 21/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0190Epoch 00020: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0189 - val_loss: 0.0144\n",
      "Epoch 22/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0187Epoch 00021: val_loss improved from 0.01389 to 0.01378, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0187 - val_loss: 0.0138\n",
      "Epoch 23/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0182Epoch 00022: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0181 - val_loss: 0.0142\n",
      "Epoch 24/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0177Epoch 00023: val_loss improved from 0.01378 to 0.01344, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0177 - val_loss: 0.0134\n",
      "Epoch 25/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0173Epoch 00024: val_loss improved from 0.01344 to 0.01343, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0173 - val_loss: 0.0134\n",
      "Epoch 26/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0175Epoch 00025: val_loss improved from 0.01343 to 0.01330, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0175 - val_loss: 0.0133\n",
      "Epoch 27/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0175Epoch 00026: val_loss improved from 0.01330 to 0.01324, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0174 - val_loss: 0.0132\n",
      "Epoch 28/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0172Epoch 00027: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0173 - val_loss: 0.0135\n",
      "Epoch 29/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0167Epoch 00028: val_loss improved from 0.01324 to 0.01318, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0167 - val_loss: 0.0132\n",
      "Epoch 30/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0165Epoch 00029: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 31/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0159Epoch 00030: val_loss improved from 0.01318 to 0.01312, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0161 - val_loss: 0.0131\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0167Epoch 00031: val_loss improved from 0.01312 to 0.01264, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0167 - val_loss: 0.0126\n",
      "Epoch 33/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0161Epoch 00032: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0160 - val_loss: 0.0127\n",
      "Epoch 34/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0158Epoch 00033: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0158 - val_loss: 0.0130\n",
      "Epoch 35/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0164Epoch 00034: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0164 - val_loss: 0.0131\n",
      "Epoch 36/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0157Epoch 00035: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0157 - val_loss: 0.0131\n",
      "Epoch 37/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0152Epoch 00036: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0152 - val_loss: 0.0133\n",
      "Epoch 38/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0153Epoch 00037: val_loss improved from 0.01264 to 0.01257, saving model to best_epoch_all_time.hdf5\n",
      "1350/1350 [==============================] - 1s - loss: 0.0153 - val_loss: 0.0126\n",
      "Epoch 39/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0156Epoch 00038: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0156 - val_loss: 0.0128\n",
      "Epoch 40/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0150Epoch 00039: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0151 - val_loss: 0.0136\n",
      "Epoch 41/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0152Epoch 00040: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0153 - val_loss: 0.0136\n",
      "Epoch 42/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0148Epoch 00041: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0148 - val_loss: 0.0132\n",
      "Epoch 43/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0153Epoch 00042: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0153 - val_loss: 0.0133\n",
      "Epoch 44/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0150Epoch 00043: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0150 - val_loss: 0.0135\n",
      "Epoch 45/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0144Epoch 00044: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0144 - val_loss: 0.0130\n",
      "Epoch 46/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0142Epoch 00045: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0142 - val_loss: 0.0131\n",
      "Epoch 47/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0141Epoch 00046: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0141 - val_loss: 0.0129\n",
      "Epoch 48/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0141Epoch 00047: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0140 - val_loss: 0.0130\n",
      "Epoch 49/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0138Epoch 00048: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0138 - val_loss: 0.0132\n",
      "Epoch 50/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0140Epoch 00049: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0140 - val_loss: 0.0133\n",
      "Epoch 51/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0137Epoch 00050: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0137 - val_loss: 0.0129\n",
      "Epoch 52/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0136Epoch 00051: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0136 - val_loss: 0.0132\n",
      "Epoch 53/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0146Epoch 00052: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0146 - val_loss: 0.0134\n",
      "Epoch 54/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0136Epoch 00053: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0136 - val_loss: 0.0135\n",
      "Epoch 55/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0133Epoch 00054: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0133 - val_loss: 0.0137\n",
      "Epoch 56/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0131Epoch 00055: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0130 - val_loss: 0.0130\n",
      "Epoch 57/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0128Epoch 00056: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0128 - val_loss: 0.0132\n",
      "Epoch 58/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0129Epoch 00057: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0130 - val_loss: 0.0135\n",
      "Epoch 59/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0131Epoch 00058: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0131 - val_loss: 0.0139\n",
      "Epoch 60/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0127Epoch 00059: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0127 - val_loss: 0.0137\n",
      "Epoch 61/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0124Epoch 00060: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0124 - val_loss: 0.0135\n",
      "Epoch 62/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0125Epoch 00061: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 63/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0123Epoch 00062: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0123 - val_loss: 0.0134\n",
      "Epoch 64/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0124Epoch 00063: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0123 - val_loss: 0.0135\n",
      "Epoch 65/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0119Epoch 00064: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 66/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0119Epoch 00065: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0119 - val_loss: 0.0134\n",
      "Epoch 67/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0120Epoch 00066: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 68/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0116Epoch 00067: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0116 - val_loss: 0.0148\n",
      "Epoch 69/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0118Epoch 00068: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0117 - val_loss: 0.0140\n",
      "Epoch 70/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0112Epoch 00069: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0112 - val_loss: 0.0133\n",
      "Epoch 71/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0113Epoch 00070: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0113 - val_loss: 0.0150\n",
      "Epoch 72/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0108Epoch 00071: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1350/1350 [==============================] - 1s - loss: 0.0109 - val_loss: 0.0139\n",
      "Epoch 73/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0111Epoch 00072: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0111 - val_loss: 0.0148\n",
      "Epoch 74/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0104Epoch 00073: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0104 - val_loss: 0.0140\n",
      "Epoch 75/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0104Epoch 00074: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0104 - val_loss: 0.0147\n",
      "Epoch 76/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0104Epoch 00075: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0104 - val_loss: 0.0146\n",
      "Epoch 77/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0101Epoch 00076: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0101 - val_loss: 0.0141\n",
      "Epoch 78/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0096Epoch 00077: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0096 - val_loss: 0.0141\n",
      "Epoch 79/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0108Epoch 00078: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0109 - val_loss: 0.0152\n",
      "Epoch 80/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0117Epoch 00079: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0117 - val_loss: 0.0141\n",
      "Epoch 81/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0103Epoch 00080: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0103 - val_loss: 0.0151\n",
      "Epoch 82/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0095Epoch 00081: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0096 - val_loss: 0.0136\n",
      "Epoch 83/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0095Epoch 00082: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0095 - val_loss: 0.0154\n",
      "Epoch 84/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0091Epoch 00083: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0091 - val_loss: 0.0149\n",
      "Epoch 85/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0088Epoch 00084: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0087 - val_loss: 0.0143\n",
      "Epoch 86/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0086Epoch 00085: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0086 - val_loss: 0.0150\n",
      "Epoch 87/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0082Epoch 00086: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0082 - val_loss: 0.0146\n",
      "Epoch 88/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0086Epoch 00087: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0086 - val_loss: 0.0142\n",
      "Epoch 89/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0083Epoch 00088: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0082 - val_loss: 0.0142\n",
      "Epoch 90/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0078Epoch 00089: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0078 - val_loss: 0.0140\n",
      "Epoch 91/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0078Epoch 00090: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0078 - val_loss: 0.0143\n",
      "Epoch 92/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0077Epoch 00091: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0077 - val_loss: 0.0149\n",
      "Epoch 93/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0074Epoch 00092: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0074 - val_loss: 0.0148\n",
      "Epoch 94/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0082Epoch 00093: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0082 - val_loss: 0.0147\n",
      "Epoch 95/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0074Epoch 00094: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0074 - val_loss: 0.0144\n",
      "Epoch 96/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0074Epoch 00095: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0074 - val_loss: 0.0142\n",
      "Epoch 97/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0071Epoch 00096: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0071 - val_loss: 0.0151\n",
      "Epoch 98/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0068Epoch 00097: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0068 - val_loss: 0.0145\n",
      "Epoch 99/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0070Epoch 00098: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0070 - val_loss: 0.0142\n",
      "Epoch 100/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0063Epoch 00099: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0063 - val_loss: 0.0148\n",
      "Epoch 101/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0063Epoch 00100: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0063 - val_loss: 0.0143\n",
      "Epoch 102/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0065Epoch 00101: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0064 - val_loss: 0.0148\n",
      "Epoch 103/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0061Epoch 00102: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0061 - val_loss: 0.0148\n",
      "Epoch 104/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0062Epoch 00103: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0062 - val_loss: 0.0150\n",
      "Epoch 105/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0059Epoch 00104: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0059 - val_loss: 0.0148\n",
      "Epoch 106/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0053Epoch 00105: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0053 - val_loss: 0.0148\n",
      "Epoch 107/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0051Epoch 00106: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0051 - val_loss: 0.0146\n",
      "Epoch 108/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0054Epoch 00107: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0054 - val_loss: 0.0154\n",
      "Epoch 109/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0054Epoch 00108: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0053 - val_loss: 0.0157\n",
      "Epoch 110/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0051Epoch 00109: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0051 - val_loss: 0.0150\n",
      "Epoch 111/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0050Epoch 00110: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0050 - val_loss: 0.0150\n",
      "Epoch 112/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0047Epoch 00111: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0047 - val_loss: 0.0158\n",
      "Epoch 113/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0048Epoch 00112: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1350/1350 [==============================] - 1s - loss: 0.0048 - val_loss: 0.0165\n",
      "Epoch 114/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0044Epoch 00113: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0044 - val_loss: 0.0157\n",
      "Epoch 115/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0045Epoch 00114: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0045 - val_loss: 0.0175\n",
      "Epoch 116/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0044Epoch 00115: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0044 - val_loss: 0.0157\n",
      "Epoch 117/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0040Epoch 00116: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0040 - val_loss: 0.0165\n",
      "Epoch 118/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0040Epoch 00117: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0040 - val_loss: 0.0164\n",
      "Epoch 119/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00118: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0038 - val_loss: 0.0160\n",
      "Epoch 120/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0040Epoch 00119: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0040 - val_loss: 0.0164\n",
      "Epoch 121/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00120: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0038 - val_loss: 0.0161\n",
      "Epoch 122/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0039Epoch 00121: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0039 - val_loss: 0.0172\n",
      "Epoch 123/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0041Epoch 00122: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0041 - val_loss: 0.0164\n",
      "Epoch 124/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00123: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0035 - val_loss: 0.0171\n",
      "Epoch 125/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0033Epoch 00124: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0033 - val_loss: 0.0166\n",
      "Epoch 126/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0032Epoch 00125: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0032 - val_loss: 0.0168\n",
      "Epoch 127/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0033Epoch 00126: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0033 - val_loss: 0.0166\n",
      "Epoch 128/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0032Epoch 00127: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0032 - val_loss: 0.0173\n",
      "Epoch 129/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0031Epoch 00128: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0031 - val_loss: 0.0166\n",
      "Epoch 130/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0030Epoch 00129: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0030 - val_loss: 0.0167\n",
      "Epoch 131/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0032Epoch 00130: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0032 - val_loss: 0.0155\n",
      "Epoch 132/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0029Epoch 00131: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0029 - val_loss: 0.0172\n",
      "Epoch 133/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0030Epoch 00132: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0030 - val_loss: 0.0172\n",
      "Epoch 134/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0028Epoch 00133: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0028 - val_loss: 0.0177\n",
      "Epoch 135/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0027Epoch 00134: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0027 - val_loss: 0.0171\n",
      "Epoch 136/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0026Epoch 00135: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0026 - val_loss: 0.0173\n",
      "Epoch 137/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0026Epoch 00136: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0026 - val_loss: 0.0182\n",
      "Epoch 138/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0027Epoch 00137: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0027 - val_loss: 0.0167\n",
      "Epoch 139/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0027Epoch 00138: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0027 - val_loss: 0.0174\n",
      "Epoch 140/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0027Epoch 00139: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0027 - val_loss: 0.0170\n",
      "Epoch 141/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0025Epoch 00140: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0025 - val_loss: 0.0175\n",
      "Epoch 142/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0025Epoch 00141: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0025 - val_loss: 0.0174\n",
      "Epoch 143/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0027Epoch 00142: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0027 - val_loss: 0.0182\n",
      "Epoch 144/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0025Epoch 00143: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0025 - val_loss: 0.0165\n",
      "Epoch 145/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0025Epoch 00144: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0025 - val_loss: 0.0172\n",
      "Epoch 146/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0025Epoch 00145: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0025 - val_loss: 0.0173\n",
      "Epoch 147/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0023Epoch 00146: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0023 - val_loss: 0.0178\n",
      "Epoch 148/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0022Epoch 00147: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0022 - val_loss: 0.0180\n",
      "Epoch 149/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0021Epoch 00148: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0021 - val_loss: 0.0181\n",
      "Epoch 150/200\n",
      "1280/1350 [===========================>..] - ETA: 0s - loss: 0.0023Epoch 00149: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0022 - val_loss: 0.0184\n",
      "Epoch 151/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0020Epoch 00150: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0020 - val_loss: 0.0174\n",
      "Epoch 152/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0021Epoch 00151: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0021 - val_loss: 0.0172\n",
      "Epoch 153/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0026Epoch 00152: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0026 - val_loss: 0.0179\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0025Epoch 00153: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0025 - val_loss: 0.0190\n",
      "Epoch 155/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0023Epoch 00154: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0023 - val_loss: 0.0173\n",
      "Epoch 156/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0024Epoch 00155: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0024 - val_loss: 0.0175\n",
      "Epoch 157/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0021Epoch 00156: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0021 - val_loss: 0.0172\n",
      "Epoch 158/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0018Epoch 00157: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0018 - val_loss: 0.0178\n",
      "Epoch 159/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0018Epoch 00158: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0018 - val_loss: 0.0179\n",
      "Epoch 160/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0019Epoch 00159: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0019 - val_loss: 0.0177\n",
      "Epoch 161/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0019Epoch 00160: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0019 - val_loss: 0.0173\n",
      "Epoch 162/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0017Epoch 00161: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0017 - val_loss: 0.0184\n",
      "Epoch 163/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0016Epoch 00162: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0016 - val_loss: 0.0175\n",
      "Epoch 164/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0016Epoch 00163: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0016 - val_loss: 0.0178\n",
      "Epoch 165/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0017Epoch 00164: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0017 - val_loss: 0.0189\n",
      "Epoch 166/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0017Epoch 00165: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0017 - val_loss: 0.0184\n",
      "Epoch 167/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0016Epoch 00166: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0016 - val_loss: 0.0181\n",
      "Epoch 168/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0016Epoch 00167: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0016 - val_loss: 0.0180\n",
      "Epoch 169/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0015Epoch 00168: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0015 - val_loss: 0.0177\n",
      "Epoch 170/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00169: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0013 - val_loss: 0.0180\n",
      "Epoch 171/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00170: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0013 - val_loss: 0.0176\n",
      "Epoch 172/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00171: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0013 - val_loss: 0.0174\n",
      "Epoch 173/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0016Epoch 00172: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0016 - val_loss: 0.0184\n",
      "Epoch 174/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0014Epoch 00173: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0014 - val_loss: 0.0179\n",
      "Epoch 175/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0018Epoch 00174: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0018 - val_loss: 0.0173\n",
      "Epoch 176/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0023Epoch 00175: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0023 - val_loss: 0.0184\n",
      "Epoch 177/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0019Epoch 00176: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0019 - val_loss: 0.0177\n",
      "Epoch 178/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0017Epoch 00177: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0017 - val_loss: 0.0162\n",
      "Epoch 179/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0017Epoch 00178: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0017 - val_loss: 0.0172\n",
      "Epoch 180/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0016Epoch 00179: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0016 - val_loss: 0.0162\n",
      "Epoch 181/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0014Epoch 00180: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0014 - val_loss: 0.0173\n",
      "Epoch 182/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00181: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0013 - val_loss: 0.0177\n",
      "Epoch 183/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0013Epoch 00182: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0013 - val_loss: 0.0176\n",
      "Epoch 184/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00183: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0012 - val_loss: 0.0175\n",
      "Epoch 185/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00184: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0012 - val_loss: 0.0176\n",
      "Epoch 186/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00185: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0012 - val_loss: 0.0174\n",
      "Epoch 187/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00186: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0011 - val_loss: 0.0179\n",
      "Epoch 188/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00187: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0011 - val_loss: 0.0171\n",
      "Epoch 189/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00188: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0011 - val_loss: 0.0175\n",
      "Epoch 190/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00189: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0011 - val_loss: 0.0169\n",
      "Epoch 191/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 9.7597e-04Epoch 00190: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 9.7422e-04 - val_loss: 0.0173\n",
      "Epoch 192/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00191: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0011 - val_loss: 0.0172\n",
      "Epoch 193/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0010 Epoch 00192: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0010 - val_loss: 0.0172\n",
      "Epoch 194/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0010    Epoch 00193: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1350/1350 [==============================] - 1s - loss: 0.0010 - val_loss: 0.0171\n",
      "Epoch 195/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00194: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0012 - val_loss: 0.0183\n",
      "Epoch 196/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0010Epoch 00195: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0010 - val_loss: 0.0169\n",
      "Epoch 197/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0010Epoch 00196: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0010 - val_loss: 0.0173\n",
      "Epoch 198/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0011Epoch 00197: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0011 - val_loss: 0.0164\n",
      "Epoch 199/200\n",
      "1344/1350 [============================>.] - ETA: 0s - loss: 0.0012Epoch 00198: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0011 - val_loss: 0.0179\n",
      "Epoch 200/200\n",
      "1280/1350 [===========================>..] - ETA: 0s - loss: 0.0010  Epoch 00199: val_loss did not improve\n",
      "1350/1350 [==============================] - 1s - loss: 0.0010 - val_loss: 0.0176\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGHCAYAAACnPchFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERCXv/D+zQT7lm06WsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10441aa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Start Training\n",
    "model.summary()\n",
    "history_w_model = model.fit(x_train, y_train, callbacks=callbacks_list, epochs=num_epochs, batch_size=64, validation_data=(x_test,y_test))\n",
    "\n",
    "plt.plot(history_w_model.history['loss'], label='loss')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.plot(history_w_model.history['val_loss'], label='Val_loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load weights into the model\n",
    "model.load_weights(\"best_epoch.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kin/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:31: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "''' === Prediction ===\n",
    "Procedure:\n",
    "1. Load CSV\n",
    "2. to_datetime\n",
    "3. create timeofday column\n",
    "4. select the time for training: 6:00-8:00 (6 timestamps) and 15:00-17:00 (6 timestamps)\n",
    "5. change it to stationary\n",
    "6. Use using_cols to select the features\n",
    "7. del 'date'\n",
    "8. change to np array\n",
    "9. MinMaxScaler\n",
    "10. make the sequences tensor as input\n",
    "11. make a forloop for prediction\n",
    "\n",
    "'''\n",
    "# 1. Load CSV - Vol + Route + Weather (Only Weather is 24-hour data)\n",
    "df_pred = pd.read_csv('../data/preprocessed_input_interpolate_20min_phase2_test.csv')\n",
    "\n",
    "# 2. to_datetime\n",
    "df_pred['date'] = pd.to_datetime(df_pred['date'])\n",
    "\n",
    "# 3. create timeofday column\n",
    "df_pred['timeofday'] = df_pred.date.apply( lambda d : d.hour+d.minute/60.)\n",
    "\n",
    "# 4. select the time for training\n",
    "\n",
    "df_pred_sel_time = df_pred[ ((df_merged_volume_copy.timeofday>= 6) & (df_merged_volume_copy.timeofday<8)) |\n",
    "                            ((df_merged_volume_copy.timeofday>=15) & (df_merged_volume_copy.timeofday<17))]\n",
    "\n",
    "df_feedin_weather_sel_time = df_pred[ ((df_merged_volume_copy.timeofday>= 8) & (df_merged_volume_copy.timeofday<10)) |\n",
    "                            ((df_merged_volume_copy.timeofday>=17) & (df_merged_volume_copy.timeofday<19))]\n",
    "\n",
    "# 5. change it to stationary\n",
    "df_pred_sel_time = df_pred_sel_time.reset_index(drop=True)\n",
    "\n",
    "df_pred_sel_time_copy = df_pred_sel_time.copy()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(df_pred_sel_time_copy)//6):  # make the loop for 14 time slots (2 different time slot x 7days)\n",
    "    for t in range(5):  #  Do the \"difference\" 5 times every loop\n",
    "        start_idx = i*6 + t + 1  # Add 1 is for starting it from index 1 in every 6-space time slot\n",
    "        df_pred_sel_time_copy.loc[start_idx, df_pred_sel_time_copy.columns[0:36]] = df_pred_sel_time.loc[start_idx, df_pred_sel_time.columns[0:36]] - df_pred_sel_time.loc[start_idx-1, df_pred_sel_time.columns[0:36]]\n",
    "\n",
    "# 6. Use using_cols to select the features\n",
    "sel_rows_pred = df_pred_sel_time_copy[ using_cols ]\n",
    "\n",
    "sel_rows_feedin_weather = df_feedin_weather_sel_time[using_cols[3:]]\n",
    "\n",
    "# 7. del 'date'\n",
    "del sel_rows_pred['date']\n",
    "del sel_rows_feedin_weather['date']\n",
    "\n",
    "# 8. change to np array\n",
    "pred_arr = sel_rows_pred.values\n",
    "\n",
    "feedin_weather_arr = sel_rows_feedin_weather.values\n",
    "\n",
    "# 9. MinMaxScaler\n",
    "pred_arr_scaled = scaler.transform(pred_arr)\n",
    "\n",
    "# add some dummy cells in front of the weather_array for transform\n",
    "temp_arr = np.zeros((84,3))\n",
    "feedin_weather_arr = np.concatenate([temp_arr, feedin_weather_arr], axis=1)\n",
    "\n",
    "feedin_weather_arr_scaled = scaler.transform(feedin_weather_arr)\n",
    "\n",
    "# Now pred_arr_scaled is (84 x 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 10. make the sequences tensor as input\n",
    "# Put into the model to get the prediction\n",
    "\n",
    "ans_arr = []  # For holding the output answer\n",
    "    \n",
    "for i in range(len(pred_arr_scaled)//6):  # make the loop for 14 time slots (2 different time slot x 7days)\n",
    "    # creating pre_seq\n",
    "    pred_seq = []\n",
    "    for t in range(5):  #  Do the \"difference\" 5 times every loop\n",
    "        k = i*6 + t + 1  # Add 1 is for starting it from index 1 in every 6-space time slot, to ignore the first index which is non-stationary\n",
    "        pred_seq.append(pred_arr_scaled[k])  # creating a sequence for a time slot\n",
    "    \n",
    "    # creating feedin_weather_seq\n",
    "    feedin_weather_seq = []\n",
    "    for t in range(6):  #  Do 6 times every loop\n",
    "        k = i*6 + t  #\n",
    "        feedin_weather_seq.append(feedin_weather_arr_scaled[k])\n",
    "\n",
    "\n",
    "    pred_seq = np.stack(pred_seq)  # change back to the numpy array (2D)\n",
    "    pred_seq = pred_seq.reshape(1, pred_seq.shape[0], pred_seq.shape[1])  # change to numpy 3D as input\n",
    "\n",
    "    feedin_weather_seq = np.stack(feedin_weather_seq)  # change back to the numpy array (2D)\n",
    "    feedin_weather_seq = feedin_weather_seq.reshape(1, feedin_weather_seq.shape[0], feedin_weather_seq.shape[1])  # change to numpy 3D as input\n",
    "\n",
    "    for q in range(6):\n",
    "        # predict next timestamp\n",
    "        output_pred = model.predict(pred_seq)  # get one prediction output (size (1 x 3))\n",
    "        ans_arr.append(output_pred)\n",
    "\n",
    "        # update the input seq\n",
    "        for j in range(1,5):\n",
    "            pred_seq[0][j-1] = pred_seq[0][j]\n",
    "        pred_seq[0][4] = feedin_weather_seq[0][q]\n",
    "        pred_seq[0][4][0:3] = output_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.03416985,  0.64532489,  0.324485  ]], dtype=float32),\n",
       " array([[ 0.01828507,  0.09214953,  0.10641111]], dtype=float32),\n",
       " array([[ 0.02829109,  0.24142185,  0.11610636]], dtype=float32),\n",
       " array([[-0.43514609, -0.13018453, -0.06435183]], dtype=float32),\n",
       " array([[-0.28384611, -0.01437771,  0.11283149]], dtype=float32),\n",
       " array([[ 0.09849536,  0.31616166,  0.07602754]], dtype=float32),\n",
       " array([[ 0.23560739,  0.26252785,  0.06468093]], dtype=float32),\n",
       " array([[ 0.030499  ,  0.15343568,  0.16943   ]], dtype=float32),\n",
       " array([[-0.12590998,  0.07665193, -0.03927835]], dtype=float32),\n",
       " array([[ 0.08959169,  0.17510627,  0.10864791]], dtype=float32),\n",
       " array([[ 0.04797691,  0.11991245,  0.06576282]], dtype=float32),\n",
       " array([[ 0.007465  ,  0.10483809,  0.11402231]], dtype=float32),\n",
       " array([[ 0.02783623,  0.67880082,  0.34572574]], dtype=float32),\n",
       " array([[-0.48091024, -0.18603581,  0.24059035]], dtype=float32),\n",
       " array([[-0.02453759,  0.30475402,  0.1661666 ]], dtype=float32),\n",
       " array([[ 0.14954993,  0.55410558,  0.01653173]], dtype=float32),\n",
       " array([[-0.1584824 ,  0.07051459,  0.07562891]], dtype=float32),\n",
       " array([[-0.46047848,  0.07417232,  0.16051704]], dtype=float32),\n",
       " array([[-0.22995743, -0.03279483, -0.03301452]], dtype=float32),\n",
       " array([[ 0.17721358,  0.49062365,  0.33874565]], dtype=float32),\n",
       " array([[-0.09375274,  0.03039407, -0.01754062]], dtype=float32),\n",
       " array([[-0.16777083,  0.18601194,  0.2311185 ]], dtype=float32),\n",
       " array([[-0.14070401,  0.05511805,  0.00093161]], dtype=float32),\n",
       " array([[-0.17269579,  0.06849361,  0.18623383]], dtype=float32),\n",
       " array([[-0.45192921,  0.31600213,  0.18770476]], dtype=float32),\n",
       " array([[ 0.36262271,  0.47243553,  0.2871446 ]], dtype=float32),\n",
       " array([[-0.51759166, -0.10512464, -0.18104547]], dtype=float32),\n",
       " array([[ 0.09010532, -0.06609955,  0.05931157]], dtype=float32),\n",
       " array([[-0.18331617,  0.21093901, -0.00687023]], dtype=float32),\n",
       " array([[-0.35249737,  0.16243558,  0.06416008]], dtype=float32),\n",
       " array([[-0.41317096, -0.01587403,  0.09197322]], dtype=float32),\n",
       " array([[-0.02478376,  0.40210423,  0.16137737]], dtype=float32),\n",
       " array([[-0.01942391,  0.17976725,  0.02788743]], dtype=float32),\n",
       " array([[ 0.02460761,  0.2664569 ,  0.25390133]], dtype=float32),\n",
       " array([[-0.06031863,  0.16195458,  0.00608884]], dtype=float32),\n",
       " array([[-0.14552119, -0.02660415,  0.01683562]], dtype=float32),\n",
       " array([[-0.17997554,  0.49733928,  0.20225957]], dtype=float32),\n",
       " array([[ 0.07124019,  0.131457  ,  0.08699887]], dtype=float32),\n",
       " array([[ 0.36143029,  0.54523128,  0.11215441]], dtype=float32),\n",
       " array([[ 0.24441153,  0.40356842,  0.07071014]], dtype=float32),\n",
       " array([[-0.58620429,  0.05974206,  0.00307382]], dtype=float32),\n",
       " array([[ 0.1873357 ,  0.73361439,  0.10045406]], dtype=float32),\n",
       " array([[-0.13446903, -0.07998359,  0.1012821 ]], dtype=float32),\n",
       " array([[-0.20182613,  0.34325123,  0.10906225]], dtype=float32),\n",
       " array([[-0.22889471,  0.16250582,  0.12516813]], dtype=float32),\n",
       " array([[-0.12491176,  0.18470541,  0.13610296]], dtype=float32),\n",
       " array([[-0.09020208,  0.11547522,  0.13321637]], dtype=float32),\n",
       " array([[ 0.06841633,  0.1641649 ,  0.1554347 ]], dtype=float32),\n",
       " array([[-0.98986995, -0.32728097, -0.40685737]], dtype=float32),\n",
       " array([[-0.77264661,  0.03010178, -0.23838711]], dtype=float32),\n",
       " array([[ 0.10048782,  0.07181573, -0.01300113]], dtype=float32),\n",
       " array([[ 0.03236938, -0.17646924, -0.08448049]], dtype=float32),\n",
       " array([[-0.70289916, -0.42039284, -0.1944467 ]], dtype=float32),\n",
       " array([[-0.44373441, -0.35436869, -0.24354833]], dtype=float32),\n",
       " array([[-0.49354962, -0.02504198, -0.11673944]], dtype=float32),\n",
       " array([[-0.20412865,  0.33308548,  0.0294135 ]], dtype=float32),\n",
       " array([[-0.103654  , -0.01950162,  0.07406245]], dtype=float32),\n",
       " array([[-0.04003016,  0.12486246,  0.09302068]], dtype=float32),\n",
       " array([[-0.14296681,  0.02563981,  0.0750196 ]], dtype=float32),\n",
       " array([[-0.243139  ,  0.11643553,  0.04843062]], dtype=float32),\n",
       " array([[ 0.21585435,  0.6586535 ,  0.30445164]], dtype=float32),\n",
       " array([[ 0.23058236,  0.53964132,  0.19197899]], dtype=float32),\n",
       " array([[ 0.06976204,  0.42846334,  0.12476481]], dtype=float32),\n",
       " array([[ 0.02626468,  0.29559159,  0.16054147]], dtype=float32),\n",
       " array([[-0.02449523,  0.24948668,  0.12952103]], dtype=float32),\n",
       " array([[-0.07576448,  0.20832813,  0.09272212]], dtype=float32),\n",
       " array([[-0.24544284,  0.14458916, -0.05956682]], dtype=float32),\n",
       " array([[-0.17108575,  0.06417951,  0.14151198]], dtype=float32),\n",
       " array([[-0.13976288,  0.07802688,  0.14315717]], dtype=float32),\n",
       " array([[-0.16168073,  0.01924618,  0.02395641]], dtype=float32),\n",
       " array([[-0.07730134,  0.14474094,  0.19159921]], dtype=float32),\n",
       " array([[-0.2791155 ,  0.00976358,  0.05228221]], dtype=float32),\n",
       " array([[-0.54820484,  0.09155709,  0.14941679]], dtype=float32),\n",
       " array([[-0.05262919,  0.33717769,  0.15052673]], dtype=float32),\n",
       " array([[-0.15267992,  0.21277565,  0.1016636 ]], dtype=float32),\n",
       " array([[-0.00219201, -0.05189794, -0.00676667]], dtype=float32),\n",
       " array([[-0.55875582, -0.20568289,  0.07781129]], dtype=float32),\n",
       " array([[-0.44446915, -0.14914128,  0.03983783]], dtype=float32),\n",
       " array([[-0.03015796,  0.22131227,  0.11962494]], dtype=float32),\n",
       " array([[-0.04191964,  0.175418  ,  0.10396597]], dtype=float32),\n",
       " array([[-0.22075152,  0.10070494,  0.15145437]], dtype=float32),\n",
       " array([[-0.01545161,  0.1161904 ,  0.09355888]], dtype=float32),\n",
       " array([[-0.25332409,  0.02519971,  0.18540521]], dtype=float32),\n",
       " array([[-0.12497587,  0.08464518,  0.12747011]], dtype=float32)]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Problems, in row 48 (= Day 5)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [  0.07741418  26.76878002  30.09120459]\n",
      "1 [ 1.49369698 -9.46420557 -0.57769562]\n",
      "2 [ 1.76385947  0.31313108  0.78579892]\n",
      "3 [-10.74894452 -24.02708679 -24.59300353]\n",
      "4 [ -6.66384497 -16.44174021   0.32523598]\n",
      "5 [ 3.65937463  5.20858888 -4.85070024]\n",
      "6 [ 7.36139941  1.69557439 -6.44643461]\n",
      "7 [ 1.8234731  -5.44996314  8.28498848]\n",
      "8 [ -2.39956957 -10.47929853 -21.06678563]\n",
      "9 [ 3.41897561 -4.03053918 -0.26312267]\n",
      "10 [ 2.2953765  -7.64573482 -6.29428347]\n",
      "11 [ 1.20155513 -8.63310523  0.49270827]\n",
      "12 [  1.7515783   28.9614538   33.07840388]\n",
      "13 [-11.98457652 -27.68534568  18.29264948]\n",
      "14 [ 0.33748519  4.46138823  7.82603919]\n",
      "15 [  5.03784814  20.79391548 -13.21791528]\n",
      "16 [ -3.27902487 -10.88129438  -4.90676254]\n",
      "17 [-11.43291909 -10.64171317   7.03151034]\n",
      "18 [ -5.20885065 -17.64806157 -20.18587072]\n",
      "19 [  5.78476664  16.63584927  32.09675621]\n",
      "20 [ -1.53132403 -13.50918842 -18.00969289]\n",
      "21 [ -3.52981248  -3.31621791  16.96057263]\n",
      "22 [ -2.79900816 -11.8897677  -15.41184441]\n",
      "23 [ -3.66278622 -11.01366841  10.6482013 ]\n",
      "24 [-11.20208871   5.19813955  10.85506515]\n",
      "25 [ 10.79081312  15.44452748  24.83982359]\n",
      "26 [-12.97497469 -22.38566376 -41.00425653]\n",
      "27 [  3.43284357 -19.82952081  -7.2015567 ]\n",
      "28 [ -3.94953662  -1.68349517 -16.50905822]\n",
      "29 [-8.51742896 -4.86046975 -6.51968527]\n",
      "30 [-10.15561602 -16.53974909  -2.60817476]\n",
      "31 [  0.33083847  10.83782698   7.15250364]\n",
      "32 [  0.47555444  -3.72524506 -11.62090284]\n",
      "33 [  1.66440557   1.95292708  20.16464449]\n",
      "34 [ -0.62860302  -4.8919749  -14.6865544 ]\n",
      "35 [ -2.92907223 -17.24257155 -13.17517726]\n",
      "36 [ -3.85933957  17.07572274  12.9019866 ]\n",
      "37 [ 2.92348524 -6.88956644 -3.30774431]\n",
      "38 [ 10.75861776  20.21264902   0.23001474]\n",
      "39 [  7.59911126  10.9337313   -5.59851434]\n",
      "40 [-14.82751584 -11.58689485 -15.11057399]\n",
      "41 [  6.05806389  32.55174223  -1.4154678 ]\n",
      "42 [ -2.63066387 -20.73892528  -1.29901572]\n",
      "43 [-4.44930539  6.98295546 -0.20485158]\n",
      "44 [-5.18015718 -4.85586876  2.06020402]\n",
      "45 [-2.37261759 -3.40179588  3.59802775]\n",
      "46 [-1.43545611 -7.93637342  3.19207065]\n",
      "47 [ 2.84724084 -4.747199    6.31675375]\n",
      "48 [-25.72648871 -36.93690343 -72.76139445]\n",
      "49 [-19.86145836 -13.52833366 -49.06851811]\n",
      "50 [  3.71317116 -10.79606974 -17.37128011]\n",
      "51 [  1.87397333 -27.058735   -27.42380593]\n",
      "52 [-17.97827727 -43.03573109 -42.88894268]\n",
      "53 [-10.980829   -38.71114898 -49.79436896]\n",
      "54 [-12.32583961 -17.14024937 -31.96055399]\n",
      "55 [ -4.51147363   6.31709877 -11.40628359]\n",
      "56 [ -1.79865813 -16.77735629  -5.12706147]\n",
      "57 [-0.0808144  -7.32150872 -2.46086453]\n",
      "58 [ -2.86010379 -13.82059271  -4.99245285]\n",
      "59 [-5.56475297 -7.87347293 -8.73180367]\n",
      "60 [  6.82806736  27.6418041   27.27380584]\n",
      "61 [  7.22572362  19.84650651  11.45617362]\n",
      "62 [  2.88357498  12.56434876   2.0034837 ]\n",
      "63 [ 1.70914632  3.86124933  7.03494717]\n",
      "64 [ 0.33862891  0.84137785  2.67237532]\n",
      "65 [-1.04564089 -1.85450763 -2.50285258]\n",
      "66 [ -5.62695661  -6.02941029 -23.92006262]\n",
      "67 [ -3.61931512 -11.2962421    4.35872684]\n",
      "68 [ -2.77359772 -10.38923914   4.59009908]\n",
      "69 [ -3.36537966 -14.23937499 -12.17374318]\n",
      "70 [ -1.08713613  -6.01946849  11.40276229]\n",
      "71 [ -6.53611845 -14.86048577  -8.19013409]\n",
      "72 [-13.80153066  -9.5030109    5.47042302]\n",
      "73 [-0.42098817  6.58513895  5.62652023]\n",
      "74 [-3.12235785 -1.56319508 -1.2453634 ]\n",
      "75 [  0.94081578 -18.89931478 -16.49449359]\n",
      "76 [-14.08640701 -28.97222921  -4.59984283]\n",
      "77 [-11.00066715 -25.26875396  -9.94025301]\n",
      "78 [ 0.18573505 -1.00404634  1.28063588]\n",
      "79 [-0.13183031 -4.01012071 -0.92156967]\n",
      "80 [-4.96029115 -8.90382655  5.7569795 ]\n",
      "81 [ 0.58280665 -7.88952856 -2.38517456]\n",
      "82 [ -5.83975047 -13.84941915  10.5316675 ]\n",
      "83 [-2.37434842 -9.95574059  2.38394326]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ans_arr)):\n",
    "    print(i, backward_scaler(ans_arr[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward_scaler(nn_output):\n",
    "    tmp = np.zeros(14)\n",
    "    tmp[0:3] = nn_output\n",
    "    tmp = scaler.inverse_transform(tmp)\n",
    "    return tmp[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode(last_timestamp_values, nn_output):\n",
    "    tmp = np.zeros(14)\n",
    "    tmp[0:3] = nn_output\n",
    "    tmp = scaler.inverse_transform(tmp)\n",
    "    return last_timestamp_values + tmp[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kin/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# create the non-stationary 6:40 and 16:40 for decoding\n",
    "df_non_station_sel_time = df_pred[ ((df_merged_volume_copy.timeofday>= 7.5) & (df_merged_volume_copy.timeofday<8)) |\n",
    "                            ((df_merged_volume_copy.timeofday>=16.5) & (df_merged_volume_copy.timeofday<17))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0, 'etc')    19.000000\n",
       "(2, 0, 'tot')    61.000000\n",
       "('A', 2)         53.751765\n",
       "Name: 311, dtype: float64"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non_station_sel_time[using_cols[0:3]].iloc[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/Kin/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "tmp = df_non_station_sel_time[using_cols[0:3]].values\n",
    "allAns = []\n",
    "for i in range(len(tmp)):\n",
    "    seed = tmp[i]  # non-stationary for reconstructing a sequence\n",
    "    segmentAns = []\n",
    "    for timestep in range(6):\n",
    "        seed = decode(seed, ans_arr[i*6+timestep])\n",
    "        segmentAns.append(seed)\n",
    "    allAns.append(segmentAns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  38.07741418,  119.76878002,   90.68995459],\n",
       "        [  39.57111116,  110.30457446,   90.11225897],\n",
       "        [  41.33497062,  110.61770554,   90.89805789],\n",
       "        [  30.5860261 ,   86.59061874,   66.30505436],\n",
       "        [  23.92218113,   70.14887853,   66.63029035],\n",
       "        [  27.58155576,   75.35746741,   61.77959011]],\n",
       "\n",
       "       [[  24.36139941,   70.69557439,   62.79134317],\n",
       "        [  26.18487252,   65.24561125,   71.07633165],\n",
       "        [  23.78530294,   54.76631272,   50.00954602],\n",
       "        [  27.20427856,   50.73577354,   49.74642335],\n",
       "        [  29.49965506,   43.09003872,   43.45213988],\n",
       "        [  30.70121019,   34.4569335 ,   43.94484815]],\n",
       "\n",
       "       [[  43.7515783 ,  127.9614538 ,   79.62173721],\n",
       "        [  31.76700178,  100.27610812,   97.91438669],\n",
       "        [  32.10448696,  104.73749635,  105.74042587],\n",
       "        [  37.14233511,  125.53141183,   92.52251059],\n",
       "        [  33.86331024,  114.65011744,   87.61574805],\n",
       "        [  22.43039116,  104.00840427,   94.64725839]],\n",
       "\n",
       "       [[  17.79114935,   72.35193843,   50.82698642],\n",
       "        [  23.57591599,   88.98778769,   82.92374264],\n",
       "        [  22.04459196,   75.47859927,   64.91404975],\n",
       "        [  18.51477948,   72.16238135,   81.87462237],\n",
       "        [  15.71577132,   60.27261366,   66.46277797],\n",
       "        [  12.0529851 ,   49.25894525,   77.11097927]],\n",
       "\n",
       "       [[  29.79791129,  119.19813955,   91.37198823],\n",
       "        [  40.5887244 ,  134.64266703,  116.21181182],\n",
       "        [  27.61374971,  112.25700327,   75.20755529],\n",
       "        [  31.04659329,   92.42748246,   68.00599859],\n",
       "        [  27.09705666,   90.74398729,   51.49694037],\n",
       "        [  18.5796277 ,   85.88351754,   44.9772551 ]],\n",
       "\n",
       "       [[  18.84438398,   66.46025091,   69.46111096],\n",
       "        [  19.17522246,   77.29807789,   76.6136146 ],\n",
       "        [  19.6507769 ,   73.57283283,   64.99271176],\n",
       "        [  21.31518247,   75.52575991,   85.15735625],\n",
       "        [  20.68657945,   70.63378502,   70.47080185],\n",
       "        [  17.75750722,   53.39121347,   57.29562459]],\n",
       "\n",
       "       [[  32.14066043,  114.07572274,   78.07531994],\n",
       "        [  35.06414568,  107.1861563 ,   74.76757562],\n",
       "        [  45.82276344,  127.39880532,   74.99759036],\n",
       "        [  53.42187469,  138.33253662,   69.39907602],\n",
       "        [  38.59435885,  126.74564177,   54.28850203],\n",
       "        [  44.65242275,  159.29738399,   52.87303423]],\n",
       "\n",
       "       [[  27.36933613,   89.26107472,   87.43024354],\n",
       "        [  22.92003074,   96.24403018,   87.22539196],\n",
       "        [  17.73987356,   91.38816141,   89.28559599],\n",
       "        [  15.36725596,   87.98636553,   92.88362373],\n",
       "        [  13.93179985,   80.04999212,   96.07569438],\n",
       "        [  16.77904069,   75.30279312,  102.39244814]],\n",
       "\n",
       "       [[  -6.72648871,   24.06309657,  -19.00962974],\n",
       "        [ -26.58794707,   10.5347629 ,  -68.07814785],\n",
       "        [ -22.87477591,   -0.26130684,  -85.44942796],\n",
       "        [ -21.00080258,  -27.32004184, -112.87323389],\n",
       "        [ -38.97907984,  -70.35577293, -155.76217657],\n",
       "        [ -49.95990884, -109.0669219 , -205.55654553]],\n",
       "\n",
       "       [[   8.67416039,   65.85975063,   37.46003425],\n",
       "        [   4.16268677,   72.1768494 ,   26.05375066],\n",
       "        [   2.36402864,   55.39949311,   20.92668919],\n",
       "        [   2.28321424,   48.07798439,   18.46582466],\n",
       "        [  -0.57688954,   34.25739168,   13.4733718 ],\n",
       "        [  -6.14164251,   26.38391875,    4.74156813]],\n",
       "\n",
       "       [[  22.82806736,   43.6418041 ,   78.37926039],\n",
       "        [  30.05379099,   63.48831061,   89.83543401],\n",
       "        [  32.93736596,   76.05265936,   91.8389177 ],\n",
       "        [  34.64651229,   79.91390869,   98.87386488],\n",
       "        [  34.9851412 ,   80.75528654,  101.5462402 ],\n",
       "        [  33.93950032,   78.90077892,   99.04338762]],\n",
       "\n",
       "       [[  13.37304339,   12.97058971,   39.93070661],\n",
       "        [   9.75372827,    1.67434761,   44.28943345],\n",
       "        [   6.98013055,   -8.71489153,   48.87953253],\n",
       "        [   3.61475089,  -22.95426653,   36.70578934],\n",
       "        [   2.52761476,  -28.97373501,   48.10855164],\n",
       "        [  -4.00850369,  -43.83422078,   39.91841755]],\n",
       "\n",
       "       [[  44.19846934,   48.4969891 ,   69.21153414],\n",
       "        [  43.77748117,   55.08212805,   74.83805436],\n",
       "        [  40.65512333,   53.51893297,   73.59269097],\n",
       "        [  41.5959391 ,   34.61961819,   57.09819738],\n",
       "        [  27.5095321 ,    5.64738898,   52.49835455],\n",
       "        [  16.50886494,  -19.62136498,   42.55810154]],\n",
       "\n",
       "       [[  17.18573505,   15.99595366,   54.00463588],\n",
       "        [  17.05390474,   11.98583294,   53.08306621],\n",
       "        [  12.09361359,    3.08200639,   58.8400457 ],\n",
       "        [  12.67642025,   -4.80752216,   56.45487114],\n",
       "        [   6.83666978,  -18.65694132,   66.98653865],\n",
       "        [   4.46232136,  -28.6126819 ,   69.37048191]]])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allAns = np.array(allAns)\n",
    "allAns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
