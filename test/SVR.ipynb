{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "\n",
    "def mape(y_pred, y_true):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../data/preprocessed_input_interpolate_20min_phase1and2_train.csv\")\n",
    "del dataset['date']\n",
    "\n",
    "# Only select columns which are useful\n",
    "selected_col = [\"hour\"]\n",
    "\n",
    "# Target predict columns\n",
    "predict_col = \"(3, 1, 'tot')\"\n",
    "predict_col_shifted = \"predict_shift_6\"\n",
    "\n",
    "# Time shift backward for predict_col\n",
    "dataset_shift_1 = dataset.shift(periods=-1)[predict_col].fillna(method=\"ffill\")\n",
    "dataset_shift_2 = dataset.shift(periods=-2)[predict_col].fillna(method=\"ffill\")\n",
    "dataset_shift_6 = dataset.shift(periods=-6)[predict_col].fillna(method=\"ffill\")\n",
    "\n",
    "# Add time shifted predict_col to dataset\n",
    "#dataset = dataset.assign(predict_shift_1=pd.Series(dataset_shift_1).values)\n",
    "#dataset = dataset.assign(predict_shift_2=pd.Series(dataset_shift_2).values)\n",
    "dataset = dataset.assign(predict_shift_6=pd.Series(dataset_shift_6).values)\n",
    "#selected_col.append(predict_col)\n",
    "#selected_col.append(\"predict_shift_1\")\n",
    "#selected_col.append(\"predict_shift_2\")\n",
    "#selected_col.append(\"predict_shift_6\")\n",
    "\n",
    "training_set = dataset[:-24*3*14]\n",
    "predict_set = dataset[-24*3*14:-24*3*7][lambda df : ((df.hour >= 6) & (df.hour < 8)) | ((df.hour >= 15) & (df.hour < 17))]\n",
    "\n",
    "# Prepare potential features to add to the feature set\n",
    "unused_features = [predict_col, predict_col_shifted]\n",
    "unused_features.extend(selected_col)\n",
    "if predict_col == \"(1, 0, 'tot')\":\n",
    "    unused_features.extend([\"(1, 0, 'cargocar')\", \"(1, 0, 'etc')\", \"(1, 0, 'motorcycle')\", \"(1, 0, 'privatecar')\", \"(1, 0, 'tot')\", \"(1, 0, 'unknowncar')\"])\n",
    "elif predict_col == \"(1, 1, 'tot')\":\n",
    "    unused_features.extend([\"(1, 1, 'cargocar')\", \"(1, 1, 'etc')\", \"(1, 1, 'motorcycle')\", \"(1, 1, 'privatecar')\", \"(1, 1, 'tot')\", \"(1, 1, 'unknowncar')\"])\n",
    "elif predict_col == \"(2, 0, 'tot')\":\n",
    "    unused_features.extend([\"(2, 0, 'cargocar')\", \"(2, 0, 'etc')\", \"(2, 0, 'motorcycle')\", \"(2, 0, 'privatecar')\", \"(2, 0, 'tot')\", \"(2, 0, 'unknowncar')\"])\n",
    "elif predict_col == \"(3, 0, 'tot')\":\n",
    "    unused_features.extend([\"(3, 0, 'cargocar')\", \"(3, 0, 'etc')\", \"(3, 0, 'motorcycle')\", \"(3, 0, 'privatecar')\", \"(3, 0, 'tot')\", \"(3, 0, 'unknowncar')\"])\n",
    "elif predict_col == \"(3, 1, 'tot')\":\n",
    "    unused_features.extend([\"(3, 1, 'cargocar')\", \"(3, 1, 'etc')\", \"(3, 1, 'motorcycle')\", \"(3, 1, 'privatecar')\", \"(3, 1, 'tot')\", \"(3, 1, 'unknowncar')\"])\n",
    "potential_features = list(training_set.columns)\n",
    "potential_features = [x for x in potential_features if x not in unused_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.136529714119828\n"
     ]
    }
   ],
   "source": [
    "clf = SVR(C=1.0, epsilon=0.1)\n",
    "clf.fit(training_set[selected_col], training_set[predict_col_shifted])\n",
    "base_score = mape(clf.predict(predict_set[selected_col]), predict_set[predict_col_shifted])\n",
    "print(base_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_holiday 23.819959098878904\n",
      "['hour', 'is_holiday']\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    next_feature = None\n",
    "    for col in potential_features:\n",
    "        selected_col.append(col)\n",
    "        clf.fit(training_set[selected_col], training_set[predict_col_shifted])\n",
    "        score = mape(clf.predict(predict_set[selected_col]), predict_set[predict_col_shifted])\n",
    "        if base_score > score:\n",
    "            base_score = score\n",
    "            next_feature = col\n",
    "        selected_col.pop()\n",
    "    if next_feature is not None:\n",
    "        selected_col.append(next_feature)\n",
    "        print(next_feature, base_score)\n",
    "        potential_features.remove(next_feature)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "print(selected_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.28061238129334\n"
     ]
    }
   ],
   "source": [
    "training_set = dataset[:-24*3*7]\n",
    "predict_set = dataset[-24*3*7:][lambda df : ((df.hour >= 6) & (df.hour < 8)) | ((df.hour >= 15) & (df.hour < 17))]\n",
    "clf.fit(training_set[selected_col], training_set[predict_col_shifted])\n",
    "final_score = mape(clf.predict(predict_set[selected_col]), predict_set[predict_col_shifted])\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
