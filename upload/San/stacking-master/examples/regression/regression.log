Start model training and prediction...
Couldn't import dot_parser, loading of dot files will not be possible.
Setting Problem:regression, Eval:rmse
train shape :(379, 26)
train shape after concat and drop_duplicates :(379, 26)
Done StratifiedKFold
Start stage 1 training
running model: v1_stage1
train shape :(379, 26)
train shape after concat and drop_duplicates :(379, 26)
loading cv_fold file
Creating train and test sets for stacking.
Fold 0
rmse:  8.60224382942
Fold 1
rmse:  8.91570543396
Fold 2
rmse:  8.99949641263
Fold 3
rmse:  9.75694382841
Fold 4
rmse:  9.23957178271
Fold1: 8.60224382942
Fold2: 8.91570543396
Fold3: 8.99949641263
Fold4: 9.75694382841
Fold5: 9.23957178271
rmse Mean:  9.10279225743  Std:  0.385446015987
Saving results
running model: v2_stage1
train shape :(379, 26)
train shape after concat and drop_duplicates :(379, 26)
loading cv_fold file
Creating train and test sets for stacking.
Fold 0
(293, 26)
Train on 293 samples, validate on 86 samples
Epoch 1/5
 32/293 [==>...........................] - ETA: 0s - loss: 542.7120 - acc: 0.0000e+00293/293 [==============================] - 0s - loss: 578.7174 - acc: 0.0000e+00 - val_loss: 499.8897 - val_acc: 0.0000e+00
Epoch 2/5
 32/293 [==>...........................] - ETA: 0s - loss: 454.5628 - acc: 0.0000e+00293/293 [==============================] - 0s - loss: 488.8087 - acc: 0.0000e+00 - val_loss: 397.6525 - val_acc: 0.0000e+00
Epoch 3/5
 32/293 [==>...........................] - ETA: 0s - loss: 481.1369 - acc: 0.0000e+00293/293 [==============================] - 0s - loss: 370.7747 - acc: 0.0000e+00 - val_loss: 266.2318 - val_acc: 0.0000e+00
Epoch 4/5
 32/293 [==>...........................] - ETA: 0s - loss: 366.2760 - acc: 0.0000e+00293/293 [==============================] - 0s - loss: 234.4746 - acc: 0.0000e+00 - val_loss: 140.7656 - val_acc: 0.0000e+00
Epoch 5/5
 32/293 [==>...........................] - ETA: 0s - loss: 116.1372 - acc: 0.0000e+00293/293 [==============================] - 0s - loss: 119.9335 - acc: 0.0068 - val_loss: 62.0909 - val_acc: 0.0000e+00
86/86 [==============================] - 0s
rmse:  7.87977972627
127/127 [==============================] - 0s
Fold 1
(301, 26)
Train on 301 samples, validate on 78 samples
Epoch 1/5
 32/301 [==>...........................] - ETA: 0s - loss: 761.1418 - acc: 0.0000e+00301/301 [==============================] - 0s - loss: 573.6566 - acc: 0.0000e+00 - val_loss: 509.3356 - val_acc: 0.0000e+00
Epoch 2/5
 32/301 [==>...........................] - ETA: 0s - loss: 580.6017 - acc: 0.0000e+00301/301 [==============================] - 0s - loss: 485.2528 - acc: 0.0000e+00 - val_loss: 403.3019 - val_acc: 0.0000e+00
Epoch 3/5
 32/301 [==>...........................] - ETA: 0s - loss: 514.8873 - acc: 0.0000e+00301/301 [==============================] - 0s - loss: 367.8971 - acc: 0.0000e+00 - val_loss: 266.5608 - val_acc: 0.0000e+00
Epoch 4/5
 32/301 [==>...........................] - ETA: 0s - loss: 265.8844 - acc: 0.0000e+00301/301 [==============================] - 0s - loss: 231.2637 - acc: 0.0000e+00 - val_loss: 145.4277 - val_acc: 0.0000e+00
Epoch 5/5
 32/301 [==>...........................] - ETA: 0s - loss: 186.8358 - acc: 0.0000e+00301/301 [==============================] - 0s - loss: 119.2698 - acc: 0.0000e+00 - val_loss: 66.1204 - val_acc: 0.0000e+00
78/78 [==============================] - 0s
rmse:  8.13144709972
127/127 [==============================] - 0s
Fold 2
(314, 26)
Train on 314 samples, validate on 65 samples
Epoch 1/5
 32/314 [==>...........................] - ETA: 0s - loss: 756.3443 - acc: 0.0000e+00314/314 [==============================] - 0s - loss: 583.2250 - acc: 0.0000e+00 - val_loss: 471.6495 - val_acc: 0.0000e+00
Epoch 2/5
 32/314 [==>...........................] - ETA: 0s - loss: 547.7113 - acc: 0.0000e+00314/314 [==============================] - 0s - loss: 487.2101 - acc: 0.0000e+00 - val_loss: 392.2082 - val_acc: 0.0000e+00
Epoch 3/5
 32/314 [==>...........................] - ETA: 0s - loss: 313.7219 - acc: 0.0000e+00314/314 [==============================] - 0s - loss: 364.5455 - acc: 0.0000e+00 - val_loss: 283.6585 - val_acc: 0.0000e+00
Epoch 4/5
 32/314 [==>...........................] - ETA: 0s - loss: 290.4670 - acc: 0.0000e+00314/314 [==============================] - 0s - loss: 223.9528 - acc: 0.0000e+00 - val_loss: 165.5723 - val_acc: 0.0000e+00
Epoch 5/5
 32/314 [==>...........................] - ETA: 0s - loss: 149.4947 - acc: 0.0000e+00314/314 [==============================] - 0s - loss: 109.6558 - acc: 0.0064 - val_loss: 80.8101 - val_acc: 0.0000e+00
65/65 [==============================] - 0s
rmse:  8.98944591331
127/127 [==============================] - 0s
Fold 3
(301, 26)
Train on 301 samples, validate on 78 samples
Epoch 1/5
 32/301 [==>...........................] - ETA: 0s - loss: 713.6832 - acc: 0.0000e+00301/301 [==============================] - 0s - loss: 551.0021 - acc: 0.0000e+00 - val_loss: 580.4593 - val_acc: 0.0000e+00
Epoch 2/5
 32/301 [==>...........................] - ETA: 0s - loss: 489.2682 - acc: 0.0000e+00301/301 [==============================] - 0s - loss: 463.7979 - acc: 0.0000e+00 - val_loss: 452.0970 - val_acc: 0.0000e+00
Epoch 3/5
 32/301 [==>...........................] - ETA: 0s - loss: 344.5428 - acc: 0.0000e+00301/301 [==============================] - 0s - loss: 348.1780 - acc: 0.0000e+00 - val_loss: 305.8285 - val_acc: 0.0000e+00
Epoch 4/5
 32/301 [==>...........................] - ETA: 0s - loss: 224.3395 - acc: 0.0000e+00301/301 [==============================] - 0s - loss: 220.8563 - acc: 0.0000e+00 - val_loss: 162.6225 - val_acc: 0.0000e+00
Epoch 5/5
 32/301 [==>...........................] - ETA: 0s - loss: 106.5087 - acc: 0.0000e+00301/301 [==============================] - 0s - loss: 111.3513 - acc: 0.0033 - val_loss: 82.5637 - val_acc: 0.0256
78/78 [==============================] - 0s
rmse:  9.08645730934
127/127 [==============================] - 0s
Fold 4
(307, 26)
Train on 307 samples, validate on 72 samples
Epoch 1/5
 32/307 [==>...........................] - ETA: 0s - loss: 670.0336 - acc: 0.0000e+00307/307 [==============================] - 0s - loss: 565.8286 - acc: 0.0000e+00 - val_loss: 545.9544 - val_acc: 0.0000e+00
Epoch 2/5
 32/307 [==>...........................] - ETA: 0s - loss: 487.2059 - acc: 0.0000e+00307/307 [==============================] - 0s - loss: 476.0830 - acc: 0.0000e+00 - val_loss: 444.2570 - val_acc: 0.0000e+00
Epoch 3/5
 32/307 [==>...........................] - ETA: 0s - loss: 326.6109 - acc: 0.0000e+00307/307 [==============================] - 0s - loss: 359.3732 - acc: 0.0000e+00 - val_loss: 307.7286 - val_acc: 0.0000e+00
Epoch 4/5
 32/307 [==>...........................] - ETA: 0s - loss: 254.4285 - acc: 0.0000e+00307/307 [==============================] - 0s - loss: 225.1513 - acc: 0.0000e+00 - val_loss: 170.2868 - val_acc: 0.0000e+00
Epoch 5/5
 32/307 [==>...........................] - ETA: 0s - loss: 157.3223 - acc: 0.0000e+00307/307 [==============================] - 0s - loss: 113.7962 - acc: 0.0000e+00 - val_loss: 78.6680 - val_acc: 0.0000e+00
72/72 [==============================] - 0s
rmse:  8.86950025512
127/127 [==============================] - 0s
Fold1: 7.87977972627
Fold2: 8.13144709972
Fold3: 8.98944591331
Fold4: 9.08645730934
Fold5: 8.86950025512
rmse Mean:  8.59132606075  Std:  0.489657451218
Saving results
(379, 26)
Epoch 1/5
 32/379 [=>............................] - ETA: 0s - loss: 604.2056 - acc: 0.0000e+00379/379 [==============================] - 0s - loss: 561.8000 - acc: 0.0000e+00     
Epoch 2/5
 32/379 [=>............................] - ETA: 0s - loss: 538.8753 - acc: 0.0000e+00379/379 [==============================] - 0s - loss: 447.7474 - acc: 0.0000e+00     
Epoch 3/5
 32/379 [=>............................] - ETA: 0s - loss: 452.4480 - acc: 0.0000e+00379/379 [==============================] - 0s - loss: 297.7437 - acc: 0.0000e+00     
Epoch 4/5
 32/379 [=>............................] - ETA: 0s - loss: 229.4500 - acc: 0.0000e+00379/379 [==============================] - 0s - loss: 147.6675 - acc: 0.0000e+00     
Epoch 5/5
 32/379 [=>............................] - ETA: 0s - loss: 72.8808 - acc: 0.0000e+00379/379 [==============================] - 0s - loss: 59.2713 - acc: 0.0106         
127/127 [==============================] - 0s
running model: v3_stage1
train shape :(379, 26)
train shape after concat and drop_duplicates :(379, 26)
loading cv_fold file
Creating train and test sets for stacking.
Fold 0
rmse:  8.22162718955
Fold 1
rmse:  8.86275160829
Fold 2
rmse:  9.28419774695
Fold 3
rmse:  9.0773621853
Fold 4
rmse:  8.96440835402
Fold1: 8.22162718955
Fold2: 8.86275160829
Fold3: 9.28419774695
Fold4: 9.0773621853
Fold5: 8.96440835402
rmse Mean:  8.88206941682  Std:  0.35865952467
Saving results
running model: v4_stage1
train shape :(379, 26)
train shape after concat and drop_duplicates :(379, 26)
loading cv_fold file
Creating train and test sets for stacking.
Fold 0
rmse:  6.05679736016
Fold 1
rmse:  6.20285912816
Fold 2
rmse:  5.81671422462
Fold 3
rmse:  6.85271307025
Fold 4
rmse:  6.34868338742
Fold1: 6.05679736016
Fold2: 6.20285912816
Fold3: 5.81671422462
Fold4: 6.85271307025
Fold5: 6.34868338742
rmse Mean:  6.25555343412  Std:  0.346448650694
Saving results
running model: v5_stage1
train shape :(379, 26)
train shape after concat and drop_duplicates :(379, 26)
loading cv_fold file
Creating train and test sets for stacking.
Fold 0
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           5.9692           0.6017            0.19s
         2           5.7046           0.4494            0.20s
         3           5.2285           0.3773            0.20s
         4           4.8006           0.2684            0.20s
         5           4.5342           0.2742            0.21s
         6           4.2798           0.2204            0.21s
         7           4.0584           0.2366            0.21s
         8           3.6419           0.1771            0.21s
         9           3.4698           0.1232            0.21s
        10           3.2514           0.1467            0.21s
        20           1.8209          -0.0093            0.22s
        30           1.1530           0.0415            0.22s
        40           0.8895           0.0014            0.21s
        50           0.7557          -0.0183            0.19s
        60           0.5735          -0.0049            0.17s
        70           0.4227          -0.0067            0.16s
        80           0.3350          -0.0040            0.14s
        90           0.2981          -0.0011            0.12s
       100           0.2382          -0.0010            0.10s
rmse:  3.01207813912
Fold 1
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           6.3444           0.3955            0.18s
         2           6.0072           0.4035            0.20s
         3           4.7199           0.3082            0.20s
         4           4.9521           0.3271            0.21s
         5           4.4319           0.3265            0.21s
         6           4.6200           0.1929            0.22s
         7           4.1035           0.1863            0.22s
         8           3.5411           0.2040            0.22s
         9           3.3635           0.1644            0.23s
        10           3.1813           0.1055            0.23s
        20           1.8464           0.0056            0.23s
        30           1.0634           0.0210            0.23s
        40           0.8735          -0.0160            0.21s
        50           0.6194           0.0033            0.20s
        60           0.4135          -0.0083            0.20s
        70           0.3850          -0.0018            0.19s
        80           0.4085          -0.0053            0.17s
        90           0.3675          -0.0026            0.14s
       100           0.3069          -0.0011            0.12s
rmse:  3.11555337804
Fold 2
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           5.6421           0.4184            0.21s
         2           5.7229           0.3155            0.20s
         3           5.3150           0.3156            0.21s
         4           4.8828           0.2614            0.21s
         5           4.6505           0.2181            0.21s
         6           4.1459           0.1882            0.22s
         7           3.6457           0.2437            0.22s
         8           3.5323           0.1889            0.22s
         9           3.5987           0.2081            0.22s
        10           3.1187           0.1142            0.22s
        20           1.6089           0.0594            0.23s
        30           1.0598          -0.0029            0.23s
        40           0.6641          -0.0084            0.22s
        50           0.5565          -0.0003            0.20s
        60           0.4592          -0.0073            0.19s
        70           0.3259          -0.0001            0.17s
        80           0.2763          -0.0045            0.16s
        90           0.2129          -0.0018            0.13s
       100           0.1794          -0.0017            0.11s
rmse:  4.24339249355
Fold 3
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           5.7596           0.4181            0.21s
         2           5.3865           0.3869            0.21s
         3           5.1651           0.3243            0.21s
         4           5.1457           0.2932            0.21s
         5           4.7226           0.2012            0.22s
         6           4.1470           0.2276            0.22s
         7           3.8555           0.1830            0.22s
         8           3.1584           0.1691            0.22s
         9           3.6899           0.1594            0.22s
        10           3.2595           0.1204            0.22s
        20           1.8660           0.0560            0.23s
        30           0.9889          -0.0031            0.23s
        40           0.7433          -0.0186            0.22s
        50           0.7030          -0.0078            0.20s
        60           0.5460           0.0008            0.19s
        70           0.4464          -0.0061            0.16s
        80           0.3885          -0.0057            0.14s
        90           0.2435          -0.0028            0.12s
       100           0.2625          -0.0003            0.10s
rmse:  3.30297700023
Fold 4
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           6.0414           0.4461            0.19s
         2           5.9467           0.4168            0.19s
         3           5.6360           0.2785            0.19s
         4           4.5787           0.4241            0.20s
         5           4.6392           0.2412            0.21s
         6           4.1663           0.2178            0.21s
         7           3.9320           0.2091            0.22s
         8           3.2134           0.1585            0.22s
         9           3.2169           0.1642            0.23s
        10           2.8948           0.1358            0.23s
        20           1.8940           0.0164            0.25s
        30           1.2596           0.0168            0.25s
        40           0.8589           0.0152            0.25s
        50           0.6094          -0.0062            0.22s
        60           0.5945          -0.0028            0.20s
        70           0.4629          -0.0012            0.18s
        80           0.3184          -0.0002            0.16s
        90           0.3755          -0.0019            0.14s
       100           0.2916          -0.0031            0.11s
rmse:  4.00657862241
Fold1: 3.01207813912
Fold2: 3.11555337804
Fold3: 4.24339249355
Fold4: 3.30297700023
Fold5: 4.00657862241
rmse Mean:  3.53611592667  Std:  0.495462916728
Saving results
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           6.2364           0.4345            0.27s
         2           5.3664           0.4081            0.26s
         3           4.8987           0.3835            0.27s
         4           4.8928           0.3095            0.28s
         5           4.6404           0.2600            0.29s
         6           4.1335           0.1790            0.29s
         7           3.8367           0.2052            0.29s
         8           3.6727           0.1573            0.30s
         9           3.3587           0.1219            0.30s
        10           3.1687           0.1411            0.30s
        20           1.8566           0.0415            0.31s
        30           1.2348          -0.0029            0.32s
        40           0.8143          -0.0009            0.30s
        50           0.5959          -0.0015            0.28s
        60           0.4473          -0.0161            0.25s
        70           0.4106          -0.0017            0.23s
        80           0.3151          -0.0022            0.20s
        90           0.2668          -0.0009            0.17s
       100           0.2401          -0.0118            0.14s
running model: v6_stage1
train shape :(379, 26)
train shape after concat and drop_duplicates :(379, 26)
loading cv_fold file
Creating train and test sets for stacking.
Fold 0
Convergence after  27  iterations
rmse:  3.48757912438
Fold 1
Convergence after  23  iterations
rmse:  3.94965710742
Fold 2
Convergence after  27  iterations
rmse:  5.38189381822
Fold 3
Convergence after  22  iterations
rmse:  3.85000341218
Fold 4
Convergence after  33  iterations
rmse:  4.77926775508
Fold1: 3.48757912438
Fold2: 3.94965710742
Fold3: 5.38189381822
Fold4: 3.85000341218
Fold5: 4.77926775508
rmse Mean:  4.28968024346  Std:  0.690640873199
Saving results
Convergence after  27  iterations
Done stage 1

Start stage 2 training
train shape :(379, 32)
train shape after concat and drop_duplicates :(379, 32)
running model: v1_stage2
train shape :(379, 32)
train shape after concat and drop_duplicates :(379, 32)
loading cv_fold file
Creating train and test sets for stacking.
Fold 0
rmse:  3.75335961421
Fold 1
rmse:  3.32345334916
Fold 2
rmse:  4.1339558159
Fold 3
rmse:  3.76259948617
Fold 4
rmse:  4.49109809849
Fold1: 3.75335961421
Fold2: 3.32345334916
Fold3: 4.1339558159
Fold4: 3.76259948617
Fold5: 4.49109809849
rmse Mean:  3.89289327279  Std:  0.394123864416
Saving results
Done stage 2

Saving as submission format
Evaluation
rmse:  2.45050864054
Done...
